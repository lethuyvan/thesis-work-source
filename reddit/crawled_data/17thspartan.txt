Bless you.

But I'm a debian man myself. 
The 3rd Halo 5.
As a non-Chinese native, I can guarantee that this video is 100% legit. People always point to the camera operator and say it's fake because they think someone else must be in the room and filming this, but they forget that all Chinese homes have surveillance cameras in them[^^source](https://www.rfa.org/english/news/china/surveillance-03302018111415.html), to ensure their citizens stay safe. 

It's likely just the friendly camera operator saw this happen, and decided it was too funny to not share on the web. 

^^^/s ^^^just ^^^in ^^^case
I use Comodo Firewall on Windows, and primarily segment my networks by the MAC addresses of my interfaces. As a backup, I've also set the network zones set up by ip ranges/subnet. 10.0.0.1 - 10.255.255.255 = TAP, 192.168.1/24 = primary ethernet. From there I route TCP/UDP traffic based on what port it uses (ie force all traffic on port 53 (DNS) to use the network zone associated with 192.168.1.x).

I haven't used UFW before, but from a few searches, it doesn't seem to have any way to specify which network zone to use based on MAC address. Maybe you can set it to do something like 'ufw allow 192.168.0.0/24 to any port 53' and 'ufw deny 10.0.0.0/8 to any port 53'? I might have gotten the logic wrong on that part (maybe it's 'allow any to 192... port 53' instead), but I think that would deny any DNS traffic on a subnet of 10.x.x.x, and allow it on a subnet of 192.168.0.x.
Yea, I don't have enough Linux experience to say for sure what the answer is, but after some googling, it seems that iptables + tc (traffic control) might be your best bet? There's a couple of posts out there that suggest you can route traffic to specific network interfaces at the application level by using using IP namespaces, or route at a packet level by using iptables + tc. I don't have any experience with either of these though, so I can't say what to do beyond that. 

But it might be worth verifying where your DNS requests are going, if you haven't already. Using something like Wireshark to capture your packets and see if the DNS requests are actually using your TUN network connection or your eth0 connection. If it's accessing your eth0, then it should be working fine, since your computer's dns cache would contain the right addresses from your pihole device, and then it wouldn't matter which network device was requesting the site's IP address. 

If you do run any kind of Wireshark type thing, be sure you clear your dns cache, just to ensure it'll make a fresh request to your rpi. 
As you pointed out, your subnet for PIA is on a 10.x while your pi is on 192.x (and your non-vpn connection on your pc should have a 192 address too). So any packet addressed outside of your network would be routed via the 10.x connection. Could be that the DNS requests are being sent on the 10.x connection too, for some reason. 

But since the ping you ran was addressed to a local address it would be sent via your normal, non-vpn ethernet (or wifi) connection.

At least, that's my guess on what's happening here. I've used the PIA app (which is based on open VPN) and it seems to only route internet bound packets via the 10.x address and all others by your local address. For example my chrome browser can connect to my tv's chromecast even when I'm on VPN, but when I force it to use the ethernet connection created by PIA (via firewall settings), it'll fail to resolve or connect to anything on my local address. 
Like I said, phone is US based, PC is currently connected to Canada. If someone wants to stitch them together and re-upload, feel free, or someone in the US could take a pic of their own youtube trending page on the PC. And I checked every section in my phone, the main trending page, the news trending page; I didn't see it anywhere. 

[Phone (US Youtube Main Trending)](https://i.imgur.com/SUHYijd.jpg)

[PC (Canada Youtube Trending)](https://i.imgur.com/NexKQ87.png)

Edit: The [video itself](https://i.imgur.com/mQeacrB.jpg) is still trending at number 2 on Canada's trending page. As shown in the pic above and here. And just for reference, all pictures were taken around 1:30-1:40 am US central time. 
It's trending at #2 in Canada and it was in the top 10 in Mexico (only places I've tried so far).

Despite it having such a high view count, it is nowhere on the main trending list for the US. Maybe people in the US just don't click on the same videos as Canadians and Mexicans (even though the rest of the top 10 videos in those trending lists seem to be the same).
It's trending at #2 in Canada and it was in the top 10 in Mexico (only places I've tried so far).

Despite it having such a high view count, it is nowhere on the main trending list for the US. 
Speaking of big companies who can throw money around: why isn't this trending on youtube in the US?

I'm logged into the normal US youtube on my phone and it's nowhere to be seen in the main trending list. But I use VPNs on my pc and it's logged into Mexico and Canada, and it's trending number 2 in those. 

Reddit I can see giving into to money from such a wealthy company, cause reddit seems sorta desperate for money. I didn't think youtube would so easily. 

Edit: replied below with this also: 

>Like I said, phone is US based, PC is currently connected to Canada. If someone wants to stitch them together and re-upload, feel free, or someone in the US could take a pic of their own youtube trending page on the PC. And I checked every section in my phone, the main trending page, the news trending page; I didn't see it anywhere. 

>[Phone (US Youtube Main Trending)](https://i.imgur.com/SUHYijd.jpg)

>[PC (Canada Youtube Trending)](https://i.imgur.com/NexKQ87.png)

>The [video itself](https://i.imgur.com/mQeacrB.jpg) is still trending at number 2 on Canada's trending page.
Having extra emails as in the paid feature (aliases)? Or did you mean extra emails in another way?

Edit: you probably meant the paid feature, which is a bummer that they don't automatically let you convert those as well.
50 over the past thousands to (potentially) millions of years. I saw an article mention that one of the events was estimated to have happened more than 600,000 years ago, but they didn't necessarily say if that was the most recent one, or just a random event that they were able to date. 

I sorta discussed why some viruses are more likely to stay than others in a couple of other comments, but there's multiple factors involved. Suffice it to say, a virus becomes a permanent part of the human genome (passed from generation to generation), if it manages to infect the reproductive cells in a human. If that person goes on to have kids, then that virus is essentially part of their genome at that point and future generations of their kids will have it.  

So, you might only need to catch a virus once for it to become a part of your genome (like HIV, which can be passed from mother to child). Things like the cold on the other hand, they don't really infect your reproductive cells, so it seems they've never been passed from generation to generation in this way. 

My comment here has a brief overview, along with links to places where you can read more into it, if you'd like.

https://www.reddit.com/r/educationalgifs/comments/8823b1/comparing_the_sizes_of_microorganisms_up_to_1mm/dwhtjxk/
Exactly. The people who support the company by taking the time to pay for the service are the ones being the most impacted by their authentication methods. I've never heard of a more justified situation for using piracy or some workaround to stop people from having such a problem. I mean, they already paid for it, at least let them use the services they paid for.
I'm certainly no expert in the matter, I was basing what I posted off of a couple of articles I was reading. I believe the term 'human genome' is simply meant to indicate the 'average human' and remove the differences between each individual (since there's up to a .5% difference from one human to the next). This would allow for easier comparisons to other animal species. So it is our entire genome, all the stuff we share with other animals (and [bananas](http://www.businessinsider.com/comparing-genetic-similarity-between-humans-and-other-things-2016-5)), just without the differences between individual humans. As /u/epelle9  noted, it's very likely a large portion of that 8% that are remnants from viruses that infected us before we were distinctly human. 

Primates are affected by viruses in their DNA, and so are [fish](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5512871/), but I don't know enough to say how much overlap there is, only that it's likely that there's a decent amount. 

>[Since viruses cannot replicate on their own, they use the cells of the organisms they infect to make new copies of themselves. One type of virus, retroviruses, inserts a DNA copy of its RNA sequence into the host cell’s genome upon infection. If the virus inserts into a reproductive cell and that cell goes on to produce an offspring, the viral DNA gets passed on from parent to child as part of the genome.2 At this point, the virus is locked in and is passed on from generation to generation. These are called endogenous retroviruses, or ERVs, and this can happen in any type of organism that viruses infect, including humans.](https://fivethirtyeight.com/features/what-percent-virus-are-you/)
Viruses definitely can/do mutate other creature's DNA. Their only purpose is to infect a cell, inject its DNA or RNA into it and replicate. Because of their nature, some [retroviruses](https://en.wikipedia.org/wiki/Retrovirus) can make for [decent delivery systems](https://en.wikipedia.org/wiki/Gene_therapy#Vectors) for us to deliberately introduce DNA into a patient, in gene therapy treatments.

The viruses that infected us in the distant past were certainly passed from generation to generation, but not all DNA changes from viruses are necessarily passed on; with some types of viruses having a higher chance to pass it on to the next generation (like retroviruses, ie HIV). Seems like there's a lot more to viruses and how they get passed on from generation to generation; and I'm definitely out of my depth in that. [This article talks about Human Endogenous Viruses (HERV), which are viruses that are passed from generation to generation.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1187282/)

The article below talks about the study that led to the discovery that HERVs make up nearly 8% of our DNA.

https://fivethirtyeight.com/features/what-percent-virus-are-you/

>One type of virus, retroviruses, inserts a DNA copy of its RNA sequence into the host cell’s genome upon infection. If the virus inserts into a reproductive cell and that cell goes on to produce an offspring, the viral DNA gets passed on from parent to child as part of the genome. At this point, the virus is locked in and is passed on from generation to generation. These are called endogenous retroviruses, or ERVs, and this can happen in any type of organism that viruses infect, including humans.

...

>Although they were once thought to be simple traces of past viral infections, it turns out that these viral sequences can affect the host. At first, the sequences may still produce new viruses, which could infect other cells or other hosts. And when they insert into a genome, they can disrupt the function of that region of DNA. Our genome has a number of ways of combating and silencing these invaders, however. When that happens, these sequences aren’t harmful anymore but are still scattered throughout the genome. Harmit Malik, evolutionary biologist at the Fred Hutchinson Cancer, said that “once they’ve been ‘domesticated’ then the genes or protein products that they encode might be of value to the host.”

>This allows the host to use a genomic sequence that was evolved by the virus for other purposes. Although the viral DNA started as a parasitic element, in some cases it has been co-opted into functional roles by our genome...

To anyone else who was wondering how much of our DNA they make up; it's about 8% of the human genome that comes from invasive retro viruses. Apparently that came from approximately 50 infection events in the past. 
But, justice is often served best via knock out.

Or a carefully written, and scathing letter. But those don't seem to be as popular here. 
It's back up?

I was able to view it.
Damn, 910 dollars for the barebones. 

I expected it to be more than their previous Skull Canyon NUC, but didn't expect it to be that much. Still, looks pretty beastly for such a small form factor. 
I know someone who works at a company in Palo Alto, and the only thing that company does is make software to enable security agencies (and the major banks) to sift through massive amounts of data and make correlations that would otherwise take months or more to make (compared to the methods they were using). They use the same engine in the software for both the CIA/NSA/(FBI?) and the bank variants, but she's one of the senior team members who develops and sells it to the major banks.

Trust me, the NSA built a massive data storage facility in Utah a few years back, and they more then have the capability to make use of all that data; and so does the banking system (but they aren't spying on the entire nation...as far as we know). 

Also, their place of work is pretty nice and they have great benefits (like covering the cost of rent among others), but I don't have anywhere near the chops to work in a place like that. 

Edit: Last time I looked them up was in 2011-2012, it seems they've grown quite a bit.  From their wiki page, a few of their clients are: "DHS, NSA, FBI, CDC, the Marine Corps, the Air Force, Special Operations Command, West Point, the Joint IED Defeat Organization and Allies"
From urbandictionary

>A dangerous stunt used by highly trained professionals in the deadly art of flirting

>*Hey princess, wanna pretend being my cousin and sit on my cock? uwu*

Sounds legit. 
It depends on the hospital system in question. The largest healthcare system (and the largest employer) in Wisconsin doesn't use pagers anymore; at least not in any of their larger or newer hospitals. Can't speak for the outlier hospitals, but I imagine they don't either. 
Yea, you can definitely do all of that, but I think they were talking about the Motorola devices that physically docked into ["lapdock"](https://i.ytimg.com/vi/PvfseZLtN50/maxresdefault.jpg) and used the cell phone's CPU/OS to power the device. 
Motorola did that and it tanked. But today's phones are much more powerful than back then, so it'd likely work better than ever now.

I looked it up just now and there's still "lapdocks" available on Amazon (for Motorola phones) that are in the 300-400 dollar range. 
I always do whenever I can. Their library is really tiny compared to Steam's and they don't get many AAA games, so a lot of the time I think people will end up buying on steam anyways.

But I support Gog whenever possible, because they have fair pricing, they always try to include extras and DLC into a bundle for the price of the base game whenever they can, and all of their content is DRM free. So even 10 years down the line, when the game publisher decides to take the authentication servers offline, you'll still be able to play the games you bought from gog.

And that last part is why I support them the most.
To be fair, the only people who are having issues are the ones who paid for plex pass services. Pirating the features you already paid for to get around the authentication issue sounds pretty reasonable to me.

Unless Plex was using the constant need for authentication to gather and sell user data. In which case, it would be unfair of piraters to deprive plex of that additional income. Like using adblock when visiting a website.
I'm amazed nobody has mentioned Gog.com yet. I mean, they aren't a real replacement for steam because their newest AAA selection is miniscule compared to steam, but they use "fair pricing" because they acknowledge that $50=/=€50.

>If a product on GOG.com costs more in your country than the price in the US, we will make up the difference in value out of our own pockets, and offer it to you as free Wallet funds that you can use towards any future purchase.

[Turned the friggen frogs gay](https://youtu.be/9JRLCBb7qK8)
Damn, that scene was hot. 

For reference: [Obviously NSFW, also it's a xhamster link. ](https://m.xhamster.com/videos/eva-green-300-rise-of-an-empire-4885882)
You'd think so, but the phone market is fairly stagnant right now and companies would pay out the nose if they could have a reliable and cost effective way to make this happen; just to have something different than the competition. 

The market drives things like this, and doing something useful or for the public good isn't necessarily profitable. 

Of course large scale production can drive down costs, leading to organizations with less money to actually work on solving important issues that may not be immediately profitable. 
Actually, the original u/incites was being 100% truthful. About a year ago, he said nearly the same thing and I, being the helpful redditor that I am, decided to check and see if his accounts were secured or not. Turns out, he was truthful about having nothing to hide, and his bank account magically drained itself of all its money that day. And later he learned that his insurance, cell phone, IRA, and dental plan accounts were all taken by some guy who wanted a new identity. 

Anyways, I gave away his reddit account to some random dude on the condition that they only use it to say the dumbest shit they can think of (as demonstrated above). 


The real u/incites learned a powerful lesson that day. A little privacy and security was literally worth more than everything he had.
I bet the guy has locks on his house, his car, and uses a password on his bank account too. Hell, he might even have a password on his reddit account.

Certainly sounds like someone who has something to hide. But if his bank account doesn't have a password, then it's ok if people help themselves to his money.

Because he's not the type to get

> worked up over some ones and zeros
Unfortunately I don't have much experience with Comodo outside of their firewall and sandbox, and it's been a while since I read any reports from places like [AV-Test](https://www.av-test.org/en/antivirus/home-windows/) or [AV-Comparatives](https://www.av-comparatives.org/dynamic-tests/). But I'll link them, in case you want to read up on how their anti-virus compares to others in terms of performance and protection.

I usually handle my own tech support issues, so I don't have experience with their remote support or forensic analysis. 

And I haven't really used their browser, but looking over the features list, it sounds like it's Chromium + Comodo's secure DNS servers + privacy extensions and options built in. I'm sure you can replicate the security/privacy features using Firefox and the right extensions, but sometimes it's useful to have separate browsers for different tasks. 
The reason I generally recommend Comodo, in a security sense, is that it actively monitors your system and it decides what to sandbox and what is trustworthy (real-time protection). After you minimize the number of notifications it has, it's generally easier for the end user to stay protected since it requires little to no interaction. 

If your goal isn't about overall system security, and instead your goal is to manually run sandboxes, or protect yourself against specific attack vectors (like browser exploits, malicious file downloads, etc), then Sandboxie is the way to go. Its sandboxing features are miles ahead and forced programs + simultaneously running multiple sandboxes, makes it well worth a purchase.


I use both. Comodo for its firewall and auto-sandboxing, and Sandboxie because I often need to run more than a few, separate, sandboxes at the same time. 
Thank you; it's crazy so many people have this mentality. Intelligence can't stop malware deployed by methods you aren't even aware of yet, by sources entirely out of your control. Its like saying to someone "be smart when you walk down the street, don't go down any dark alleys, and you won't ever be mugged". The mugger doesn't care how much common sense you have or how intelligent you are. 

I certainly hope people with "common sense" instead of security software, are at least taking the time to pgp verify every file they download and inspect the source code of every executable they use. 
If you're looking through the source code of every executable you download, or you're running pgp checks on every file you download (after getting the fingerprint info from the developer directly or via WOT type of thing) and you trust that sites, even those of large enterprises, can't fall victim to malicious attacks that they might not be aware of (like when legitimate news sites had ads that spread malware, and they had no idea since that ad company using that space didn't know they had a problem) then I absolutely agree and don't think anybody would need any security software.

Until everyone starts doing that, I think it's best to run security software of some kind. Even running as a non-admin account isn't good enough, since there's lots of exploits that can escalate privileges. 
Malware bytes is good and I use it regularly, but as someone who plays with malware (security testing), sandboxes are where it's at.

Comodo firewall is one of the better (non-enterprise) automatic sandboxes I've come across. 

(Simplistic explanation) Antivirus and anti-spyware works on the basis of, check file against a database and as long as there's no matches, the file is OK. It's a, trust this file until proven otherwise methodology.  

There's heuristic scanning, but that and the normal database checks can be defeated with proper encoders (not something out of date like Shikata Ga Nai). 

Automatic sandboxes (comodos specifically) works on the basis of; check the file's digital certificate and if it's not from a trusted source, sandbox it. It's a, trust no files until proven trustworthy system.

Since lots of smaller developer software can come without a trusted digital certificate (or doesn't have one at all), Comodo doesn't actually stop you from running the software. It just runs it in a protected environment where it can't damage your files or the filesystem. If it doesn't act maliciously, and you see it working well, you can choose to unsandbox it and run it normally on your system, or just leave it sandboxed and run it like that. 
Don't use Windows then? None of the stuff I've said is windows specific, you can use custom DNS services, VPNs and ublock+addons on Linux as well. 

It seems the goal of this post is to stop Facebook. If you're looking to stop all sources of tracking, then you're in for a hell of an undertaking. Especially since most folks who worry about windows spying are likely using iphones or Android phones already. 

Edit: For anyone interested in getting started, r/privacy probably has some decent pointers about that kind of thing.
You can still use the headset itself without Oculus. You just need to make sure you disable the oculus apps. I use the headset with Google's VR platform without issue, and it basically acts like a nice version of Google cardboard VR. I think Google's daydream platform is fully compatible too, but I haven't played around with it much. 

If you're on a Samsung phone, you can disable system apps without root.

http://www.packagedisabler.com
I do, but I don't use the oculus applications anymore. You can use your Gear VR, with Google's cardboard apps, or their normal daydream/VR apps.

Freeze/delete the oculus apps (you can freeze/delete system apps without root on Samsung phones), and then use it like a normal VR headset.

http://www.packagedisabler.com

Uses the Knox API to disable system apps without root. 
I think they meant for Android and iPhones. I think it works like most other ad blocking apps and routes your traffic through a VPN server that blocks ads. So it works everywhere, not just on your browser.

But on your home PC, I'd just change my DNS provider, use a paid VPN service that i pick out myself, and use ublock origin + other addons. 
There was an article on r/android a while back about how you can turn off your GPS/location, but Google doesn't actually respect that and doesn't actually turn those off. (that's on normal Android phones, unclear if it's the same on iPhone).

So apps, not just Google ones, can still get precise location data on you. Even if your GPS actually turned off, they can still use your wifi or cell signal to get a decent idea of where you are. 
Damn. I would have thought that your upload bandwidth would need to be higher just to hit the 120mbps down speeds.

Then again, I guess I've never paid attention to what streaming videos/downloads/sites use TCP vs UDP or anything like that. 

I just know that when I'm maxing out my ~120mbps connection, I usually have about 3-5mbps in overhead, upload bandwidth, being used. If I'm using up 90% of my upload bandwidth to do backups, then I usually can't hit full download speeds. 
It really shouldn't have any affect at all. At worst it might cause a few more reads and writes to happen, but that's what hard drives are designed to do anyways.

All of your Windows machines and Ubuntu all play nice with NTFS, so your file systems shouldn't face any damage from your OS choices.

Also, there are plenty of folks who run hypervisors/VMs that handle lots of drives, and often switch back and forth between the OSs. 
Right. The folks who are supposed to be well trained make mistakes like this. I'm not looking forward to a future where teachers, with absolute minimal training, start carrying around guns, expecting them to kill school shooters when cops aren't even willing to enter a school with an active shooter. 

Just seems like a clusterfuck waiting to happen. Kids are gonna get shot when mistaken for a school shooter (in an active shooter situation, I'm willing to bet there'll be more than one casualty caused by a teacher), accidentally when a gun goes off, when a teacher feels threatened by an unarmed student, or to break up a fight. 

Anyways, this was the guy I was thinking of, DEA agent: https://www.forbes.com/sites/kashmirhill/2012/01/17/viral-video-of-dea-agent-shooting-self-in-thigh-may-have-hurt-but-didnt-violate-privacy/#79ac5a066378
/u/Manolo_Ribera kinda explained it all, but to show how trivial it is to 'spoof' your mac address, Windows 10 has a feature that lets you change your mac to a random address for every new network your connect to if your wifi card is compatible (to prevent your location from being tracked as you move from place to place). Settings > Network and Internet > Wifi > Random hardware address. 

I've never done it on Windows, but I've used non-existent mac addresses quite often.
Pinged it and got a response :O

It came from inside the house!
If you're curious, Windows 10 has an option to use random mac addresses for any new wifi networks you connect to, so long as you wifi card is compatible. It's to help prevent you from being easily tracked (physically tracked as you move from place to place). 

Settings > Network and Internet > Wifi > Use Random Mac Address. 

Of course there's lots of other ways if your wifi card isn't compatible with that particular Windows feature. 
Damn, beat me too it. I had just finished searching through a list and was about to post.


Truth is that if you actually look for it, there's been articles about guns going off in schools surprisingly often (I don't mean school shooters). It's just that nobody cared until now.

I remember one from a few years back where a cop shot himself in the leg while trying to show highschoolers proper gun safety.

Shit happens more often than people think, it's just that nobody cared until now, but now that guns in school is a hot topic, every instance of improper gun use is the liberal's fault.

Edit: [This was the guy I was thinking of.](https://www.forbes.com/sites/kashmirhill/2012/01/17/viral-video-of-dea-agent-shooting-self-in-thigh-may-have-hurt-but-didnt-violate-privacy/#79ac5a066378)
Just hit Ctrl+Alt+F1 and switch to a terminal only, non-graphical interface (tty mode). For Fedora and Debian based distros anyways.

That'll probably be enough to stop most folks in their tracks.
In my case it's because Nvidia GTX cards give you a code 43 error if you try to run it in a VM (with certain hypervisors), whereas I can use a single AMD GPU and run multiple VMs with it.

As much as I need/want a Vega64, I can't justify paying 880 for a Vega64 or 1080ti.
Have you read any of the other comments in this chain? Because if you did, you'd notice that it's already well established that he's going to jail for securities fraud and then the discussion was about his price gouging (which nobody has said is illegal, and I said many other companies do it all the time). 

Please try to read the comments before commenting yourself, so you don't detract from the conversation. 
I'm not emotionally invested at all. I honestly don't care if he goes to jail or not, because his going to jail changes nothing in the big scheme of things. 

I was only clarifying what the guy before me said about price gouging people. If you feel differently, you could take the time to write something useful rather than to simply say "You are 100% wrong".
He's no more evil than anyone else in the industry, and I'm in no way suggesting he is more evil. I was only explaining what the previous guy was talking about.

He took a drug that was 13.50 per pill (widely considered affordable, especially with insurance and governmental programs covering it) and raised it to be 750 per pill overnight, the media made a big deal about him having jacked up the price (because normal companies don't use that massive of an increase all at once, since it would inevitably draw negative attention), and in response to all the negative press, he later announced he would be making it free for low income folks (so they could start to use that pill again). 

And to the bit about covering the costs to develop better versions of the drugs, that's what every drug company says. The reason they push for longer exclusivity on selling rights (prevent generics from being released), the reason they have to charge so much for X pill, the reason Americans pay more per pill for nearly every drug than every other country on earth, is because they have to cover the cost of R&D, and in turn they've had record profits year over year. This is despite the fact that they spend more on [sales+marketing](https://www.washingtonpost.com/news/wonk/wp/2015/02/11/big-pharmaceutical-companies-are-spending-far-more-on-marketing-than-research/?utm_term=.91ab44c7ed3a) (and lobbying) in the US than they do on R&D. If that money actually went to R&D, well that would be a fantastic change from how business is done today.
I'm not talking about whether there are programs to help poor people afford medication (because there obviously are, in both public and private sectors), I'm talking about the fact that his policy changed afterwards to give the pill for free to those who can't afford it.

PPA is a service that helps connect uninsured or poor folks with the (free/low cost) prescription programs that serve them best. But they say right on their website that the drugs that are available in the programs they search through, are entirely decided by the pharmaceutical companies that participate in these programs. If the drug company in question isn't offering the specific pill you need, for free or low cost, then there isn't much they can do (especially if it's a drug that medicare/medicaid doesn't cover either). 

All the major drug companies participate in these programs where they give meds for free, but they don't have every drug available to be had for free or low cost. That's what I was talking about when I said he changed his policy to start offering that particular drug for free to low income folks. 
Camelcamelcamel is a lifesaver. There's been so many lightning deals/prime day/black friday deals/etc I've passed on because looking at camel camel camel, it's obvious that they just jacked the price up by 50-100% the day before and then lowered it again so you'd think you're saving a lot of money.

One of the lightning deals Amazon suggested for me was a mechanical keyboard on sale for 50 from the original price of 250 dollars. Looking on camel camel camel, the only time the keyboard was 250 dollars was on the first month or two after it was originally released (years ago), and it's always been 60 or lower. 
He could have set a policy to gouge insurance companies but to provide it for free to anyone who couldn't afford it. That wasn't his policy originally and it wasn't until he was publicly shamed for having jacked up the prices that he announced that he will be giving it out for free to those who can't afford it.

Had he kept the price gouging within a reasonable range (like most pharmaceutical companies do) then he'd never have been called out and he never would have needed to make a policy to give the pill for free to those who can't afford it.

What he did was nothing more than a PR move. Like a oil company causing billions in damages by losing product into the ocean, but then donating a million or two to an oceanic wildlife preservation thing and making a big deal about their philanthropic endeavors. 
The only major thing that he did that seriously pissed me off is when he fired a massive portion of the workers at one of his plants after "performance reviews". In actuality it was because they were talking about unionizing because of the shitty working conditions. 
It's only in the US that they use high-fructose corn syrup. Pretty much every country I've been to (various places in Asia and Europe), they only use sugar. And Costco/Sam's Club type places sell Mexican Coke (and other sodas), which is basically just Coke, but it uses sugar instead. 

Same goes for most products as well. We use high-fructose corn syrup, while other countries use sugar instead.
Professional messes? I can do that, where do I apply for that job?
As an owner of the S7, and Note 8, I can say that Samsung's got it down when it comes to water resistance. 

As long as you don't go diving into the sea with it, or leave it in water for days on end, you'll be fine. I regularly use mine in the shower, near/in the pool, and rinse it off under the faucet whenever I feel it needs it.
First would be to limit the amount of social media accounts you have and what kind of personal info (like your emails/numbers/etc) you have on them, and also make them private or friends only. From there, be careful about what apps you download onto your phone, or log into on the web that require access to your social media accounts. Some phone apps will request more access than they need so they can sell your info, and some websites can do the same thing. So if they offer it, it might be useful to make a random email account and sign up to sites like that using your email instead of using social media logins. Facebook apps and games should be met with skepticism too, because they could also be requesting more access than they need. 

Another good measure is to use 'burner' numbers when you have to sign up for something that requires a phone number. You can use something like a Google voice number (which is more permanent, but allows you to screen calls and block numbers more easily) or use an app like burnerapp, which gives you a temporary number whenever you need it, to help limit having to use your real phone number (which might help keep your phone number off of sites like truepeoplesearch). Also, it can help when you need to give a number to a tinder date you don't fully know yet.

Also, check out r/privacy. I haven't visited there in ages, but back in the day they used to have all sorts of good info on how to limit exposing your personal info online.

All of that being done, some things will be hard or next to impossible to erase, like your living addresses or court records (which are public, so it can't go away). So you can try using something like DeleteMe from Abine (which is a paid service) and they will send removal requests on your behalf. They won't stop all sites, but they'll take out a portion of them and that can help limit your exposure from people like on OP's pic. 
That's a good thing, isn't it?

No need to worry about stalkers getting your current info. 
It's not always a home run and it varies a lot. The friend that I looked up doesn't have a common name, but it isn't terribly uncommon either, but for the area she was living in, it was pretty uncommon. So that made it a lot easier for google (and other sites, like truepeoplesearch) to return results. And the amount of info you find varies a lot with some folks having social media links and email addresses and everything listed and some folks will only have their previous addresses listed (on free websites anyways, I'm sure paid ones will return more info).

Future employers, and landlords would all be using paid services and likely have contracts with certain businesses to do background checks. They'd have a lot more info to work with too (like your address, name, possibly social security, current place of employment, etc) before they even start the background check process.

As for folks you work with...well if they know your full name and what city you work in, then they might be able to get more info on you, but it can be hit or miss if your name is common. Either way, court cases are a matter of public record, so it's quite likely a co-worker could look you up in that and figure that much out about you at least (arrests, DUIs, speeding tickets, etc).
Definitely, but some of the info that these places have can be hard to hide (like addresses, family) and come from sources where faking your info could potentially cause problems (ie the DMV, but they at least have the option to opt out of allowing them to sell your info).

Other stuff, like email addresses, social media, and sometimes phone numbers, that's definitely possible to fake without much effort. And writing a fake history for yourself on a non-private Facebook (like colleges you attended and jobs your worked) can definitely help as well. 
If you really need info on people on the regular, I guess truepeoplesearch is an option. My post wasn't really about signing up for those services, just to know that these services have info on you and give it out easily. 
I didn't really explain how to use Google or how to perform a search, I only explained what the outcome of such a search could be.

If people were going to creep on others, they probably figured you could put people's names into a Google search long ago. But for those who won't creep on others (and therefore have never tried googling someone), I think it's important they know what kind of info is available about themselves. 
It depends on how they use that phone number. I haven't played around with searching just by number, but if it's their primary phone number and they use officially (ie put on official forms or on social media) then it's quite likely that number will tie back to their real name and from there you can get more information. 

If you (or anyone reading) are looking for safer ways to deal with situations where you need to give out your number (maybe when you're dating), then you should look into voip services that give you 'burner' numbers to use (with texting and calling like a normal number). There's a number of apps on iPhones and Android for exactly that kind of thing. I don't have enough experience with any of them to outright recommend them, but this is a rather popular one I know of: https://www.burnerapp.com/

So you can protect yourself a bit by giving one number to online acquaintances, another number to some form you had to fill out on some website to access something, and yet another to some new person you just met on tinder. And for the most part, these 'burner' apps will let you keep a phone number active as long as you need it. 
Absolutely. Big data is all the rage, but AI could bring in "dark data" (data that can be collected but isn't easy to analyze and therefore difficult to monetize) and add whole new dimensions to what people can know about you.

Last year, Apple bought out an 'AI' company that focuses on finding and utilizing all the unstructured/unofficial "dark data" out there, because there's a huge and unrealized potential to monetize that kind of data. 
Scrubbing your info seems like a difficult task. I've looked into it casually because it makes me cringe every time my bank would ask me what previous addresses I lived at as a security question. Literally anyone taking the time to call in and impersonate me already has all that info. 

I've found that there are some privacy services (like [DeleteMe](http://abine.com/deleteme/)) that will remove your info from as many sites as they can, but they only cover a portion of the number of overall sites that have that same info. Once the info is out there, it spreads between these sites like wildfire, and even if you request a removal from a certain site, they could easily just host your info again by saying it's new information that they got from a new source (so its outside the scope of your original removal request). It's why so many privacy services are subscription based because they regularly send in removal requests. 

Best route I can see is to close as many email/social media/etc accounts you can, make new ones with all fake information on them and allow that info to propagate out to these sites. It doesn't get rid of your old info and only makes your current info less reliable, but when it comes to addresses and phone numbers, even leaving the internet altogether won't help, since others will sell that info regardless. 

Then again, I've only looked into this casually, so (hopefully) there may be more effective ways to deal with all this.
I wasn't a marine, but googling stuff was a big part of my job too (IT). I'm assuming that's all he did. 

Seriously though, if you know a person's first and last name (or first name and age), and the general city they live in now (or their phone number, or an old city they lived in, or a college they dormed in) you can generally find everything you want to know about that person and their relatives. 

Including, but not limited to, current and previous phone numbers, current and previous addresses, arrest records, email addresses,  social media links, all the same info for their immediate family members, and more. 

There's hundreds of free services who offer up this kind of info without requiring any pay, so you can use one of them directly or use a Google search to often find what you want. Truepeoplesearch is one that had a creepy amount of info on my friend when I Googled her. 

Don't get me wrong, what the dude did was a creepy as fuck move, but people should be aware how easy it is to get this kind of info. Being able to get it, and doing something with it are totally different things though. 
You'd be surprised. Most of the PC scams out there are basically exactly like this. "Let me remote into your comp, or else it'll be destroyed by a nasty virus". 

Of course, you also have ransomware, which is the real thing, but that does the damage first and then threatens. 
Known as Mr. Swirl, Swirl, or Vico. I like the nicknames they have for him. 
As a prominent string theorist I can verify their claim. Adding extra dimensions to a problem will cause it to act in ways you wouldn't expect, which will likely solve the problem.

Make a 2D grate into 3D (like a dome) and the results could be fantastic in ways we can't predict. I can't explain why this works, if I was that smart I'd have written the unifying theory between general relativity and quantum mechanics, but I can promise that this will work.

You can trust me, I'm a scientist who does science.

^^^^^^(/s) 
Flip that sign around and it would be perfect for 2meirl4meirl.
This should be common sense, but nobody ever seems to exhibit any.

Never leave the house without a 50 meter weighted rope when going to the beach. 
Could be, but random things are abreviated in a lot of tech texts, and only work in that very specific context.

Like the textbook I was reading for one of my classes (I think it was Linux or wireless networking/security), they used MAC as an acronym for media access control, medium access control (osi layer) and later on in the textbook, mandatory access control. Definitely annoying to read since the first thing I think of when I see MAC is media access control (Mac address). 

But at least all of those MAC acronyms are for important technologies. Like you said, I dunno how often anyone needs to talk about a secondary storage device as an SSD. 


Yea, I ended up doing that for the rest of my troubleshooting (I ended up having bad ram and had to swap it around to figure out if it was the slot or the ram) 
Yea, I used to do that too. I still have a folder of minimalist or sci-fi/futuristic-art that I've picked up from imgur over the years, and while some are small, they look good on 1920x1080 screens, but not my current one. 

I'm always on the lookout for new wallpapers though. The stormtrooper is a pretty good mix for me though, with it's simplistic colors and added streaks to keep the photo looking interesting. 
For me a moment of pure panic was when I was installing new RAM, and the mobo made contact with the metal case behind it and shot out a spark. 

Shut down the PC, but I forgot to turn off the PSU :/
I'm guilty of using it too.

Searched for 4k wallpapers and then after like 2 hours, I was like "eh, fuck it, I got that one pic from PCMR".
So I only browse this reddit on occasion, but I'm definitely missing the point on this one.

Which one is the creepy one?
Hentai definitely works, cause there's no time for all this "cutesy" stuff when a tentacle monster is doing its thing. 

Happy cake day!
This is true. Back in the day, I used to pirate everything before I'd even consider buying it; especially if that software had any semblance of DRM on it. 

Now I'm too lazy to pirate, especially with the risks that come with downloading pirated software, so I just don't buy new software anymore (maybe a new version of MS Office and such every now and again).

I think the last time I bough software, it was the [Stablebit](https://stablebit.com/) applications, which aren't subscription based and are a great value for their price (and keep getting better over time).
Isn't that the app that was caught for installing a cryptominer onto your comp?

Are there any open source versions that don't have miners embedded in them?


True. I guess my pranks are a bit more benign. More along the lines of wasting their time (could definitely be seen as a dick move), but not causing them to redo any work they had already done, kind of thing. 
Well if they weren't in on it, it seems more like an asshole move than a prank, but could be. 
Well it's definitely fake. I mean, look at his trail of footprints. He had to have stepped up onto that 2-3 foot slab of concrete in order to start doing this skit. 

A normal person would have realized on that first step that it wasn't dried and would have taken a different way around, cause nobody wants concrete encased boots for the rest of the day.
Dude had to step up about 3 feet to get onto that wet concrete. I think he was pretty determined to get to where he was going and knew exactly what he was doing. 
GPU prices are sky high, but so is RAM.

I had to buy some RAM to replace a couple of bad sticks in my machine and it cost a little over 300 dollars for 2x 16GB sticks. My wallet is still unhappy about that one.
From a script I wrote last night: hashtable,col1,col2,col3,row1,row2,inputfile,inputfile2,inputquestion,inputanswer,inputhash,inputalgo,hashinputsource,computedhash,file1hash,computedhash1,computedhashpath,hashcomputed

And that's after I finished, went through and renamed everything to something slightly more manageable, so they weren't all named input1-input6, or "hashx". 
I never said he used sex slaves, I said he was friends with Epstein to give an example of the kind of wealthy and influential people Epstein met with and had supporting him. Bill and Hillary Clinton both addressed their relationship with Epstein during the campaign and impressed upon interviewers how shocked they were that he'd do such things. 

My entire point is that it doesn't even matter who had sex with those girls, because they'd never face any kind of justice. Epstein literally owned and abused underage girls, traded them to his friends and his punishment was to take a vacation at his estate in the Virgin Islands (an estate that he could leave anytime he wanted as long as he said it was work related, so we can't even say he was under any kind of house arrest). 
Even then, you only go to rehab if you're upper middle class. I grew up with folks who fall into 1%er status who have been caught multiple times with different drugs and nothing ever came of it (maybe a night in the drunk tank if they were driving). And that's as adults. Anyone poorer than them would have been kept in jail pending bail. 
I'm not sure that matters. I mean only if the public is made aware and crying out for some kind of justice will there be any kind of action taken and even then, the type of action taken depends on how rich the person is. 

Just see Epstein. He kept underage sex slaves that he let wealthy and influential people fuck (his friends being people like Bill Clinton, Trump, Prince Andrew, etc), and after literally doing some of the worst things a human could to another, he got off with a slap on the wrist (thanks to a non-prosecution agreement from the US attorneys).

He got 18 months of time that he spent at his estate in the Virgin Islands, and he was allowed to leave for work every day. 

Of course none of the others were even touched, even though Prince Andrew was directly accused by a 17 year old who was given to him by Epstein. 
I don't own any guns, but having a few friends who are all about them, this could be quite handy for gifts. 

And one can never go wrong with some deals on clothes.

Thanks.
Huh. I need to start a multi for deals/savings reddits. I didn't know many/any existed outside of r/buildapcsales
I had a second gen ipod, which was a giant brick, but it failed just after a year or so of using it and Apple support didn't help at all with it. So happy I went with Zune. The Zune 30gb and the [Zune HD](https://i.imgur.com/hbHHSm7.jpg) were amazing devices.

I came across my old Zune HD a couple of months ago, and I was surprised how fantastic it still looked, even compared to modern smartphones.
It's nice to think that there might be money in my account whenever I'm not checking it. 
Because it's always amusing when Alexa returns results that are inappropriate for the family room.

Plus it offers valuable insight into what Alexa is all about before the date even starts. 
*should have not could of 
If it's fast food or gas stations, I usually just ask if I can place the phone near CC swipe slot. 

If it's a sit down restaurant, I always use a normal credit card.
[Hand made in USA](https://www.youtube.com/watch?v=mEG-X_UbNuA)
Depends on how they go about it, but if it's just a backdoor that's flashed to the chip, then it's quite likely that the manufacturer never discovers that there's a backdoor in the code. Since they only manufacture the chip, and don't actually design it, they have no obligation to review the code or understand what they are flashing onto it. So the responsibility of understanding the code and making sure it works would rest with Qualcomm. 

If it's a hardware backdoor and the manufacturer does discover it, I doubt much would come of it since I'm sure normal supply chain contracts prevent them from disclosing detailed information/specs of the product to others. If anything, they might secretly leak info to some agency and let that agency go public about the discovery. To avoid losing business, I'm sure the manufacturer will avoid any situation that links them to leaking that information. 
No need to hope. Memes are one of the most stable aspects of our society, and make for the best currencies.  

[Video to back up my statements.](https://www.youtube.com/watch?v=WYI87MMB9Xg)
I was pretty straight up with my roomates. I told them, we could switch utilities and they could pay for our 65/month internet plan, and the gas (also consider it's winter right now, so heating is important), or they could continue to pay the electricity bill, knowing that the price of the bill would go up by up to 25 dollars per month. 

They said they'd rather pay for electricity, cause they can do basic math and know that it's cheaper to pay electricity than the other utilities. 

But even still, I'm not using a computer from 2002 to mine. I'm using a GTX 1070, which is why I'm making a profit of about 3-4/day on average (again this is in the current market, so it's half of what I was making a month ago). If you're using a computer from 2002, and your electricity costs are .12 kw/h, then I can see why your 'average computer' estimate is so high, and why you think it's not possible for someone to make a profit while mining. 
They aren't doing it for free though. They're being paid by their currency being used to purchase rides. Basically, when the company first reveals their idea, they also reveal their cryptocurrency (lets say they called it TaxiCoin), and they'll keep a portion of the total coin supply to themselves. Right now, TaxiCoin is worth nothing. Next they open up the coin to some initial investors, or open it up directly to the public market. If their technology sounds promising, and achievable, then people will buy in early while TaxiCoin is worth very little in the hopes of getting rich as the technology gains popularity. All these people buying in early could cause the coin to raise in value from 0.00 to being worth a few cents, but even just raising a few cents could be very rewarding to the devs, depending on how many of those coins they kept to themselves. 

Once they release their fully finished application to the public, and normal people start using their product, then they'll start to get rich quite quickly. When normal people start using the app, the app will have them purchase TaxiCoins so they can pay for rides. This means the demand for TaxiCoin, and the daily trading volume of these coins will skyrocket. Maybe each TaxiCoin will go from being worth a couple of cents, to being worth a couple of dollars. And this could make the devs rich enough that they can retire comfortably if they wanted to. Or they can continue to improve their product, get more people to use it, and watch the value of their coin continue to increase and get richer still. 

Lets say that they've been charging a 10% fee on top of all of this and people have been willing to pay it because they were the first to the market with this app/coin. Not only have people been buying TaxiCoin to pay for rides, but 10% of their payment for that ride went to the developers. Well, there's likely to be some competition and the easiest way for the competition to undercut these folks is to introduce their own coin and say their rides will be fee-less. If you use this new company's app (which has you buy CarCoin in order to pay for rides), then you won't have to pay a fee on top of that (so riders save 5% and drivers make 5% more money because there's no fees). This is one of the easiest ways to undercut the competition, but this company would be willing to do it, because they kept a huge amount of CarCoin to themselves, so the more people who buy into CarCoin, and cause the value to rise, the richer this new company gets. If there's a bunch of companies, all of whom are offering fee-less rides, then the only way they get richer is by making a better product (maybe the app is easier to use) and attract users to their coin that way. 

If you look at this from a traditional tech startup viewpoint, then this model doesn't work. The equivalent to cryptocurrency is the stock market. If your company paid it's employees entirely in company stock, and then people bought into that stock because they thought the company had value, then those employees will get quite rich. But it doesn't work this way with startups because you can't be listed as a publicly traded company right from the start. So the way startups go about this is to get money from private investors. The only issue is, if they said "we're gonna make an app that doesn't charge any fees" no investor would give them a second glance, because they basically said they have no way to make any revenue. They don't have stocks that people can buy into and trade back and forth, or make people buy their company's stocks via their app, and they aren't charging a fee, so there's no reason for investors to buy in.

That's not a problem for cryptocurrency companies. From the very start, they're letting people buy into their company (via their coin) which helps pay the developers, but also pays back the investors when the technology takes off and starts to attract more users.

Sure. So, two resources I suggest you check out are [What To Mine](http://whattomine.com) and [CryptoCompare](https://www.cryptocompare.com/mining/calculator/eth?HashingPower=31&HashingUnit=MH%2Fs&PowerConsumption=362&CostPerkWh=.10&MiningPoolFee=1). What To Mine will give you info on hashrates for different algorithms for whatever GPU you put in, and give you some info on what coins might be most profitable for you. Take that hashrate info and you can plug it into CryptoCompare to see how you'd fare mining a coin like Ethereum (which happens to be the most profitable coin for my 1070 at this very moment). Most pools charge a 1% fee and both sites have a place to type in your cost per kw/h, so that'll help you decide whether you'll make a profit or not. 


The application I use is AwesomeMiner (I use the free version), and the site (pool) that I have it linked up to is MiningPoolHub. You set up a username and stuff, and you use that to set up AwesomeMiner (I can go into more detail for setup if you want). On MiningPoolHub, you set what currencies you want to keep, or if you want you can have them all exchanged into a currency of your choice. Once you've got all that setup, then you just double click on Awesome miner when you want it to run and let it do its thing. 

Another thing you'll want to set up is a wallet to be paid into. There's a few ways to go about this, and it depends on the currency you want to be paid in. There's lots of options, for Ethereum, one of them is [MyEtherWallet](https://myetherwallet.com/). After recieving the money in your wallet you can send it to an exchange (like Coinbase) and have it transferred to your bank in dollars. Another option (not positive if this works with MiningPoolHub or not) is to set up an account on an exchange like Coinbase, and have the pool send your coins directly there. 

Either way, it sounds more difficult than it is. I spent months sorta looking into mining but never pulling the trigger cause it sounded complicated, but it's not that bad and once you're past the initial set up, there's nothing to it. 
Gotcha, yea, it's fine. I'm just disappointed I did a poor job in getting my message across. 
I guess in my attempt to try and convey the benefits of using mining to my fellow gamers, as a way to make some money from the (likely) higher specced PCs that they have, I might have come off as a jerk who was bragging about making money.

Which wasn't my point at all. The point I wanted people to get, is that miners who buy 10 GPUs aren't the only ones who deserve to profit, and everyone else shouldn't be content to just get stuck with higher GPU prices. Unless electricity is expensive in your area, you can play the game too and use a GPU to make some money back and maybe afford a better PC, pay off your textbooks, save it for a rainy day or a car repair or something. 
I literally have 1 GPU in my household (which is probably on par with most people here). I bought it so I could play games and run VMs (which didn't pan out as nicely as I had wanted it to). Nothing I've done has contributed to the increased prices of GPUs, and I'm as bummed as everyone else by the price hikes in GPUs because I need an AMD GPU for my homelab setup (cause AMD GPUs don't give a code 42 error when you run a VM); and there either are none available, or they're 500 dollars over the MSRP. 

My point wasn't about how rich I'm becoming with my one GPU mining operation. All I was trying to convey is that people should play the same game that miners already are, which is to make money off of mining when you're not using your PC. 
I don't pay for electricity in my current living arrangement. I've discussed it with roomates, but I've already been paying for the gas and internet, so they're fine with it. 

I had to benchmark my system at full load on the GPU and processor (~360w), since I do a lot of data heavy work and needed to buy a UPS system that can handle that wattage to prevent data loss. Knowing that, I should still be making about 70 bucks a month in profit, on average, if I were paying the electricity bill (.1/kw in my area). 

And that's calculated using the cryptocurrency prices that we've been seeing recently, which, as everyone has been pointing out, is in a lull/decline. 
Various currencies, but since it's mining when I'm not using my PC, I never really check or know what it's mining at a given moment. The application I use took about 2 minutes to set up, and it figures everything out for me. Nowadays, I just double click on the application to open it, turn off my screen and it'll figure out what is most profitable to mine on my hardware. After a certain amount of time, it'll re-evaluate whether that coin is still the most profitable to mine or not. The mining pool that I'm a part of will take all those random currencies that my computer mined and exchange it into a single coin I want to be paid in (in this case, I chose Ethereum, because I like to support platforms that have a practical use beyond being a currency or a store of value). 

My current system was a homelab type project that I built with a threadripper processor and a GTX 1070 in it, which set me back a pretty penny, so I'm eager to recoup the costs (and I am, slowly but surely). Of course using a TR system is about as terrible a move as you can make when it comes to mining, but luckily my electricity costs are near 0.  

I know my earlier comment got downvoted a lot, and I know that it sucks that GPU prices are so high, since I've been in the market for an affordable Vega 64 for months now (because Nvidia cards don't play nice with VMs), but mining is like getting free money while I'm asleep. 
It's the blockchain technology that enables this. Public ledgers + smart contracts allow for people to perform trustless (as in, no need to trust anyone; whereas with centralized institutions, you're placing all your trust in them) transactions with eachother. Before I get into it, I want to point out that I'm writing this off the top of my head (and I'm not a developer, so I won't think of every scenario that needs to be handled), and there are many people here, who I'm sure are much more familiar with crypto technology and can explain this better than I ever could. 

If you were to build an app like that today, and stuck it up on Github (open source, of course), and it catches on like wildfire (doesn't dwindle into obscurity), then you'll likely still need to have entirely centralized portions of your service, because you'll need some services (like Paypal) to help process payments and settle customer disputes. 

With a public ledger, you can ensure that everyone can audit the entire ledger at any time and verify who has been paid and when (using anonymized wallet/tokens and not actual people's information). This can help because it allows for smart contracts to be established within your application which dictate when payment is done, when it isn't necessary, or when only partial payment is required. If the data in the ledger indicates that the person got out before their stop, then they could pay less than the original estimate. 

Another thing is that any company or app like this will have substantial overhead if it's done the way traditional silicon valley startups are done. That means, they will need to comply with payment industry standards (PCI), undergo formal security audits (which are never free), do background checks on their potential drivers, and secure sensitive data like social security numbers and more. This means that to clear all these barriers, the development company will likely need to seek out investors and funding (to keep them going during initial development), whom they will then be beholden to at some level and at some point down the line. At the same time, finding investors will be difficult, because nobody wants to invest in something that is fully decentralized and doesn't take a cut of the profits from each ride. There's no incentive there for anyone to invest. Kickstarter isn't an option, since nobody is going to donate on a regular basis (possibly for years or more) to keep a company afloat while they build their product.  

With a company that leverages a cryptocurrency, they can essentially pay themselves, and how much they make will be entirely dependent on how well their product does. They tether their project to a token/coin, and then buy/save some reserve of those coins for themselves while the rest is left on the open market for others to buy into. This acts like stocks essentially. Everyone and anyone can buy in, and during the early years, the people who will buy in are the folks who have read the whitepapers, or researched the dev team, and believe the project can be a success (or at least see the potential to make money from it). Those people buying in causes the coin to rise in price which can keep the company afloat while they build their product (you see this happen all the time in crypto as it is, and sometimes this can lead to scam artists getting rich quick). If their service takes off, then people will start buying and trading that coin on a regular basis as they will be using it as a way to enforce smart contracts and also render payment for the services they were given (ie a ride). That leads to a huge explosion in price and the developers are sitting pretty happy with X amount of a coin that was worth nothing initially, but is now worth a lot more. Or none of this will pan out, they'll crash and burn and someone else will pick up the ball. A good example is the decentralized cloud storage industry that is building up and growing right now, courtesy of blockchain tech and cryptocurrencies to enable peer to peer payments and storage in a trustless fashion. 

Since the developers in this scenario aren't beholden to anyone, other than to make their product as good as they possibly can in order to increase their own wealth, then they can set up a fully decentralized network to allow transactions to take place with a 0% fee; because they simply don't need the fee. If they do charge a fee, then someone else will come along and unseat them by charging less or nothing at all. We're starting to see the same thing happen with cryptocurrency exchanges. The biggest and earliest ones had high fees to trade one crypto into another, but now there's more coming out that are decentralized, and with some of the platforms that are being built, there should be some that will move towards fee-less transactions and trades. 

Another aspect to consider is that since their payments aren't being done through credit cards, or Paypal; and everyone has a crypto wallet (which allows for accountability and anonymity, meaning people's real info never needs to be stored anywhere), they don't have to go through all the work of storing social security numbers, names, numbers, addresses, going through PCI audits/compliance, or any of that. People here are paying eachother directly with a cryptocurrency, the devs aren't taking a cut, and therefore none of these drivers can be considered their employees in any way (so no need for the devs to collect or directly handle anyone's personal info, ever). This is the part I'm not sure how it works (I'm not a blockchain dev), but Oracles can handle the passing of information from outside entities (like car insurance companies) to the blockchain to handle potential issues in that regard. This could be some sort of simple 'yes/no' affirmation of whether the driver associated with X wallet address has kept their insurance up to date or not. 

I'm sure there's a lot I missed and didn't think of, but those are some of the ways I think a company leveraging blockchain technology will differentiate themselves from those stuck doing it the old way (which can't truly be decentralized). 


I was honestly tempted. I've been in the market for a new GPU for a long while now, but the prices are just too high for me to justify right now. 

I think I'm gonna hold off for a while until the next gens come out and see if I can get one early, before anyone knows if it's good for mining or not. 
I used to be in your boat, but I'm paying off my entire system by letting my pc mine while I'm not using it. 

I'm not a miner, I never purchased a single part with any intention of mining (my rig is incredibly poorly designed if it was meant to be used for mining), but I honestly don't understand why other people don't do it. It's less stressful on the hardware than constant temperature fluxes from normal gaming (except for the fan, that will likely wear out if you plan to mine for years on end), and you're literally paying off the expensive hardware you just bought. 

I'm not saying folks should buy a 1070 at $1000, because that's insane, but I got mine at 450 dollars back in September, and I've paid that card off. I'm just working on paying off the rest of my PC/server now. 
This is something that doesn't get said enough. 

But going beyond the coins that act as a simple currency, there are a lot of cryptocoins out there (well companies) who are solving real world problems by leveraging blockchain/public ledger technology. 

People hate on cryptocurrencies, but the tech is going to a lot of good for society as a whole, because it enables an entire new way of developing applications and providing services. You can make a decentralized Uber (so there's no Uber company taking a massive cut), and allow people to pay eachother directly, meaning cheaper rides all while drivers getting more revenue. 
I checked a week back (I think?), and I saw 1070 prices so high on Newegg, that it was almost cheaper to buy a prebuilt system with a 1070 in it, than it was to buy the card by itself. 

It was like 800-900 dollars for a single 1070, but the prebuilt system was going for around 1100-1300 dollars. 
First time I saw it was 2013. The image has been in use forever, any time there's a bubble and crash. 

I've lost track how many times wealthy/famous people have said that this crash would be the end of bitcoin, over the years. 
People have been posting that exact same image a few times a year since 2013 and always claiming that this crash will be the end of cryptocurrencies. 

Do a reverse image search on it, you'll find plenty of old sources for it. It's probably been done earlier than 2013 (back when bitcoin was crashing down to 100 dollars), but that's just the first time I saw it. 
Reimage: The go to, fix all, solution (or it does the trick most of the time).

When I worked level 1/2 support, I loved that most of the computers we had deployed were shared workspace computers, so there's usually no custom software (that couldn't be pushed) or personal files, which meant a reimage was always an option to fix an issue. 
I can't tell you about the profitability of older chips, but you could run benchmarks on those CPUs, plug the hashrate numbers into a site like whattomine.com, and calculate how much money you'd make. Depending on how you want to mine monero, there's a few different options for what kind of mining application you can use, and how to run the benchmarks.

While it's probably not the best option for mining, NiceHash is an easy way to get into mining. Basically you download their software onto your PC, and it has a GUI interface to help you run benchmarks and can auto-select what currency to mine on your machine based on what performed well. NiceHash only pays out in bitcoin though. 

As for watching your mining rig, you don't really need to. Once you've got it set up, you can just leave it to do its thing and maybe check up on once every now and again. I had an older PC that I usually let run for a month or two in between checking in on it. 
Yea most of the street vendors in India pour their tea like that as well. Not always so high, but you see it done just about everywhere in South India. 
I'm not talking about racism at all. I literally said I agreed with them that saying something like that can't be used to label someone as racist.

I posted a comment because I felt "criticize" is entirely the wrong word for someone who prays for someone else's death.

I'm critical of Congress's tax plans, but I'm not actively praying for their deaths. That's more akin to outright hatred (again, not necessarily racist hatred, just normal hatred). 
I agree with you that it isn't proof by itself, but praying for someone's death seems like it's a step, or two, beyond simple criticism. 
I did the same. If there wasn't a comment, I was gonna post this video, but really, same diff. 

https://youtu.be/_iZwVRJrfiA
Hawking radiation was primarily used to solve the information paradox, right?

If white holes exist and work the way that some people in this thread speculate that they do (ie as exit points for the energy/matter falling into a black hole), then Hawking radiation theory wouldn't be necessary? Information wouldn't actually destroyed, it just ends up someplace else.
Crazy. I was looking on Newegg and its almost exactly the same price to buy a single 1070, or buy a prebuilt system with a 1070 in it. And that's without any shopping around or browsing, just looking at the first results when I searched for gaming desktops.

Gigabyte's external graphics card enclosure that comes with a 1070 is a few hundred bucks cheaper than a 1070.

It's getting to the point where it'll be cheaper to buy a whole new desktop and just cannibalize the parts you want.


I don't know about you, but I've used it on occasion when I needed to bring something up quickly. I usually have the assistant set to mute anyways, so it's no louder than I would be if I were talking to my phone normally.

That being said, I still don't like using assistants in public because people don't need to know that I'm searching for directions or resturant hours. 
I have to agree. My experience with the Pixel was very limited, but I didn't see a difference in performance between that and my Note 8. Loading apps, switching tabs, swiping, typing, gestures, they both seemed equally smooth to me.

I even tried sticking videos and other apps in multi window to see if one of them would outperform the other.
Ah ok. That makes a lot more sense. I couldn't imagine Amazon listing it at these prices in the current climate. 
I just checked Amazon for Vega 56 and top two results are air cooled Vega 56s for 1000+. The rest of the results are 580s for 600+.

You are one lucky SOB.
So he sucks at hitting reporters and sucks even more at hitting trees.
Ah ok. That makes sense, thanks. 
That's what I thought too! It all makes sense now!
Damnit, all the comments in here are about her being vegan, and I'm only here cause I don't get what the secret message is.

Someone tell me what she meant by "Let me know if you read it". It's not the first letter of every line, and it's not all the capitalized words in a sentence.
That's odd. I can send and receive, but I can't view gifs that people send me unless i download the photo and view it in another application. In messenger lite, it looks like a still image until I download it and view it elsewhere. 

In normal messenger, I can send videos and other stuff as well, but with messenger lite, I'm limited to gifs that are smaller than ~10mb in size. 
Definitely still exist. My grandparents run Windows 10 + Chrome, and chrome auto-updates itself as it needs to.

Still, every now and again, I'll see their chrome loaded up with add ons, toolbars, weird ass start pages, etc. 
From some googling, it seems that the rubber duck floating on water/beer was a modification of the Mywater app released by Asus on the Google Play Store.

I tried installing a rubber ducky app/mod that I came across, but it didn't work since I think that was originally created to run as a system app on an Asus tablet. 
I think that's a fair price for the product, but it's not really 300 dollars off (Amazon is tricky like that). It's been retailing around [560-580 for the last 2 years](https://camelcamelcamel.com/Buffalo-TeraStation-Desktop-Drives-Included/product/B00Q7VC7R0), so 515 sounds about right since Newegg has it listed at that price too. It likely breaks down to about ~280 for the 4x 3TB drives, and 235 for the NAS itself.

Reading through the Amazon reviews, it looks like they don't officially support any drives larger than 4TB, so it might hamper your future expand-ability if they aren't upgrading the OS to support larger drives. I don't have experience with Buffalo products, so I'm not sure what their OS/product support is like.

Personally, I think it's best to buy your storage and NAS separately, and I'd go with something like the [DS418j](https://www.amazon.com/Synology-DS418j-4bay-NAS-DiskStation/dp/B074VB8DY7?th=1) from Synology, but only because I know they officially support for larger drives (they updated my DS916 from officially supporting 10TB drives to 12TB drives), and their customer support seems to be pretty decent (in my experience). 

There's cheaper NAS systems out there than what Synology and Buffalo offer, but their OS/product support and such may vary. Most cost efficient route would probably be to grab an old desktop and optionally stick [one of these in there](https://www.newegg.com/Product/Product.aspx?Item=9SIA2F83UC8058&cm_re=hot_swap_bay-_-17-994-155-_-Product), or build a new desktop [in a NAS case](https://www.newegg.com/Product/Product.aspx?Item=9SIA8T937D5953&cm_re=nas_case-_-9SIA8T937D5953-_-Product), put a bunch of drives in it and use an OS like FreeNAS. 
Nope, sounds like it would work fine. Given your usage plan for the external bay, it sounds like archive drives (like shucking the [Seagate Backup Plus](https://www.amazon.com/dp/B01HD6ZLQ6/ref=cm_sw_r_cp_apa_mAxvAbFRRB2RQ)) should work well for your purposes.

And since you aren't using raid, you definitely could use both archive and normal drives in there too (whichever is cheaper). 
Is 76 Tron a normal transaction/withdrawal cost for Tron?

I tried moving my Tron out of Binance a week ago with a 30 Tron transaction fee, and Binance cancelled the transaction (no idea why). Today, I looked at doing that and the withdrawal fee is 76 Tron, which comes out to 10 dollars. Is this normal? Should I wait and see if the withdrawal fee goes down?
When it comes to shucking, it's not really much of an issue when it comes to performance/reliability. What does matter is the drive inside it, and some external cases are very difficult to take apart without damaging anything. 

Some external drives have archive drives (SMR) in it. These are best for a, write once (or write rarely), read often, type of situation. When they're in external cases, they're usually called Backup drives. This might work if you plan on storing your data on it as a backup and don't plan to change the data often once you fill up the drive. 

There's a post on this reddit right now about a sale on 8TB WD EasyStore drives from Best Buy. These contain WD Red or White drives, which are optimized for Nas type storage (basically they're optimized to be able to run 24/7). These are easy to shuck and they aren't archive drives and should be fine for your usage (video, photos, etc). 

In regards to the case, if you stick 8 drives into the case you linked, it'll show up as 8 drives on you computer. I've had that Mediasonic case for about a month and it works well for me. I put in all my drives (4tb, 6tb and 8tb drives) and used Stablebit Drivepool to join all of them into a large pool. I also have it set to 2x duplication. So I should be able to lose any single drive and be able to recover all my data without issue. I also hid all the individual drives (in windows), to keep it from cluttering up my computer. 

One thing to look out for is that some drives are odd about encryption or things like that. Like the WD My Book Duo, it apparently had some kind of custom Raid/encryption that prevented people from accessing their data when the drives were outside of the case. So I'd buy some of those WD EasyStore drives, put them in the 8 drive bay, and copy all your data over, so you have a backup, just in case something gets messed up when you're shucking your drives. 
Did it just not turn on at all after being left off for a while? Did Samsung send you a replacement or anything? I bought a tab s3 recently after my Nexus 7 died and now I'm a bit concerned. 
To be fair the 3ds is incredibly different to a smart device. I left mine off for more than a year and didn't seem to lose more than a single percentage point of battery (according to it, anyways).

The iPad on the other hand, echos my experience with them as well. They have insanely efficient standby battery, and Apple does appear to keep a decent amount of battery in reserve for their devices as well (which helps with allowing it to reach "0%" and come back to life without issue, weeks/months down the road).

Just FYI, Apple sources its batteries from Samsung, and Samsung gets its batteries from Samsung; so there's probably more to it than just the quality of materials used. 
I've run multiple RAID types, but the only ones I've had to rebuild and expand are RAID 5s because they hold most of my data. I know about the URE debate and I would move to RAID 6 if I could afford the space (I probably will if I get around to buying/building a rackmount system/server).

My Synology NAS is running SHR1 (~Raid 5) on a set of 4 disks (which I've expanded twice) and a set of 5 disks (which I've expanded 4 times, with 1 rebuild from a failing disk). I also do monthly RAID scrubbing to try and avoid a URE type situation.

While I'm trying to move away from it, Drobo has to be one of my favorite RAID setups (I've had one in near constant use since 2012 on a RAID 5 equivalent). It's super simple, you can mix and match any sized drives while getting the max space possible, shrink and expand the array without needing to worry about rebuilds, scrubbing, or defragging since it handles all that automatically. I've lost count of how many times I've expanded and shrunk my Drobo, but it's well above a dozen times (never had to do a rebuild for a failed disk though). 

One thing I particularly like is how shrinking is as simple as ripping out a disk and (optionally) putting in a smaller one. My parents have a drobo (since 2009), and after de-duplicating a lot of the data they've been backing up over the years (from 5TB down to 800GB), I kept ripping out disks and letting it rebuild overnight until it went from being a 5x4TB array, down to a 1TB+1.5TB+2.5TB.

--------------------

As I'm sure you know, RAID isn't a replacement for backups in any way shape or form. While I know that it's not easy to follow this advice, especially when your budget is limited and you have a lot of data to store; I'd say that any setup you can manage that has backups will be better than a setup without any. 

Right now, I'd say that 80% of my data is backed up in some way, locally. My NAS is partially backed up to my Drobo and to a few external drives, while the unique data on my Drobo is backed up to an 8 bay system that is running JBOD with Drivepool to ensure it maintains 2x duplication.

In regards to costs vs backup space/setup, I'd skip using enterprise drives (ie WD Black), and stick to using WD Reds or Ironwolfs. As I understand it, the main difference between consumer and enterprise drives comes down to the firmware settings and the length of the warranty offered. 

When it goes on sale (and it frequently does), buy a bunch of those 8TB external drives from BestBuy (which usually have Reds or whites) and shuck them for use with your set up. There's a lot of threads in datahoarder about the sales and shucking them. 
Sure no prob. And in the event you ever want to use comodo in the future (or if you're still having issues with blocked sites), I think I might know why you're getting blocked sites. When I installed Comodo firewall, it asked if I wanted to use Comodo's DNS servers. I always uncheck that option, since I use different DNS servers, but if you use Comodo's, I think it would block sites that it determines has some kind of malware/phishing/etc. So that could be the issue.

Or it could be the VPN provider as well. Some of them block ads/malware sites by default, and in PIA they have an option called PIA Mace to do that.
2 different people linked me the original of that graph, trying to convince me to sell everything I had. Both of them said I was in the 'denial' phase, but then again, everyone thinks you can apply normal investing logic to cryptocurrencies without knowing anything about cryptocurrencies.

I like this version much more.
Huh, I never messed around with the website blocking thing, but I haven't had any issues yet.  

And yea, sorry, if I knew you only wanted to use it for qbittorrent then I would have suggested limiting it to a specific interface. I have the same setup for qbittorrent. 
Ah ok, gotcha. 

Yea, I just used a random password generator that I had on hand.
I didn't have that issue with it. I used Defender to scan the exe before install and the iota folder after install.
How should one generate their seed? I thought it was ok with anything as long as you used the number 9 and letters, or something.
Yes, but it's the difference between direct control (literally deciding the interest/inflation rates to suit the very few who control the dials) vs influencing the market with their wealth (buying/selling). It might seem arbitrary, but the important point is that bitcoin operates on a global scale (no federal reserve controlled by a group in one country) and there are a lot of wealthy people with different goals. 

What benefits the exceptionally wealthy on Wallstreet, will not necessarily benefit the wealthy/corporations in a different industry. People in different regions will have different interests, and let's not forget corporations and governments, both of which have a lot of money to throw around and have their own goals.

Cryptocurrencies aren't going to solve the massive inequality we see in the world, it'll just keep a few key players from having direct control over the currency itself. They might be a part of the equation to solve excessive inequality (there could be projects involving blockchain tech that help), but it'll primarily be up to society to reexamine what it values. 
Eh, if you wanna cash out now, it's not a big deal. Many people (myself included) would still make an absolute killing if we were to cash out now; or even if it kept dipping.

But bitcoin was never meant to stop insider trading, or anything like that. It was created so that no one entity could arbitrarily decide things like inflation rates/currency printing/etc; because things like that can lead to an economy that only truly serves a small, but powerful group.

There'll still be insider trading, wallstreet sharks looking to make profits, fraud, hacks, etc with bitcoin and cryptos. It never weeded out the scumbags, they were always going to start coming in droves once cryptos gained mainstream attention, it only stops the biggest of scumbags from profiting off of their mistakes by influencing monetary policy. 

The way I see this is that it's just another phase of cryptocurrency's growth towards mainstream legitimacy. There'll still be kinks to we worked out, and things like decentralized exchanges will help with reduction of fraud/insider trading (like the kind we saw at coinbase).
I'd say that I got a very different impression from researching Cardano. Maybe we're talking about different coins entirely. I think it is a decent project that shows potential, and Cardano wouldn't be on the map for most people if it wasn't for people pumping the coin because it's easy to push onto others when you can point to their dev team as proof that the coin could be worth a lot someday; but I fully agree that it's massively inflated, which is worrying and annoying to me. I had hoped it'd spend the first quarter of 2018 staying off of people's radar. 

You're right that they don't have any of the original bitcoin devs, but they do have a [co-founder and core developer of Ethereum, Charles Hoskinson](https://web.archive.org/web/20140302035654/http://blog.ethereum.org/2014/01/23/ethereum-now-going-public/). You can like him or hate him (and it seems people are very split on that), but it'd be absurd to say that someone who helped in bringing the Ethereum project to life, knows little about cryptocurrencies. Unless you meant long time cryptography experts, because they have people who literally have their masters in cryptography (and the teams they've worked with, [plus their research papers are available online](https://scholar.google.com/citations?user=sxdob7UAAAAJ&hl=en)) and the teams at IOHK put their papers up for peer review with a [couple already accepted so far](https://www.forbes.com/sites/amycastor/2017/08/23/at-crypto-2017-blockchain-presentations-focus-on-proofs-not-concepts/#4a34b8117b70) (and this approach makes sense since the research was done in [collaboration](http://www.businessinsider.com/iohk-sponsors-blockchain-research-lab-at-the-university-of-edinburgh-tokyo-tech-2017-2?r=UK&IR=T) with two [universities](https://www.titech.ac.jp/english/news/2017/037573.html). Saying they don't have crypto experts is quite the opposite of everything about this project, because their papers are about proving their implementation of proof of stake picks up the slack where others are vulnerable to attack. And you don't do peer reviews on a vague concept, which is most cryptocurrencies offer, these are actual proofs submitted to conferences related to cryptography and security.

Anyways, I can understand the issue when it comes to their looks since some industries put a lot of value on looks and presentation. Seeing people from various walks of life in the tech industry is something I've gotten used to, where some people look young enough to be fresh out of highschool, some dress poorly and wear ragged/baggy clothes, and some are old enough to have retired a while ago (actually someone I worked with used to be a doctor for quite a long while before they left that profession and dived into their passion which was coding). Defcon is absolutely great at that kind of thing, cause you see security experts from all over, and age and looks can be very misleading in regards to what they know and the position they hold (professionally). But, I fully understand where you're coming from with the concern that they might look young or like 'used car salesman'.

Either way, I just hope you didn't miss out on investing in Ethereum because of how Vitalik looked/dressed/acted, because I know that he looks pretty damn young and doesn't always dress in the [most professional manner](https://tctechcrunch2011.files.wordpress.com/2017/09/vitalik-buterin-147a2578.jpg), but he's still great at what he does.

Edit: Grammar.
I actually use youtube-dl to accomplish exactly what you're talking about. I run it manually maybe once every few months, but only cause I don't need the videos right away. I use a config file to keep life easy for myself, so I don't have to remember what to type or what channels to rip.

To run it, I just enter the following command in CMD: 

    youtube-dl.exe --config-location config.txt

And that's all I need to type to run it. I have an example of my config.txt file below.

My youtube-dl.exe file is in a folder with my config.txt file along with a file called "channel_list.txt" and 'ffmpeg.exe' (which you can google/download). When you rip in the highest quality possible, youtube-dl needs to use ffmpeg to merge the audio and video back together, since youtube stores them separately. Youtube-dl will create a file called "downloaded.txt" which keeps track of what videos it can skip in the future. If you want, you could directly copy and paste the below into your a text file and use these settings yourself. Any line that has a # in front of it will be commented out and ignored by youtube-dl. 

    #keeps a list of every downloaded video to prevent downloading the same video twice when re-ripping a channel/playlist list. This works pretty well
    --download-archive downloaded.txt
    
    #ignore errors for videos that can't be downloaded (ie deleted/copyright claim takedown, etc)
    -i
    
    #This creates a folder called "Videos" next to the youtube-dl.exe file. The video file has a name that contains the upload date, title, duration, and resolution; and it will be stored in the path Videos\Users\(channel name)\
    #To use playlist titles instead, just replace %(uploader)s/ with %(playlist_title)s/  
    #ie: "Videos\Playlists\%(playlist_title)s/%(upload_date)s - %(title)s - (%(duration)ss) [%(resolution)s].%(ext)s"
    -o "Videos\Users\%(uploader)s/%(upload_date)s - %(title)s - (%(duration)ss) [%(resolution)s].%(ext)s"
    
    #uses the best video quality possible, downloads it in mp4 if available.
    #using the best possible quality requires keeping ffmpeg.exe in the same folder as youtube-dl.exe (or telling youtube-dl where ffmpeg is).
    -f bestvideo[ext=mp4]+bestaudio/best
    
    #downloads all the channels listed in the channel_list.txt file, 1 user/channel per line. You could put playlists in here too, but I have a different config file i use for playlists.
    --batch-file=channel_list.txt

    #No overwrite of older videos with same names
    #I added this here in case you'd rather use this command than keep a list of your previously downloaded videos in downloaded.txt.
    --no-overwrites
    
    # Write metadata to the video file
    --add-metadata
    
    # Write video metadata to a info.json file
    --write-info-json
    
    # Save video annotations to a .annotations.xml file
    --write-annotations
    
    #Download all available subtitles
    --all-subs
    
    # Write the video's description to a .description file (basically plain text file).
    --write-description
    
    #Save the youtube thumbnail photo
    --write-thumbnail
    
    #More detailed output to the CMD screen of what the application is doing
    --verbose

In my channel_list.txt file, anyone with a channel/username in the URL, I write as "ytuser:channelname". Everyone else, I put the full url. Example of my channel_list.txt file: 

    ytuser:LinusTechTips
    ytuser:h3h3Productions
    https://www.youtube.com/channel/UCd1fLoVFooPeWqCEYVUJZqg
Haha, sounds good.
Sure no problem. 

With the VPN enabled, are you normally able to connect to Plex from outside of your home? If you can't, or have an indirect/bad connection, then it might be a port forwarding issue, which is something you'd need to enable in your VPN client. If you use PIA, [then you can follow the instructions here to enable it](https://helpdesk.privateinternetaccess.com/hc/en-us/articles/219460187-How-do-I-enable-port-forwarding-on-my-VPN-). Once you enable it, remember to configure your Plex server to use the correct port number for outgoing connections. 

If you are able to connect to Plex from outside your home network while your home computer is connected to VPN, then I'm not positive what the issue is. You shouldn't need to apply any special rules to Plex in Comodo, so it should continue to operate as it always has. I guess an option would be to check the 'network intrusions' log and see if it's blocking incoming/outgoing Plex related traffic. You should be able to get to 'network intrusions' from the main Comodo screen, you might need to click on "advanced view" in the upper right corner. 
Well if the prices are cheap, or prices haven't gone up yet (and I know they will cause of something in the news), then yea, I fill up the tank entirely. 

It's only after the prices have gone up that I avoid filling it up fully. In my area of the midwest, when an event (like I described above) happens, prices go up, but quickly hit their peak and stay there. Once the supply problems are resolved, they go back down just as quick. 

Of course, if we're talking about OPEC nations starting to hold their reserves in order to drive prices up, then that's an entirely different issue and prices could easily continue to rise or be unpredictable. In those cases, I just operate as I normally would, filling up the tank fully when I need to.
Most of the time, the only reason I don't fill the tank is if gas prices are sharply increasing. And when they do, it's usually for a random/temporary reason...like a pipeline broke, or some refinery blew up, kind of thing. 

So if I can only take a bit of gas and make it on that, then I can fill up fully when prices go back down again. 
Is there a big difference between the two? 

I remember briefly overlooking a thread about the differences, and remember seeing something about power differences between the two, or something like that? 

I have 2 NESN drives that I haven't taken out of the box to look at yet as I was waiting on some drive cages first. Are there any complications with the NESN drives?
Ah ok, sounds good. Thanks for the help. 
Looks pretty solid to me. Do you think the PSU upgrade from platinum to titanium is worth the price difference? If it results in better reliability I'm willing to pay it. 

Also that Enermax cpu cooler is probably one of the best AIO for the TR processors right? I think I might go ahead and pull the trigger on that. Which means I only need to get the case and PSU. 
First of all, I didn't say I didn't know what the coin was about, I said I didn't know where folks stood on it. It doesn't matter if a coin has the greatest tech we've ever seen, if people don't invest in it, and they call it a scam, then it won't take off. At which point its likely some other team of devs will pick up the ball and do better with the development of that tech, if they have better marketing. 

[Secondly, are you sure that white papers are a good indication of whether something is a scam or not?](https://www.upwork.com/job/Blockchain-White-Paper-Writer-for-ICO-Project_~01a09694d5affeaff5/) There was a pretty good post in r/cryptocurrency, recently, about how easy it is to outsource all the major parts of your scam ICO to science and IT major students who are looking for work (white papers, spoofing the dev teams credentials, making a professional looking website and company, etc). 

And lastly, this post and comment are 50 days old. I had invested in Cardano before I wrote that comment. I was hoping that others would stop calling it a scam and that it might do well. 
I've had that issue on some sites with Internet Download Manager. Clicking on the download option will show a ton of streams, each piece is only a couple of seconds.

Just means that IDM hasn't been set up to play nice with that site yet. Lots of places, porn hub included uses split up streams and it handles all that just fine, just random (more obscure sites that it doesn't).

Anyways YouTube dl is usually updated quick when a site changes its streaming strategy. 
IOMMU passthrough works, but it varies and depends on what virtualization client you use. I've been wanting to buy a threadripper machine for a long while, so I've sorta been following the developments around the platform. It wasn't until this weekend that I pulled the trigger and started buying parts (after the NPT bug was fixed). I'm no expert on any of this, and I'm going off of my memory, so some of the info might be a couple of weeks, out of date.

I'm not positive about SATA passthrough specifically, but KVM still has some issues with GPU passthrough. Apparently (many) GPUs are entering a sleep state when they are passed through to the guest, which means they aren't useable, and the GPU has to lose power completely (ie a host reboot) before it can be utilized again. I don't recall if this is just Nvidia cards or if it's more widespread than that. /r/VFIO is a good place to follow for info on IOMMU passthrough.

From what I understand, this is not an issue with Xen or Esxi. From what I've heard, Xen seems to work fine for the most part, but it's not as flexible as other virtualization clients, since it assigns resources at boot time. From the way you want to run your system, it sounds like this wouldn't be an issue for you.

With Esxi, it used to give people the PSOD, but now it apparently works fine for the most part. The one issue people have had is with USB devices/controller passthrough, but I've heard it's an issue that can be overcome.

All of this is on top of the fact that certain x399 manufacturers have odd IOMMU groupings, which can make differentiating devices a difficult process. I recall hearing Wendel [(of Level1Tech)](https://youtu.be/I5xdbPI3v3s) say that things have gotten much better after updates from board manufacturers, but some small things persist, like NVMe pci slots getting mixed into other groupings. 
Sharing a file directly from your Google drive won't be possible with Stablebit Clouddrive since it's impossible to know where any file is stored on your Google drive. 

Sharing a file over your local network or via windows' built in file sharing features would work since it's mounted as a normal drive on your local computer. 
Stablebit Clouddrive has been my tool of choice, but it is limited to windows.

I don't know about android, but rsync should meet your needs. 
The point of the fees is because this is a service that runs on top of the iota network, meaning it will cost money for people to provide this service to others. Hopefully the fees will be low because iota itself requires none to be transmitted.

Personally, and I say this as someone invested in iota, I would have just continued to use monero for my private transactions, even if it costs more. 
A centralized mixer who keeps logs on the testnet because they are testing this feature (that's the point of the testnet). I don't know why anyone would think that the devs wouldn't keep logs to make sure their product is working right on the **testnet**. 

Here's a quote from u/ndha1995 who replied to your concerns a hour ago:

>The team is working on timestamps in the Tangle. Once timestamps are available, trustless mixer and smart contract can be deployed. That's why all of those features are still just in testing/developing period.
I don't know why you're being down voted because you're 100% right. 

Everyone sending *fake* iota over the ***testnet*** should be very concerned. It's terrifying to think that someone might send fake funds on the testnet, to a centralized mixer that is being used to test this concept (on the testnet), and think their transaction is perfectly private. 

I don't even have any iota on the testnet, so this isn't an issue for me. 
Haha, that's pretty hilarious. I didn't even think about it doing that. 
Interesting. Just curious, but do you have facial recognition features turned on? If you write a name for the face, you could search by actor/actress. 
I absolutely agree. Now that blockchain tech is available to the world, there's no going back to how things were before. Even if Ethereum or bitcoin or whatever coin fails, blockchain is going to reshape how we do things. 

I see it like the early internet; we can see so many useful ways to utilize it, but I think there's applications out there that we can't fathom that will have the biggest impact on people's lives.
With Ethereum specifically? Not terribly far away. There's lots of companies bringing solutions to help make data on the blockchain easier to access from the outside and vice versa (ChainLink is a decentralized oracle that many seem to think has potential). 

There are a lot of competitors to Ethereum who are trying to bring their solutions to market as well and some of them are being built from the ground up with these solutions in mind, which could lend them a significant advantage over Ethereum. Time will tell.

I expect we'll see decentralized versions of Airbnb sooner than most think, but I think it'll be a while before they pose any threat to Airbnb, just cause there'll be a lot of solutions competing against eachother on the blockchain. Like the decentralized storage market, there's a lot of products there and no clear winner, and it'll be a very long time before they start taking on Amazon.

Personally, I'm excited for decentralized Uber (or decentralized everything); cheaper rides while still providing drivers with higher pay since there's no middleman (often made of just a few people) to take a cut of the profits. 
I always thought he was batshit crazy. But then I saw a youtube vid of him talking about security regarding wallets on mobile devices and he seemed slightly less crazy, but then again, he still needs to eat a shoe on live cam because of his claims about the iphone. 

Anyways, he doesn't hold coins, he has a mining company in Oregon(?) and they just mine and convert to fiat. He's all pro-blockchain and all that jazz, but he doesn't seem to see cryptocoins as a worthwhile investment (when compared to fiat). 
Stablebit CloudDrive is also useful for encrypting and obfuscating your data.
This sounds not fun. I'm glad I came across your comment, or else I would have dived into this deal without knowing what I could be getting.
The type of drive you want depends on what you plan to use it for, but you can't really go wrong with enterprise disks. You'll usually get longer warranty and better performance, especially if you want to keep your device running 24/7.

As for virtual hard drives, it sounds like you want to partition your drive into multiple ones. There's tools built into Windows to do this, via Disk Management (on Win 10, click start, type in disk management and hit enter), or via command line if you're comfortable with that. With Linux there's GParted, which is a great tool, and it's also capable of doing it via terminal. There's also lots of good, free software out there that will make the process easy as a few mouse clicks, or give you options you might not have in something like Disk Management; so it's worth a look if you're interested in that kind of thing.
[How u learn?](https://i.imgur.com/I5pJFRR.png)
Classic 'buy the rumor, sell the news' situation?

You see that all the time in the stock market when it comes to tech companies anyways. Not saying it's the same thing here, necessarily. 
I'm assuming you're mostly interested in the killswitch part of the post and have an OpenVPN type VPN provider already (Private Internet Access is the VPN provider I use).

**Step 1: Get the IP and MAC of your VPN interface:**

The first step is to get the IP and the MAC of the virtual network interface that the VPN creates. One way to do this is to use CMD. On Windows 8/10, click start, type in CMD, and hit enter when it finds a match. Once the command line window pops up, type in "ipconfig -all" without the quotes and it'll show you all the network devices on your computer. In PIA's case, the adapter will be called 'Ethernet for PIA'. Once you have the ip (IPv4 Address) and MAC (in CMD it's called "Physical Address"), you can go to Comodo to start setting it up.

**Step 2: Set up your VPN as a Network Zone in Comodo**

In Comodo, go to the [Network Zones](https://i.imgur.com/cJzdM1N.jpg) tab, and create a new Network Zone called "Private Internet Access" (or whatever you want to call it). With that newly created Network Zone selected, go to add and click on "New Address". In there you'll want to type in the MAC address you found in CMD and then create another one for the IP address. With Private Internet Access, it assigns a different IP each time you connect, but all the addresses are in the 10.xx.xx.xx range. So In the picture, I have it set to cover every IP address in the 10 range, from 10.0.0.0 to 10.255.255.255. If your VPN provider does the same, it might be best to set up a range as well, as long as it doesn't conflict with your other address (in my case, my home addresses are all 192.168. addresses, so they're a different range entirely). 

**Step 3: Create a Ruleset in Comodo**

Next step is to set up the [Firewall Ruleset](https://i.imgur.com/Q8yLHJw.jpg) (in Firewall --> Rulesets). Create a new one and add the same rules you see in my ruleset. The blocked out part is just the name of my home network. Basically, with IP Out, select your network zone as the source address and set any as the destination address. Vice versa, and make sure the two allow rules are at the top. Then set up the block rules at the bottom.

**Step 4: Add applications to be blocked by Comodo if your VPN loses connection**

Lastly go to Firewall ---> Application rules and add the applications you want to block. Then check/select them and go to edit, and then it will allow you to select the ruleset you just created. 

-------------------------------------------

With all of that, you should be done. Any app using that ruleset should only be able to access the internet while your VPN app is connected. If it disconnects then that application should lose all connectivity. If you're familiar with IPs and all that and know what your local network's IPs should be, then you can double check to make sure your ruleset is working by using the Comodo Killswitch app. Go to the main Comodo screen, click on "Contained Apps" and then click on "More" and it'll open up, or install the Comodo Killswitch App. At the top of that app, you can select Network, and then scroll down until you find the application you're trying to block. Once you find it, you can turn off your VPN and see if it's able to make any successful connections outside of your network or not. With my ruleset, it should kill all internet access for that app, and also kill any local network connections that app has. 

If your app needs local network access, let me know and I can give you a screenshot of my other ruleset. I have an app that needs to access the computer's loopback using random ports, so I made a ruleset so it could continue to work, but not access the internet if the VPN is turned off.

Hopefully this works for you. These are the settings that worked for me. If you need any help with any of these steps or have questions, let me know.
[We did it reddit!](https://www.youtube.com/watch?v=kPIdRJlzERo)
-245k now
-250k: Dissolve EA

Come on guys, we're so close! Just 5k more downvotes. 
Certainly could be. I'm out of my depth when it comes to the software development side of things. 
Is 22% considered a lot?

I mean, I'm sitting over here with my coin going up over [200k%](https://i.imgur.com/PV0brsz.jpg). Netting me a 114k profit on a ~30 buck investment. 


But in all seriousness, my best performer today has probably been Ark or VTC; not-including whatever glitched currency CryptoCompare is throwing my way. 
Bittrex isn't too difficult, especially compared to other markets/exchanges. You just can't buy any coin on it directly using fiat, so it's purely cryptocurrency trading. This means you have to buy a coin (like BTC or ETH) and transfer that to Bittrex before you can do any trading.

Buy Bitcoin or Ethereum at someplace like Coinbase (which allows you to use a credit card to purchase ETH/BTC) and then transfer it to your wallet in your Bittrex account. Once you have it in your Bittrex wallet, you can use the links below to trade that currency for Siacoin. 

[BTC --> Sia](https://bittrex.com/Market/Index?MarketName=BTC-SC)

[ETH --> Sia](https://bittrex.com/Market/Index?MarketName=ETH-SC)
Wait for Trezor 2, or use Nano S. Trezor (original) is good, but I don't know how easy it is for them add currencies to it, but Trezor 2 is being made from the ground up to be easy to update and such. 

Ledger Nano S on the other hand, seems to be ok with adding new currencies to their wallet. 
Yea, that's unfortunate. I've never heard of this until now, but I guess it's one of those things that would be hard to stop, even if they were putting in the effort.
So, even if we use reddit magic (large number of reports) to bring youtube's attention to the vids in OP's post, it still doesn't really matter?

Honestly, this might be a good scenario for Google's AI type applications, whenever an AI that can watch videos is introduced. 
Since people who haven't been using the program for a year are receiving this message too, it sounds like they sent it out in error, or they're bringing and end to the rewards program. I certainly hope it's the former, because I just went to go see what I could redeem and the Samsung Visa rewards cards aren't displaying for me anymore. 
He's sacrificing his investments, so that we can gain profit from bitcoin.

Respect /u/strifesfate's sacrifice, for he's the man who will get bitcoin past 10k.

On a more serious note, I have the same problem. If I invest in a coin, it's almost guaranteed to immediately dip. I should probably start publicly posting what coin I plan to buy and when, just so people here can profit by buying the dips.
I haven't used any blockchain based cloud storage platform yet, so I can only go off of what I read. That being said I'm invested in Sia and only because I believe their tech is something the world could sorely use. 

Fully decentralized with client side encryption ensures your data is safe as long as you remember your password, and keep paying to have it stored. Since all the rates and prices are set by the market, it should be a decent amount cheaper than Amazon or Google, because anyone can enter the market and offer storage (although there's an algorithm/rating system to determine who is a good/reliable host). 

It's geared towards enterprise and I've read that the user experience isn't great, but they also have support for applications like Duplicati, so that might make the process easier (and they're working on the user experience as well). As for reliability, I haven't heard any complaints on that front. 

There's also a lot of companies who are competing for the blockchain based cloud storage position (at least 5-6 or so that I'm aware of). It's hard to say who will win out at this moment, but Sia is doing well, at least compared to some others. While Sia is enterprise focused, Storj is consumer focused with an easier user experience, so that might be another one to consider. I'd check out their reddit first (and Sia too), because Storj used to have some major cost balancing issues, partially from operating in the consumer space where it's less profitable. But I haven't heard of any issues about reliability on Storj's platform either.

/r/storj 

/r/siacoin 

Just about every blockchain based storage company will claim to be decentralized, but there's always some aspect of their platform that is firmly centralized (like Storj directly controls/modifies the payout that miners/hosts receive). I've invested in Sia, because (from my understanding of how it works), at some point in the future, the Sia devs could just walk away from the project and the platform would continue to operate just fine, since it's fully decentralized and market based (no need to have a centralized entity modify prices, or anything like that). I find that concept to be pretty appealing.

Still, the best practice is to keep a local copy of the data you upload, regardless of whether you use Google Drive, Sia or something else. And with Sia, you could consider creating more than one storage contract, for even more redundancy (and it'll still be cheaper than Google/Amazon).
They do it to [hide their numbers.](https://youtu.be/Gvh3l8K7PX0?t=4s)
I haven't tried it yet. I tried out the other app because it was quick and didn't seem like there was much of learning curve to it, but that didn't pan out since it couldn't parse JS files.

Selenium + Chromedriver looks like it might do the trick, but from what little I've seen of Selenium, it seems there's a bit more setup/learning curve (for me anyways). So I was going to try it out this weekend.
Gotcha. Does it let you export the information you entered into it?
Yea, I think you're right. I believe it was both, but I edited my comment to remove the anti-Semitic part because I wasn't positive which of the two was the main focus of her rally. I skimmed a few articles an hour ago when looking for that 6-8 page article, but I must have skipped over that part. 

Also, in the interest of being accurate; to anyone who is interested, as best as I can remember, that 6-8 page article was written in sometime around 2015. So they spoke of the former chair stepping down for DWS, but they didn't know at the time that it was in exchange for the VP seat. I added that in, because it became clear later on that's why he stepped down.
There was a huge 6-8 page write up from Politico on the relations between Obama, DWS, and the former chair, who stepped down in exchange for the promise of being VP (I haven't found the link to the article yet).

Basically, Obama appointed her at the behest of Clinton, but [Obama couldn't stand DWS](http://www.politico.com/story/2014/09/democrats-debbie-wasserman-schultz-111077), and even tried to remove her after the elections made it clear that she would sacrifice what's good for the party to further her own agenda. She only remained because Hillary was on her side, and she threatened to hold rallies against Obama, claiming he was sexist. Given the pushback he was facing from republicans, he backed off because he didn't need that from his own party.
Thanks for the recommendation. I had looked into that one in the past, and it looks like a fantastic service, especially the free tier. 

I'm going to definitely give this a shot. I didn't try them out before because I have limited funds (so their paid tier is a bit too high for me), but also because I'm nearly 3/4ths of the way to hitting the trade limit on their free tier.
I have my trezor on a keychain, but I just stuck a short micro usb to usb A keychain cable on it. It might be easier to just get a keychain cable (micro to USB A, [like this](https://www.amazon.com/Nomad-Cable-High-Speed-Micro/dp/B00QDFFKHY/ref=sr_1_17?s=wireless&ie=UTF8&qid=1508857697&sr=1-17&keywords=keychain+micro+usb), and or [this](https://www.amazon.com/inCharge-Portable-Charging-Keychain-Version/dp/B01C7MR2AO/ref=sr_1_2?s=wireless&ie=UTF8&qid=1508857697&sr=1-2&keywords=keychain+micro+usb)), and then get a USB A to micro USB adapter. 

Edit: [These](https://www.amazon.com/gp/product/B015GZOHKW/ref=ox_sc_act_title_1?smid=A3ON5HWR8S7L0D&psc=1) might be better, or [this](https://www.amazon.com/gp/product/B01L786S7C/ref=ox_sc_act_title_2?smid=A18YO9QJVZ6LHS&psc=1)

Finding a cable-less male to male micro USB adapter seems oddly difficult to track down.
Thanks for the suggestion, I'll check it out.

Edit: It doesn't seem to have a way to parse JS files, so it ran into the same issues as the others. 
You and I have the same superpower. We should really coordinate our buys, so we don't accidentally destroy any good, up and coming cryptos. 
Yea, I left r/bitcoin because I dislike censorship and power abuse. Going to any reddit for any crypto is bound to have some level of that as well, which is why I don't hang out in reddits for specific cryptos, unless I have a question or issue that needs solving. Going to r/Iota or r/Ethereum etc is not an answer of people who want a place they can discuss cryptocurrencies in general.

Honestly, it's kind of disgusting that so many people are calling for even more power abuse, from outright bans, thread removals, to more situations similar to the auto-mod, and many defending the mods saying that reddit is not for open discussion and that mods should always have the say on how discussion is led (because it's in the reddit rules or something, as if that makes it ok).

It shouldn't be the mod's job to shove information down your throat, whether it's about Iota, Link, Bitcoin Gold, or Bitconnect. It should be their job to only remove posts that are overly offensive (racist name calling or something)/off topic (things that have nothing to do with cryptocurrencies). They shouldn't be the police in charge of what information people should or shouldn't recieve (and in turn, what they do or don't invest in). 

I understand why they're doing this though. If I were in their position, it would be extremely tempting to push everyone towards investing in the coins I have in my portfolio.

To answer your question. No, there really isn't a good place to discuss cryptocurrencies in general. There's the obvious faults with this place, and any subreddit that's created out of the need for a neutral/open place to discuss cryptocurrencies will be populated by those who are feeling outcast or unwelcome here (namely, Iota supporters, so you'll likely only see Iota related posts). I really wish there was someplace where open discussions on cryptocurrency in general were possible; where it was up to the reader to make up their own mind, not the mods.
Yea, I'm with you on that. 

I came here from r/bitcoin (after I got fed up with the bitcoin/btc toxic environment and the censorship), and I honestly thought this was one of the few places to openly discuss coins without repercussion. But apparently that's not true anymore, as discussion can result in the placement of an auto-mod stickied post.

Iota is the smallest part of my portfolio, and Link is one of the largest, but I can readily admit that there was a extreme amount of shilling for Link over the course of a couple of weeks. Apparently a dozen threads along the lines of "Why you should put your life savings into Link", is acceptable, but legitimate and positive news about Iota isn't.

I don't care what coin it is, Iota, Link, Bitconnect, Bitcoin Gold; this should be a place for people to make up their own minds without having the biases of the mods (whether their biases are correct or not) affect the outcome. As a mod, their voice is more important than everyone else's...they have mod tools to ensure that (ie auto-mod), it's not their place to push people one way or another. 
The mods got back to me and said I should put everything into Bitconnect. They said they were heavily invested in it, and if all of us put our money into it, it'll soar to the moon.

I trust the mods, they're the same folks who made that savvy auto-mod.
That's me. I always buy coins at ATH cause that's just the kind of luck/planning I have.
I'll have to look into this and give it a shot. Thanks!
Well I certainly hope to. I mean, I want to buy it at it's lowest point and, you're right, that'll probably be when it's stabilized/flat.
I accidentally sold almost all of my VTC (meant to only sell half), but I plan to buy the dip when it stabilizes. To me, it looks like it'll fall someplace between 2.5 and 3.

Anyways, as long as I buy it at anywhere below 4.3, I'll come out ahead.
There's a festival for the God Shiva (so at his temples), where priests and others spend the entire day smoking Marijuana.

Edit: Apparently the festival I'm thinking of happens in Nepal.

http://www.npr.org/sections/goatsandsoda/2016/03/07/469519964/shiva-is-a-god-who-likes-marijuana-and-so-do-many-of-his-followers
I haven't dropped bitcoin yet, but I stopped following both of those reddits a while ago. R/bitcoin especially was seeming more and more like r/conspiracy but with more censorship. 

Either way, the BTC related communities (on reddit at least) seems toxic and would likely turn off any people who are exploring crypto for the first time (like I was, earlier in the year).

I've been sticking to this sub almost exclusively, for the most part. 
You could dual mine, which is what many miners do. VTC on GPU and use the CPU for XMR or something. VTC uses an algorithm that's designed for GPUs (Lyra2REv2), and would perform very poorly on CPU. 

XMR uses an algorithm that's CPU friendly (CryptoNight), but even still, you likely won't produce a profit unless you have no electricity costs.

As someone who doesn't have electricity costs, I've been playing around with mining on an old desktop and have it set to dual mine. I know it's doing XMR on the CPU, but have no idea what it's mining on the GPU (I'm using Nicehash and their program figures all that out for you and then they pay you in BTC).
I don't recall the name behind the concept, but everytime Apple (for example) [throws an expected press conference](https://www.cnbc.com/2017/09/12/apple-stock-movement-during-iphone-x-event.html), to reveal their new products for that year, you'll see the price go up during the press conference (and in the days leading up to the conference). Shortly after halfway through the conference, you'll start to see people dumping the stock and it'll drop in price. It seems to happen like clockwork, every year, and the people buy back in, usually before the release of the actual phones. 


I honestly don't know if the same thing is happening here or not, but I've sorta seen that trend happen in some coins; where they'll announce some new feature that could provide a competitive boost over other coins, and the coin's price will drop.
I'm pretty sure you're right. This video is from December of 2016, and I think the first SD835 phone didn't come out for another 3-4 months after that. 

I came across a few more recent videos of people filming a tech conference demo with their phone (so not great quality), and then came across this one and assumed it was an 835 also. I should have checked the date before posting that.

Edit: The quality on [this one](https://www.youtube.com/watch?v=oSXUDKpkbx4) isn't as bad as the others, and this is from June of 2017 running an 835, if anyone is interested. 
If you're interested in checking out a demo video they released.

https://www.youtube.com/watch?v=A_GlGglbu1U
Given the processor it's running on, [I'd say it seems rather impressive](https://www.youtube.com/watch?v=A_GlGglbu1U). Faster than some of the virtual machines I've had to deal with in the past.

~~They don't specifically say it's the 835, but given that there's other live demos that took place on the 835, I'm guessing it's that.~~
Ok thanks, that makes sense. 
Gotcha, thanks.
As someone that's new to NAV, do you need to keep the wallet open to ensure the coins are being staked?
Seems like it's been on and off maintenance for a while now. I bought some on the 10th or so and had to wait 24 hours before maintenance ended so I could transfer it out. Just bought more and it's still under maintenance?
I had to scroll down way too far to see this comment. 

Nobody (in IT or related) would answer with the loopback when asked for a local address. 
I appreciate the video of a turtle eating a strawberry. 

While it could go after bitcoin, the multilayered blockchain is what caught my eye. The TCP/IP stack being separate from the physical layer (allowing both of those technologies to evolve independently of eachother, instead of needing major overhauls when either is updated) is exactly what drew me to Link and now to ADA.

So many people are calling this a scam coin, but it seems like an interesting project.
I'm looking for the same answer myself.

Everywhere I look, half the people scream that it's a scam coin, the other half mention that they're buying into it because it has potential. 

At least, that's how it was with almost every thread on it up until the last few days. I don't know where people stand on it now, but I'm sure many will double down on calling it a scam or supporting it.
With good reason too. Every device with a high quality internal dac has it for use with the headphone jack (which means it doesn't need a USB C to headphone adapter). Every device that doesn't have a high quality internal dac (and therefore has no need to include analog passthrough in their USB C port) will use a more expensive dongle with a dac built in.

Unless you can find the full spec sheets on a device, are able to test the USB C port with equipment most folks don't have, or manufacturers start making USB C analog passthrough cables (which I don't know why they would), we won't really know either way if a device supports that or not.

Edit: As I said earlier, I haven't found any such spec sheets during my searches, but I was hoping to find a teardown of the Dex station for the S8/Note 8, so we could see if there was analog passthrough or not. 
I'm guessing you could, but if the USB-C on the Note 8 passes along analog audio, you wouldn't need an adapter as expensive as Google's (or as expensive as most of the USB-c to 3.5mm adapters out there).

Unfortunately, I can't find anywhere where it lists the USB-C specs for the Note 8.
That's basically the concept behind using twisted pairs in ethernet cords isn't it? 

The electrical signs traveling through the wires is enough to create a magnetic field that causes interference among the other wires within that ethernet cord. So they twist two of the wires together that will nullify the interference those wires put out.

I don't know enough about SSDs or the interfaces it connects to, but it makes sense that a powerful magnet could affect it. Might not wipe the SSD but it could cause data corruption if the SSD is receiving data. 
The chip part of the cards should be ok, but you won't be able to swipe it anymore (since that is a magnetic strip). I don't know about SSDs though. It might not wipe the data on it, but I imagine there's enough metal that it could cause issues. 
Wow, thank you so much!
The devil takes many forms, don't let these pretenders cause you to stray from the righteous path. Have faith that God wants you to buy our ICO. Garunteed bamboozle free.*

*Garuntee only entitles you to a refund. All refunds are processed on February 31st. 
As a deeply religious subreddit, I know I can count on the support of r/cryptocurrency to back me up as I launch an ICO to fund our battle against cryptocurrencies and any other trick the devil tries to pull. 

Our coin (JSUS) will have all the ~~buzzwords~~ technologies; decentralized, atomically scaling quantum swaps, vertical integration, AI, private transactions, hackproof because it's closed source (but it's open source to God of course!), capitalism, and synergy. 

Guys, this coin will hit $10k per coin and have a 12 trillion dollar marketcap in 3 years, don't miss out.
A pro-Bixby article in r/android?

I, too, like to live dangerously.

But in all seriousness, I use Bixby a decent amount. Anytime I want to do something on the phone, but for one reason or another find it less convenient or slower to tap on my phone, I ask Bixby to do it (sometimes it's amusing to watch Bixby work on the phone). Anytime I want an answer to a general question (ie, something the internet would know), I get Google Assistant to answer it. And Alexa is going largely unused, now that my house is devoid of any easily accessible smart devices.
I used to have something similar happen on one of my old android smartphones, but it happened whenever you plugged it in, and it was most noticeable through headphones. I'm not an engineer (so I could be totally wrong), but I figured maybe it was electrical interference or feedback affecting the DAC/headphone/speaker outputs or something.

If you want to try some other troubleshooting steps before you get a replacement, here's what I suggest.

1. Try disabling fast charge and see if it happens.
2. Do you still experience this issue if you charge it during the day? 
3. Have you been able to reproduce it in other locations (try plugging it in at work or try a plug on the opposite side of the house/apartment)?

If you want to rule out software, I'd suggest making a backup of your phone using the Smart Switch app (set it to backup to your SD card), then do a full factory reset. Do the bare minimum to set up your phone (log into gmail and things like that, but avoid installing any other apps if possible) and see if it still happens.

If it still happens, then it sounds like it's almost certainly a hardware issue. If it doesn't, then it might be some app/settings that was triggering some action at 3am (or when the battery was full) to cause this issue.

Otherwise, it definitely sounds like it would be a hardware issue and might be best to take it to a Samsung store, or contact support.
That's pretty shitty.

There's no way to try and do an RMA through Best Buy? I mean, in all likelihood they'll tell you to go through Samsung, but still, worth a try. 

I know this is a bit different (maybe unique to buying phones through T-Mobile or something), but my sister busted her S7's phone screen and she went through T-Mobile to get the phone replaced. They sent out her phone to Samsung, gave her a loaner while she waited for her phone to come back and she got her same phone back or it was a refurbished one (I don't recall). 
Isn't that true for many cryptos nowadays? I a haven't started mining yet, but it seems like with every day that passes, sites like 'what to mine' show there's less and less of a difference in return on a lot of coins. 
Unlimited works in theory, but, at this point, I think only Google could pull it off, because Google Drive is so widely used.

Basically, you offer only an unlimited plan and you use the profits you get from casual users (who will end up paying more than they use) to offset the costs of heavy users (who are far less prevent, but will use a lot more than they pay for).

Problem is, every service that offers unlimited in the data storage realm is immediately noticed by heavy users. Then the companies make no real effort to attract casual customers. 

Amazon is a good example of this. They are large enough to be able to pull this off, but when they offered unlimited storage, they didn't advertise it or try to get people to buy into it. I'm a Prime user and I didn't hear about it until I saw a post on this reddit. So it ended up dominated by heavy users and Amazon shut it down. 
I think I saw the exact same post like 6 months or more ago (same user).

Probably a bot designed to go to random places, comment, and upon reaching a certain age/karma, the account will be sold to someone for marketing/political use.

My guess anyways. 
I've had the Nexus 7 for years and never knew it had wireless charging. Or maybe I knew it but never used it and eventually forgot about that.

Either way, I'm glad I found that out just now. Makes charging this thing so much easier (now that my primary phone charging cable is USB-C).
When it comes to the big coins (ETH, BTC), I'd say it's more ok to invest and forget, but even still follow the news for the occasional big event, like the upcoming BTC hard fork.

I haven't been trading all that long, but I've been holding all the alt coins I've purchased for the long term. That being said, alts usually undergo regular/fast development, and I'd definitely recommend keeping up to date on the news for that reason alone. For example, WTC is going to switch from being an ERC20 token to being on their own blockchain, and Iota recently updated how their 'tangle' tech/wallet works. In both cases it seems necessary for folks to go through a coin transfer/conversion process.

It's not always easy to tell when is a good time to give up on a coin either, and I've never had to do that yet, so I don't have any good advice in that regard. Reading online could help, but you'll always find people saying the coin is dead, and others saying it's a good time to buy more.
WTC and ChainLink look fantastic right now, but 2-5 years is a long time. The devs could mishandle an issue, a competing coin could simply market/advertise their services better or form partnerships with industry players, a coordinated attack could be planned by malicious actors (or competing coins), etc. 

There was that time when a certain group caused ETH to lose 4 billion dollars in market value by getting the public to believe that Vitalik had died; those same folks are heavily invested in ChainLink and could dump whenever they feel the time is right. A company/coin having good technology can only get it so far (as we've seen a lot of cryptos with good fundamentals going unrecognized), but certain actions could easily knock it out of the running, no matter how deserving or vital that coin could have been the crypto ecosystem.
I'd love for it to go up 10-20x. I'm in it for the long haul, but FCT is currently one of the worst performing cryptos in my portfolio.

That's just my personal luck though, as I have an excellent ability to buy cryptos when they're at an ATH.
But the babble fish feature isn't compatible with any phone other than the Pixel right?

It seems like these are marketed at the folks who either like the Google brand (given their dongle prices, it seems Google is going full Apple in this regard) or they only expect Pixel users to buy these.

Still dissapointing either way. I hope other manufacturers don't make Bluetooth headphones that only work best with their own phones. 
You know their excuse was that it was removed to "make way for a bezeless future", right?

Given how the Pixel 2 looks, it's very clear they didn't need to remove it any time soon.

You're thinking of Apple, who used the excuse that they needed more space in their phone for things that weren't important to consumers. 
It's fine to be excited and all, but it's really nothing interesting. I've got a phone that has Bluetooth 5, USB-C and a headphone jack and even though I've owned all 3 devices, I go back to the headphone jack every time. Convenience of use across all my devices, better quality and lack of charging make it an obvious choice for me. 
Wouldn't that only be a benefit in Apple's eyes? I mean, I left the Apple back when they went to court and said jailbreakers were just common criminals. Given that on stock iOS (back then) you could only change your lockscreen background, and only change your call ring tone (not the texting one, or do custom ring tones for contacts), having a non-jailbroken iphone was a non-stsrter for me. With the jailbroken apps I had running, I was able to use notifications, quick replies and proper multitasking before even android had it.

If the only way to fix a phone is by taking it to Apple, it sounds like that's the perfect phone for Apple. Keep in mind, they've also done everything they could to stop 3rd party repair shops, but were shut down in court back in April, I think it was.

If this is how it plays out, I'm sure Apple is counting down the days until they can go full wireless. 
I used to do both actually. I'd save my keys/seeds into a password manager, which would get put into an encrypted archive (along with all the files I need to run/open that password manager file). Then that archive goes onto a USB drive. I'd also keep backups of those paper wallets by writing down part of my seed data onto 3 pieces of paper and store them in various places. So you'd need all 3 pieces to recreate the seed.

It's not necessary to go to that length, and some folks would say I didn't go nearly far enough, but whatever route you take, I'd recommend that you future proof yourself as much as possible. You don't want to end up in a situation where you go back after 5-10 years, only to realize you don't have the right ports, or the right OS, or there's some barrier preventing you from accessing your coins. If you use password managers or encryption, make sure you set yourself up in a way that you'll be able to get at those passwords to unlock your files in the future. 

And flash drives (including SSDs), can lose their charge over time, which might cause bits to flip if it's left unplugged/unused for a long period of time (this could lead to corrupted data or data loss). A good way to prevent that from happening is to plug in your USB drive into a computer, maybe once or twice a year.

I've only skimmed through some info related to Chainlink, and they do call themselves "secure blockchain middleware", so you're definitely right in that regard. It sounds like the key benefit is having to only deal with one API (to receive all outside information). I'm guessing that could greatly streamline development, creation, and maintenance of smart contracts and respective applications.

Whether companies jump on and sell access to their services by using Chainlink is tricky to say, but it's not like companies don't partner with middlemen (or use middleware) all the time because of the convenience/security/options/etc it provides. Many of these same companies may want to utilize or create their own contracts/applications and they'd benefit from the ease of access when using a single API to access what they need from others.

Some will only need access to one blockchain, I can see many, that may need/want to utilize more. A hypothetical example would be a company creating contracts using Oracle's supply chain management services (which uses Hyperledger, much like MS's and IBM's services) while utilizing another blockchain for supplementary services (possibly payments to vendors or passing information to another smart contract on a different blockchain). 

Using middleware also allows the blockchain and companies to evolve separately without disrupting access to one another. It would be up to Chainlink to implement any changes caused by an event/update in the blockchain. 

I don't know if Chainlink will succeed or not, but I do think the type of service they provide will become a fundamental part of accessing the blockchains. So, if Chainlink doesn't pan out, I think someone else will make this happen.
I was telling a friend of mine yesterday that I have a gambling addiction that I never knew I could get (because traditional gambling has never been an issue for me).

Anyways, I suggested we create a cryptocurrency support group, and in order to fund the endeavor, we should create a crypto for people to buy into. Possibly using the token 'Help'. 
I was discussing this with a friend of mine just yesterday (when I suggested that I had a gambling problem). I suggested we find a way to decentralize the care/support, and create a crypto to help fund our Cryptocurrency Anonymous endeavor.

We could call the token 'Help'. 
I've never tried either and I don't know what their fees are (or which countries they accept customers from), but I think Coinmama, Bitpanda and Changelly all allow credit card use.
It depends on where you buy your alt-coin from. Some of them only support BTC-altcoin pairings, others accept ETH-altcoin pairings, some accept both.

If a place accepts ETH-altcoin pairings, I almost always choose to use ETH because it has lower transaction fees and confirmations come in faster than with BTC. Basically, I'm losing less money in overhead if I use ETH.
Number 2 is a concern, but it's part of the reason why people suggest you trade while thinking in satoshis/bitcoin/eth/etc. The price of bitcoin will fluctuate compared to EUR/USD, so it's best to not convert the price of a cryptocurrency to EUR in your head constantly; instead focus on trading to maximize your ETH/BTC holdings (or whatever other currency), and then cash out when the prices are high. If bitcoin/eth is in a slump, that'll mean you could end up waiting as much as a couple of months while you wait for the prices to recover (compared to EUR).

I don't know about 1 or 3, but there will be fees. I'm not familiar with most exchanges, but there'll usually be fees, and there will definitely be fees when converting from BTC/ETH to EUR.
1. A fork is expected to create two currencies, but it would be more complicated than the BTC and BCC split because of the lack of replay protection. 
2. Yes, but before using/selling either of them, I'd check back here to see how people handle the lack of replay protection thing. 
3. I'd recommend searching r/cryptocurrency for info (there's been a decent number of threads and there'll be a lot more leading up to the fork). They obviously don't talk about it as frequently as the folks on r/bitcoin or r/btc, but I find that cryptocurrency is more neutral and less likely to be riddled with conspiracy theory/fud posts (also, from what I know, there's no outright censorship here, which can't be said for certain other reddits).
4. r/btc and r/bitcoin will be full of posts with people's thoughts of how it will all play out. I'd just suggest remembering that censorship will heavily skew the truth of the matter and helps push out a certain message, so take it all with a grain of salt.
1. It depends on your stance on closed source applications. If you think they're safe, then I guess there's no issue with storing it long term. From their [support pages](http://support.exodus.io/article/42-how-do-i-restore-from-my-12-word-phrase), it sounds like all you need is your seed to recover your accounts in Exodus. So what you're proposing should work just fine. 

2. I'm not positive what you mean by unknown coins, do you just mean all the various coins out there? I don't know of any coins that can't be put into cold storage of some sort, but it might not be the best move with all coins. For example, WTC is moving from an ERC20 token to its own blockchain, so it'll probably be best to consider cold storage after that transition.
Very late reply, but I was just searching for info on OMG wallets myself and found this thread.

Just in case nobody answered your question, you can store ETH, or any ERC20 Token in your ETH wallet. 
Yea, our wages, taken at face value are much higher than most of the world.

It doesn't account for cost of living, although, overall our standard of living is good/high when you include developing nations for comparison. 

A person making $20k in the US would likely struggle with paying for necessities, but someone with the same income ($20k) in India would be considered middle class and could afford a big house, cars, have expendable income and plan for retirement. Rent, utilities, groceries, everything costs less in India with a few exceptions (like imported electronics can still be quite expensive). 
Unless it's a laptop you don't want to use anymore (ie old laptop), I wouldn't. 

Mining with desktops when you're not using them is fine, but laptops generally have poor cooling (compared to desktops) which leads to higher CPU/GPU temps. The processors are designed to handle higher temps, but it's still not good for them. 
I agree, but I had assumed they were typing in that manner so they could post it to reddit/imgur for internet points. 
I'm not sure how it works exactly, but whenever I use a paper wallet, or the desktop GUI client (2.4 or 2.5) to generate a receive address, they all create the same addresses, in the same order from my seed. I only ever used the first address and I used it to receive Iota back in August. So on 2.5, once I changed the weight to 14, the first address was the right one. 

Is it not generating the addresses in order for you? If you make a lot of transactions, I'm sure it could be difficult to figure out what addresses to look for.

I hope you find it soon.
I came across that article when I was googling frantically to try to see if I could fix this, but I wasn't sure if that issue applied to me or not, since I got into Iota well after that was posted (August 27-28th, but I was still using 2.4).

Either way, after reading that I did reinstall 2.4 and ran through 1000 addresses and it didn't find my balance. I tried re-running the address search after changing to bitfinex node and then back to the default I was on, but that didn't help. So that's when I decided to post here and see if anyone could help.

Edit: You're a lifesaver. I did what was described in the picture and it worked right away. Thanks so much.

Edit again: Are there any other steps I need to take? The 2.4 guide made it sound like we'd need to transfer to a new seed/address to get up and going. Is that necessary if you do the steps in the picture?
Gotcha. Thanks for the explanation. 
I'm still unfamiliar with some of the crypto concepts with coins like OMG. It sounds like OMG is a proof of stake coin; do all proof of stake coins pay out in the way that OMG is supposed to (like stock dividends, or similar to Ark/NEO)? 
I knew a girl in highschool who refused to believe in evolution for the same reason. If you explained it in a more concise manner, she'd say that we were the crazy ones for saying that we evolved from monkeys. 

Sometimes it takes a bit of reading or effort to understand a topic. 
I'm not sure if this is what you're looking for, but in the Samsung Pay app, if you go to the credit cards section and then select one of them, it'll show you some of your most recent purchases. I think it only shows the 10 most recent purchases. 
You should be getting points. Did it say that you were charged for the gas, or is it saying you were charged $0
None of them. As far as I know, no exchange allows unlimited daily withdrawals (to fiat). A lot of them have limits in place, ie $10k per day.

Even if you could withdraw that much in a day, you wouldn't receive a billion dollars anyways. You're selling so much bitcoin (1/68th of the total market cap) that it's exceptionally likely that your selling those BTC would cause the value to drop. The result would be that as you sell more BTC, your remaining BTC coins would be worth less and less. Hell, a person trying to take a billion dollars out of the market could be a big enough blip on the radar to cause speculative investors to pull their money out, leading to a crash (at which point your BTC would be worth a lot less)
I definitely agree that companies like Cummins are deserving of more visibility than they're getting, and there was an article about their electric truck on every tech news site, and usatoday, fortune, buisiness insider, etc. 

I don't know if I'd say they're farther ahead than Tesla since they did their reveal two months earlier, both of them seem to have planned to start production in 2019, and, more importantly, Tesla and Cummins are targeting different aspects of the trucking market.

From what I've read, it seems Cummins is targeting local/city trucking (with their 100 mile batteries, with plans to offer extra battery packs and improve charging speed in the future), whereas Tesla seems to be going after regional trucking with their 200-300 mile range. 

Even though both of those trucks still have far less range than diesel trucks (up to 1000 miles), I think either of them could displace much of the industry if they properly implemented self driving/charging. Where a trucker is *supposed* to take a certain number of breaks per X hours driven, I believe these trucks could charge several times (especially with fast charging tech Cummins plans) and still come out ahead when all things are considered. 
Also, Tesla is the only one who's sort of allowing normal folks to beta test them (at least for owners of the Model S).

If others brought their tech to market in that way, it'd be much more exciting and newsworthy. 

Gotcha. OK, that makes more sense then.
Coinmarketcap and one of the Dash blockchain explorers has the circulating supply at 7.5 million. 

Is coinmarketcap not considered a reliable source in this regard? Genuinely asking, because I'm a very casual alt-coin holder (never really look into marketcaps and such).
I'm out of touch with all of this stuff (I've never looked into crypto marketcaps until today), but why does Dash's marketcap make no sense?

Did you mean that the circulating supply (~7.5 million according to coinmarketcap) is absurdly high or something. I mean, I don't really look up marketcaps and such (I really should), so I don't know if that's a high number or normal number for this particular crypto.
That's good to hear and I'll definitely check out the service. As a former Onlive customer, this kind of platform certainly appeals to me, and seems like it has a lot of potential.

Speaking of potential (I saw you say earlier that you're not limited to any one platform in particular), I hope you guys add expanding to Android into your roadmap somewhere down the line. I imagine bringing the service to include Android would be big, as there's so many games out there, and likely a lot of hidden gems that people are missing out on, and there's VR games on it as well.
I like the idea, because I loath micro transactions and DLC can be a pain when there's lots of it and they don't provide enough content for the cost. Your strategy solves that issue. 

My question is, for the developers who regularly release a lot of DLC, are there any rules in place on what counts as a DLC worthy of the extra attention they'd get by being featured in New Content Updates?

Some devs are slow to release their DLC, but it'll have enough content to be its own game, but others often add tons of small game elements/small story chapters, etc on a regular basis. Seems that extra attention to the latter developer (because they keep adding new content to stay in that category) might be unfair to the former developer. 
Yea, I've tried to use Samsung Pay at Home Depot 3 times, and it only worked one of those times. At the self checkout lines, it always fails the first try, but one of the times I got it to work on the second try but only after the employee cleared out the first transaction.

Not sure what the issue is, but I just use a normal credit card at Home Depot now. 
Yea, it's tricky to say how it'll play out in the future. The way I expect it to happen is that as more places adopt wireless payments, places like Kroger (even despite their size) might feel pressure to start using the tech themselves, if for no other reason than to stay competitive by offering that convenience to their customers.

From a cost side, other than potentially having to pay for an upgrade to their POS systems, there isn't any associated ongoing costs with using wireless payments; at least nothing more than the standard CC processing fees they already pay anyways. 

So, ignoring the greed factor (like Walmart wanting to do Walmart Pay, or all the telecoms+others trying to force Softcard to happen), most large companies should be able to implement it without issue if they wanted to...so hopefully they eventually will. 
I do get asked that at some of the stores that I visit, but the gas stations that I normally use don't ask me that. 

If it asks you that question when using a normal credit card/debit card, then I expect it would be the same with Samsung Pay as well. 

If you try it out, let me know how it goes. I added my debit card to Samsung Pay ages ago, but I've never used it (in Samsung Pay or as a physical card). 
Even still, he shouldn't be seeing that low of a SOT unless he's doing something crazy like video rendering, shooting nonstop 4k video, or just leaves his screen on and uses max brightness at all times. I honestly have no idea what he could be doing to see those kinds of SOTs.

I managed to get 5.5 hours of SOT, while using Gear VR for about 4 of those hours. I was only watching VR videos, not playing AAA VR games, but VR is still quite demanding since it bumps up the resolution, brightness, and prevents the CPU from being throttled to prevent latency, since latency in VR is the kind of thing that makes some people feel ill when using it. 

And the CPU throttling plays a big part in the battery drain in VR. In normal phone operation, the CPU is throttled to prevent the phone from getting so hot that it's uncomfortable to hold. In VR, it can get that hot, but at a certain point, it'll ask you to pause the app to let the phone cool down, rather than throttle the app and risk laggy response. 
I honestly have no idea what he could be doing that he only gets 3-4 hours of screen on time. Video rendering, or constant 4k recording?

My usage 2 days ago had me only go 12 hours without charge and with only 5.5 hours of screen on time (I plugged in at 15% battery), but that's because I used Gear VR to stream a few VR videos and a 3D movie (in the Netflix VR app) for about 4 hours of that time. 

Normally, VR, even to just watch videos, is pretty demanding, as it bumps up the screen resolution to max, bumps up the brightness significantly, and (I assume this is still the case in the Note 8 too) it would engage a special performance mode just to reduce latency (the CPU would be entirely unthrottled, which would lead to some pretty hot phones in older S/Note phones).
I see, that's unfortunate. 

I don't know where you are, but all the Note 8's released in the US have that piece because Samsung wants you to use Smart Switch to get data from your old phone and put it onto your new one. Maybe it isn't something they included in some countries? 
Yes, power transfer shouldn't be an issue.
I'm not expecting 100% adoption, but just based on my experience with the growth I've seen over the last couple of years in the Midwest (around where I live) I wouldn't be surprised if most places were accepting wireless by the time magstrips are phased out. My time living in Northern California was a different story entirely. A lot of local places accepted wireless payments, and even more so in cities like Berkeley which was packed with small shops and merchants. 


Magnetic strip readers aren't going away any time soon, and I expect Walmart will be as successful as CVS/Verizon/Tmobile, etc's versions of wireless payment tech (which went nowhere, despite a decent number of companies backing it). There's enough time for Walmart's attempts to fail a couple of times before we need to worry about not being able to use Samsung Pay at Walmart. 
I looked at data recovery services a while back (for an Hdd that I can't seem to figure out how to connect to my PC), and I wasn't able to land on what route I should take. A huge number of the sites I went to were full of the same info, same layouts and the same "We have the highest data recovery rate in the industry" claim. Makes me wonder if it's all owned by the same company or not (like that one cloud company that sells the same shitty cloud storage services under multiple company names).

Anyways, the site you linked doesn't have that claim plastered on the front page, so it already seems like a better choice than some of the ones I looked at.

If they're going to examine each disk individually (which they might need to do if your Hdd is totally out of commission), then 900 to 1400 sounds about on par with the rest. When I was looking it up, it seemed most places went with a ~$1 per GB rate for that kind of recovery. 
Other than the 5 minutes between transactions thing, there's no rules that I'm aware of. 

In the past, there's been a few times where I'd buy a soda from the vending machine for about a dollar, every 5-10 minutes. 

Last year, I was travelling abroad when the Chase 15 dollar reward for 3 transactions thing was going on, and I wasn't due to get back until the promotion was over. It was difficult for me to use a credit card or Samsung Pay anywhere (for a variety of reasons), but at one point we stopped at a McDonalds, which I knew would accept credit cards, and I made sure to buy 1 item per my 3 transactions and did that over the course of 20ish minutes. It worked out just fine and I got my rewards card sent to me in a matter of minutes after leaving McDonalds. 
You should have also received a [USB A to USB C adapter](https://i.ytimg.com/vi/g6iQUnEzOvk/maxresdefault.jpg) (it's the [black one in this image](https://i.ytimg.com/vi/Ja6KDwT4VgM/maxresdefault.jpg)). Plug the micro usb part of your cord into your Trezor, then plug the large end of the cord into that adapter and into your phone.

Another option is to buy a [micro USB to USB-C OTG cable](https://smile.amazon.com/MicroUSB-connecting-Controller-Smartphone-Computers/dp/B071SJ8S75/ref=sr_1_8?ie=UTF8&qid=1505967357&sr=8-8&keywords=micro+usb+to+usb+c+otg), or use a [micro usb to micro usb OTG cable](https://smile.amazon.com/Meenova-Mobility-Cable-MicroUSB-MicroUSB/dp/B00ZYB44UW/ref=sr_1_2?ie=UTF8&qid=1505967253&sr=8-2&keywords=micro+usb+to+micro+usb+otg) and use your micro usb to usb C adapter, if you already have one of those lying around.

Hmm. Not sure. A quick google search returned [this article](https://mobilesyrup.com/2017/08/22/samsung-pay-might-expanding-support-canadian-banks/). Sounds like they might be in 'beta' mode and only supporting a single bank at the moment, but they might be doing a wider release soon.
You can use chipped cards with Samsung Pay without issue. In my experience, almost every place I've visited either has a combo of chip reader + magnetic strip reader (swipe), or they have chip reader + wireless payments. In either situation you'll be able to use Samsung Pay. I've very rarely come across a place that only had a chip reader. 

Samsung phones/Samsung Pay won't work with chip reader only devices, but by the time folks phase out magnetic strips entirely, I expect wireless payments will be a much more common way to pay.
That sucks. If you haven't already, making a post in someplace like r/samsung might help. Maybe someone else has gone through this and knows of a better way to deal with it, or might have some other helpful tips.

I'm not the most familiar with dealing with CS, but I know people in random reddits often suggest tweeting and tagging the company's customer support twitter account in order to get someone to look at your ticket and speed things up. 

Anyways, I hope you have better luck with this issue going forward.

I'm not sure, but if it does, it'll only be the Samsung Pay app. The watch won't have the MST tech that's in Samsung phones which allow it to work with normal credit card readers.

So I imagine the watch has NFC, so you'd be able to use it anywhere they already say they accept wireless payments (ie Starbucks).
Yea man, fight the power and all that.

I'd totally join you in saying that, but my resolve isn't strong enough to pass up free money. Especially when it adds up to amounts I'd actually be able to use and requires no real change in how I go about my day.
Right, I know what you mean since Chase has certain months where you get 5% back on gasoline. On my statements, it shows up as if I didn't use Samsung Pay at all, which I expect is how it would show up for other banks/credit cards, even with Andriod Pay.
Nice, yea I hope it picks up soon. I think they might be building a new Kwik Trip near me in the upcoming months, so I'm guessing that one will have it.
Huh. I've just been using Samsung Pay at the gas pump. Seems safe enough for me. I mean, I have to swipe a fake card (I use a hotel NFC card which has no ~~barcode~~ edit: magstrip) while using Samsung Pay, because gas pumps need a physical card to be swiped, but it works.

It'd be nice if gas stations (at least in the midwest) started to implement NFC. Would save a lot of people trouble and headache, when it comes to having their credit card number jacked.
Gotcha, thanks.
Is it still in ICO/not-public yet?
There's been a lot of people hedging their bets on Filecoin. Filecoin has raised a huge amount of money from wealthy investors, so it seems they have a decent future ahead of them.

Anyways, Siacoin has some decent stuff planned, but the dev team seems to focus more on building the platform than they do in raising value for their coin (or even advertising, but they might be fixing that now). Given that Siacoin is the only, truly decentralized platform for file storage, I hope they do well.
How do you have that hooked up to your laptop?

I haven't seen any PCIe to thunderbolt devices small enough that you could hide it behind that PSU, and I don't think a PCIe to USB device would have enough bandwidth to pull of gaming (although it'd be useful for mining or something where latency isn't an issue).
Gotcha. I don't blame you, that's a pretty decent upgrade.

My parents had S5s, and they're still functional, waterproof and everything, but they are slow/borderline unuseable compared to modern phones. Touchwiz was pretty rough (in my opinion) in both terms of performance and in looks on Android 5.0.
Ah ok, so it's a Verizon thing. I was curious, because Final Fantasy just seems like...such an odd thing for Samsung to bundle. 

I got a Note 8 (unlocked from Samsung), and the only non-Samsung/Google app it came bundled with was Facebook.
Only thing is that you'll have to get the unofficial version of adhell to get it to work now since the official version was disabled (you can install it, but the app says to contact support or something).
If you still plan to get a Samsung phone, get it unlocked, from Samsung, or Bestbuy or wherever. Seriously, it's a much much better experience.

I got the unlocked Note 8, direct from Samsung (to use on T-Mobile), and the only non-Samsung/Google app on my phone was Facebook, which you can uninstall.
Well, you're sorta right but you used 'mining' in the wrong context.

Data mining is what you were thinking of, and that's what big businesses (Amazon, Google, etc) are all about.

This kind of mining on the other hand doesn't have anything to do with personal data, just solving complex problems for a payout, like mentioned earlier.
That's surprising. Just last week there was a slew of articles about being able to unlock the Note 8 via Face Unlock and a selfie picture and how the iPhone X is more secure. But really, face unlock is on all android phones (as part of the OS) and was never meant to be a secure method of authentication, just convenient.

Did they release an update since then? Cause I saw the Note 8's infrared light thing going off, which I thought it only used for reading irises. 
Phones only, I'd imagine. I wouldn't send in anything extra, since it'll probably get tossed (at least small things like cases and cables). 
Yea, I just found it there. And I've heard it can take a bit for them to review the device, but hopefully not all that long. 
Thanks, I found it there.
Gotcha, I found it. I guess if you click on your order number, it'll take you to their site and you can print it out. Thanks.
I preordered with Samsung and got my phone on 9/12. I would have got it on the 11th, but the package requires a signature and Fed Ex managed to show up for the couple of hours I wasn't in the house.

Overall, dealing with Samsung has been a good experience for me...so far (I still have to figure out how to ship my old phone in for that extra discount). Plus, unlocked phones are definitely the way to go.
I have the same issue with Coinbase. No matter what address I try (M or 3), it just won't send it. For some reason it doesn't even populate the fee, but it does give me a checkmark next to it as if it recognizes it as a legitimate address. 

It's not efficient, but I basically just transferred to Bittrex and then to my Trezor wallet.
Cool, thanks.
I kinda wish they would just upload their livestream to youtube as well. That'd make life easier for everyone, plus a lot of other companies already do this for their own conferences (like MS).
Project onto your retinas? Or [project](https://youtu.be/qElEtRf6rMg?t=1m54s) from your retinas?
I think I know [exactly](https://youtu.be/qElEtRf6rMg?t=1m54s) what you mean.
There's a lot of animals that can show complex emotions, many that are intelligent (relatively speaking), or otherwise demonstrate traits that indicate they can, in some sense, grasp what's happening and respond to that in the future. Crows, elephants, dogs, are all excellent examples of this. Crows and elephants can even [communicate to others](http://www.popsci.com/science/article/2012-06/how-crows-recognize-individual-humans-warn-others-and-are-basically-smarter-you) that a person in particular (or place with humans in it) is helpful or should be avoided. They can do it [well enough](https://www.thedodo.com/elephants-travel-humans-help-1353631970.html) that animals who have never seen that individual or been to that place, will know how to respond.

I don't imagine this guitar shark is intelligent enough to comprehend whats going on enough that it sees humans as trustworthy, but if it were, it's quite possible it would still see humans as a threat. This guy is putting the shark back, but as someone pointed out below based on what he's wearing, he could have been the one who fished it out of the ocean in the first place.
You already bought the car at a subsidized price point which is why I think it would be silly to believe you have an inherent right to that 8th cylinder unlock from the manufacturer. Of course there's the long discussion that could be had on an economy with socialistic type tendencies vs capitalistic ones and whether a company actually needs to produce a profit to provide proper competition in a market, but I'd rather not get into all that.

But, and I say this sincerely: if you want to go unlock the extra capacity in your Tesla battery, or you want to use that self driving hardware, or those hidden USB ports on your USB hub, or the extra capacity in your battery bank, or those hidden I/O headers/lanes/etc that the pre-built OEM isn't utilizing in base models, or the extra features, and (some disabled) cores that are entirely artificially limited in consumer processors/GPUs, or remove that electronic limiter in your car (if it has one), or in any number of other instances in our economy where they are selling you a product that has more capability than the manufacturer allows, by all means, go ahead. I fully support this kind of thing, but it's easier to pull off in some cases, but extremely difficult to pull of in others.

I don't think it's deceptive in the least. When you go to buy a Tesla on the website, and you want the cheaper version, and they sell you a subsidized battery and tell you that you can unlock the extra capacity later with a software update (which would bring you to the cost of a non-subsidized product), I don't think anyone thinks they're doing this by magic.

I don't really understand why you're so upset/concerned by this. It happens all the time in the consumer market (and even in the enterprise sector as well), but those companies are doing it so they can increase their profit margin. Tesla does it to subsidize the cost of the product (they aren't cutting into profit margins, they're actually losing money on the product) and people think it's an absolute outrage. You say it's a slippery slope as if it's not already a common thing and that other companies might look at Tesla and say "well, why didn't we think to do that?". It's common and established business practice, and the reason it happens all the time is because manufacturing and supply chain costs aren't so simple that every company can just make a dozen versions of every product if they want to sell a lower cost version. If it were truly that simple, they would just build a lesser/cheaper product so they can maintain even higher profit margins. Given what the market already looks like, at least Tesla is bucking the trend by doing this when it's unprofitable for them. 

But if you honestly want to know when Tesla will stop selling those cars with the software update to unlock the extra battery capacity, it will be when it's profitable to sell a base car. If you follow the news, then you should know they've dropped prices on the software update for folks who own the lower specced Model S cars (which they've also stopped selling; not because the base model is providing the profit margin they want, but because they don't need to sell a lower specced Model S when the Model 3 is an option now). Given that they currently operate in the luxury market where brand is one of the most important aspects in purchasing a car, and that Tesla doesn't have any serious competition of any kind for the type of vehicle they sell, they have 0 reason to drop the price. They could have kept doing this for as long as they wanted.

Yet, you're worried that they won't drop the price when the time comes that it's profitable to sell base Model 3 cars in the incredibly cost competitive mass consumer market where they are going against giants like GM, Ford, Volkswagon, etc etc. The second it becomes profitable to sell base cars with that large of a battery, every other car manufacturer will be selling those cars as well (and they may even be buying parts from Tesla if Tesla has extra units that they can sell, like they used to for Toyota and Daimler). The entire reason Tesla is using the model that it has now (where they'll likely be operating at a loss for years to come), is because they have to get as large a foothold in the mass consumer market that they can get and start early because they don't have anywhere near the mass production manufacturing capability that the giants do. 
Are you talking about running a speedtest from the internet, or are you talking about link speeds?

I mean, in either case I guess it doesn't really matter because you aren't getting Gb speeds anyways, and your school's bandwidth control/QoS setup is likely limiting you.

Either way, when you talk about the difference between lab settings for ethernet and wifi, you're talking about drastically different things. In ethernet, you're talking about losses due to distance, potential crosstalk, or minor things like that. In wifi, there can be other devices sharing the same bandwidth, or interference from other wireless sources.

If you take 10 devices and stick them all on a halfway decent switch (capable of 1Gbps per connection of course, using cat 5e/6 cables), then you can have 10 devices saturating their respective connections and seeing close to 1Gbps speeds.

On wifi, things are nowhere near as simple. If you take a router and you only put a couple of devices on it (basically recreating a lab setting), then you'll likely see good speeds for both devices. Stick any more devices on your wifi network and your performance will go down because all these devices are using the same shared bandwidth. That's not even taking into consideration if there's any interfering wifi networks. 

I have a 4x4 MU-MIMO router capable of 1.7 Gbps (on AC channels anyways), and I have no interference, but I don't see Gb speeds on my devices despite them being compatible and it's because there's other devices and users on the network that need bandwidth too (albeit most of them don't need much, just enough for Netflix/browsing). I don't have this same problem on my switch, where devices see almost all of the Gb connection they're on.

Also, I'm talking about network tests, not internet speeds.
Your price is off by about 10 grand. If they sell every car at 37k, then they will take a loss on every single car they sell. At which point, you'd have to wonder why they'd bother selling any cars at all. Operating at a loss is something Tesla is familiar with, and not a big deal given their long term strategy, but they've never taken a 100% loss across the board on an entire line of vehicles. 

An analysis by UBS has said that for Tesla to break even, they have to sell cars at 41k. Everytime someone buys all the software options, and they bring the price of their car above 41k, they are helping Tesla offset the costs of selling a car to someone else at under 41k.

Even as it is, the price of 35k never made sense on paper, since the cost of the battery alone would eat up so much of the car's costs...then you have to add in the fact that they also ship every car with self driving hardware built in. 

The reason they are shipping cars with larger batteries and self driving hardware, and then just subsidizing the cost, is for two reasons. First, they don't have the manufacturing capacity to spare on a massive project like creating an entirely new line of batteries and then an entire new configuration of Model 3s. As it is, you only get 2 options, change the color of the car or get larger rims. And they aren't even manufacturing both of those configurations at the same time. They are doing it in runs, so if you wanted a red Teslay, you'll end up waiting until they start doing their red production run.

Secondly, they subsidize the price because this is their mass production vehicle. Average people aren't going to buy a car that costs 45-50k upfront (they simply wouldn't be able to afford it, even when you consider federal and state rebates). But what they might do, is spend money on upgrades down the line, like extra range or self-driving software. Which is what Tesla is hoping for in order to recoup the costs.
I used to have this issue often, but it only happened when I tried to wake my Surfacebook using the trackpad. 

I'd use the trackpad, the keyboard would light up but my SB wouldn't turn on. If I pressed the power button to wake the device while the keyboard was lit, then the mouse/keyboard wouldn't respond. If I waited a bit after the backlit keys turned off, and then pressed the power button to wake it up, the keyboard/mouse would work normally.

I don't have this problem anymore, and I suspect one of the driver/firmware updates I did back in March (or April/May, I don't recall exactly) probably fixed the issue. I was having a separate, more serious issue, so I went through and updated and reinstalled/updated all the firmware MS had for the Surfacebook. 

Now it's a bit different. If it's been a sleep for a short period, I can wake it up with the trackpad without issue. If it's been asleep for a while (not long enough to enter hibernation), trackpad won't wake it up, but hitting the power button when the keyboard is illuminated only results in a 3 second period where the trackpad won't register. Otherwise, it's fine.
Same here. I have a lot of linux isos across many different categories, but I doubt I'll ever get around to reading/watching even 20-30% of them.
Nice. What NAS/OS are you running?

As for me, it's all tossed on direct attached storage instead of on my NAS, and also uses the ["Stuff"](https://i.imgur.com/KEhPepE.jpg) label. 
My total collection of linux isos is about 30ish to 40TB in size (not including backups).

Of that total set, the linux distros that you're asking about are about 7.5TB in size (although realistically, it's probably 7TB as there's probably a lot of duplication).
I can't tell you how many times I've been asked the question "Do you really need that much of X?". Never been asked that about porn, but I've been asked that about everything else I store by friends/family. Sure, they love to use Plex, but when they hear the raw numbers behind it, they always ask that. 

"17thspartan, do you really need that many linux isos? Why do you need a 4k version of this linux iso when you already have a 1080p version of it? This linux iso is still in theaters, do you really need to download the web-dl and the bluray versions?"

The place is called r/datahoarder, I can guarantee you that nobody needs to store as much data as we do (if anyone ever did, then it's not really hoarding is it?), but we're gonna do it anyways.
Thanks, and yea, it's very much a buyer's market at the moment with Sia. I think some of that comes from the apparently steep technical curve to become a renter (folks on Sia's reddit have complained about that). Not a big deal for enterprise users, but enterprise users will only start flocking to Sia once they have a more fleshed out or proven product (which the devs seem focused on creating). In the mean time, lowering the bar to allow more normal consumers to jump in as renters, might be a worthwhile to even out the market, even if it isn't profitable in the long term. Which is an [issue](https://www.reddit.com/r/storj/comments/6yk01a/august_payout_sheet_posted/dmpp3zu/) that Storj seems to be working on now, as they've apparently been subsidizing hosts by paying out more per shard than they receive from renters.


Either way, it'll be interested to see where things stand in a year or so, with all the new companies jumping into this space, and when companies like Storj and Sia have more mature products. 
For features that Touchwiz doesn't have, the only thing I'm interested in is changes they made to help password managers with autofill.

Otherwise it doesn't seem like a terribly exciting update in terms of new features; just lots of background improvements (app icons, restrict background apps, bluetooth improvements, etc).
If you run custom roms, or AOSP type roms to get the latest update, then you should know that they ship with lots of things broken that get fixed over time in the nightlies.

No normal consumer would ever accept that kind of experience. I accept it, but I'm fine with troubleshooting, and losing the ability to auto-rotate my screen, or losing cellular data access (or similar things) aren't as much of an issue for me because I don't put custom roms on my primary phone.

Multi-billion dollar companies aren't dumb enough to shoot themselves in the foot like that. They do extensive testing before pushing an update.
Yea, I'd probably be weary as well, mostly cause of potential coin price fluctuations. I've never used it, and I don't know much about whether Sia hosts are making a profit, but it sounds like you're one of the luckier ones on Storj (getting lots of data assigned to you), so that's probably the better option. 

But I can understand how Sia's system (including collateral) can be offputting. For anyone not familiar with the differences between the two platforms:

Sia is geared towards enterprise renters (or tech savvy users), with the entire system being decentralized, and you (the host) setting the prices. Since the renter takes the risk of starting a contract with a given host (and there's a reputation system to help with that), the collateral system makes sense (to me) to help reassure renters that you'll make the necessary efforts to uphold the contract you set/agree to (ie, uptime, avoid data loss, etc). You can set how much collateral you want to commit (you get reputation bonuses for offering more than is necessary), but you only need to put up enough to cover the prices you charge, so smaller/shorter contracts (using less collateral) is definitely an option as well. With Sia, the renter pays the host for all storage and upload bandwidth used. The renter can set up as many mirrors as they need (by starting contracts with others), and they can probably set up a several mirrors before they hit Storj's prices. If a host doesn't fulfill the contract (ie has more than 2 days of downtime in a month), then the collateral is 'burned'.

Storj is much simpler/straightforward, primarily because renting prices and host payouts are set/fixed by a centralized source (Storj Labs), it's a consumer facing service, and only part of the host's upload bandwidth is paid. With Storj, redundancy is included in the price, but all mirrors are created using unpaid bandwidth (the hosts supply the bandwidth and therefore have to cover any associated costs), which allows for a more flexible system with no need for collateral. If a host loses data/goes offline, then the other mirrors are still available to the user, and the mirroring hosts are responsible for covering the bandwidth costs to make a new mirror. So if you (as a host) met the requirements for that month (uptime, at least X amount of data stored, etc), you get paid, if you didn't, then you just don't get paid that month.

Makes for a much simpler, and much easier to use system for both renters and hosts, and allows for the easy month to month payouts (as opposed to being paid when the contract is up, whenever you set that to be). Not to mention that in its current state, Storj is much more user friendly than Sia; which is something I hope Sia will change sooner than later.
I'd be careful before choosing which service to go with, the tech behind some is sketchier than others (personally I prefer decentralized solutions). There's quite a few available in this general area (Sia, Storj, MaidSafe, FileCoin, etc.), some of which have been around for a while now.  Some will definitely be more profitable than others in the short term though, and you could absolutely hedge your bets and use more than one at the same time if you have the storage space to spare.

Personally, I'm hoping for Sia to pull through. The dev team seems determined to provide a good platform and features (many services/coins/tokens often seem too focused on raising money/building token value), they're looking to the future and provide methods to better secure the network (against 51% attacks), and it's a fully decentralized solution as well (which can't be said for all of the alternatives). 

Still, probably not the best option for short term profit, but if you're in it for the long game, might as well sell some of your storage on all the platforms and rack up some money. 
Yea, my build was going to be built around virtualization (with some side gaming), and the TR processor looked perfect for it. I might have to consider going the Xeon route in a second computer, or possibly using a cheaper i9 instead of TR.

I believe you can use Xen on Ubuntu, but I've never used Xen so I can't say much more than that. A quick google search suggests that the package is available on Ubuntu.

As for the Nvidia thing, KVM has a way around this and it accomplishes that by hiding the VM state. I don't know of any way to do that in Xen, but I did find out recently that it's possible to do this in Esxi, so that's a potential option as well (local gaming might be a pain to set up on Esxi though).

For KVM, you just add this bit of code to the VM XML file if you want to [pass through an Nvidia GPU](https://medium.com/@calerogers/gpu-virtualization-with-kvm-qemu-63ca98a6a172):

    virsh edit vm-name

    # Add to file within <features> </features> tags

    <kvm>
      <hidden state='on'/>
    </kvm>
I hope they release it soon. I'm still waiting on my refund for my (extra) Trezor 1, so I can put that money towards a Trezor 2.

Going forward, the Trezor 2 does sound like a better product, because as I understand it, the platform will be easier for them to add new cryptocurrencies, and others can develop for it more easily. Still, I hope the Trezor 1 gets some love soon. Seeing Ledger get support for cryptos like XMR and others, has got me a little envious. 
Yea, I've been wanting to get a threadripper build going since it first released, but the only thing really holding me back is the lack of [good KVM support](https://community.amd.com/thread/215931). There are [some workarounds](https://level1techs.com/article/ryzen-gpu-passthrough-setup-guide-fedora-26-windows-gaming-linux) ([video related to article](https://youtu.be/aLeWg11ZBn0); a more recent [video guide](https://youtu.be/cDbn98QTAbg)) for varying levels of performance, but I'd rather wait until the issue is solved in earnest. 

If you're fine with using a hypervisor that assigns resources at boot-time (ie: the GPU you want to passthrough would be assigned to your Windows guest OS whenever you boot the host OS), then Xen (on an OS like Fedora) might work well for you as an alternative to KVM. From what I understand it gives pretty good performance on AMD CPUs. Only thing is that Nvidia GPU drivers will detect that you're running in a virtual machine and will prevent the cards from working properly (if you use a consumer GTX card). So you'll have to find a way around that or passthrough AMD GPUs (which aren't artificially limited the way Nvidia cards are).

As RPGs have taught me, weight management is key when adventuring outside. By removing all the components and leaving the case, the OP has drastically reduced their carrying weight, while maintaining the option to forge/purchase a new PC case and regain their buff stats.

But in seriousness, I think the only thing I would have removed is the GPU, and only if I thought a bump on the road would have dislodged it or caused it to sag/bend (assuming OP is driving). 
If you're running Ryzen processors (or earlier AMD processors), then they don't play well with KVM. Folks are only just now starting to try and address that issue. 
~~What are you running as your hypervisor?~~ Edit: Saw you mentioned KVM.

I've been wanting to jump on a 1950x, but the lack of good KVM performance/support is holding me back.
I originally signed up for it about 3-4 or so years back (could be longer), and I most recently tried it out again in early 2016.
I've only ever used it on Android and at the time it was too much of a pain for me to keep it going. The only reason I had it was because they offered a lifetime, unlimited storage for a one time payment of 50 bucks.

When uploading, it separates files into different categories and uploads them like that. All pictures get grouped together, all docs, all music, etc. For my use case, I needed some of those pictures/music/docs/etc to stay in their original folder structure, but that wasn't really an option. If it came across files it didn't know how to categorize, then it would keep the original folder structure, but there was no way to get it to apply that to the other file types. Talking to support got me nowhere, so I just stopped using the service altogether. 
I've never used ARK, but I suggest googling 'ark wallet' and go with a desktop client.
Bittrex.com

Buy bitcoin at Kraken, Gemini, Coinbase, etc then send it to Bittrex and trade that bitcoin for ARK.
Ok sounds good.
Hmm, with a 1080, you should still be able to net around 12 cents per hour. Even without an optimized driver, you shouldn't be that far off, especially since folks do use 1080's on Windows to mine. 

Whattomine says the best algorithm right now is LBRY (mining the LBRY coin) or Equihash (mining ZCash). 
That's good to know going forward. I'll probably just go with getting 2 because I know it's something that would work for sure (lots of other people already do it). 

I was just curious to know more about PSUs and whether powering a riser using a molex plugged into a PSU's peripheral port was any safer than using a SATA plugged into an identical port.

Thanks for the reply though. 
Really? That doesn't sound right, unless you're running something less powerful than a 750ti (possibly too old to have optimized drivers for a given algorithm?). 

I don't pay for electricity, so I've been having my old i7-2600 mine, and it gets about $.025/hour. I originally had it start mining as part of a stress test to see if I should use it as a Plex server, but I've decided to keep it running until October; because I should have about 40 bucks of XMR by then.
Do you have the mobo sitting on something, or is the cart made of a non-conductive material? It's kind of hard to tell from the picture.
Now it just needs some racing stripes to make it mine faster.
Indeed, which is why I said that my explanation was simplified. But the number of miners on a network has a big impact on how fast transactions can be. Difficulty is designed to scale appropriately, but if there aren't enough miners on a network, we end up with what Bitcoin has been going through recently, with transactions that take far longer than usual, despite having higher than normal fees. A few days ago I ended up waiting an hour before I received my first confirmation, despite paying a 5 dollar fee on a 20 dollar transfer.

If miners weren't going back and forth so often between Bitcoin and Bitcoin Cash, then this likely wouldn't be as much of an issue.
Well taking that route is certainly an option, but what you're talking about is basically investing in a coin, which is not what I'm advocating at all when it comes to mining for quick profits. When I'm talking about making X per year, I don't account for price changes because that kind of thinking is too long term for my tastes (at least when mining is concerned) which is why I included the qualifier "at this very moment". The exception is if you're trying to mine on weak hardware (and have a high pool withdrawal minimum), in which case electricity costs would likely make mining unprofitable anyways.

What I'm suggesting is that people should do what most miners already do; hop from coin to coin. Mine the most profitable coin, withdraw regularly and convert it to another currency (whether crypto or fiat), and when the difficulty is raised too far, or it's not as profitable as it should be for any reason, move on to the coin that took the top spot as most profitable for your hardware.

Of course another option is to just let the currency sit, while using stop limit orders to prevent being caught off guard by a market correction. This is what I do for my investments, because with the tools made available to everyone, there's no reason anyone should have to be a 'loser' when a bubble bursts.
Sure no prob. And I know mining gets a bad rep, especially in places like this, but I don't see it as a bad thing. Like everyone else, I'm bummed I can't buy graphic cards at MSRP (especially since I'm looking to build my first HEDT PC soon), but I fully plan to use mining to recoup all the money I spend on my new, badass PC, once it's built...and when I'm not using it, of course. 

Everyone is mad at miners for raising prices on GPUs, but I see it as an opportunity to pay off my expensive PC builds. Sure, it might [take 200-250 days](https://whattomine.com/coins?utf8=%E2%9C%93&adapt_q_280x=0&adapt_q_380=0&adapt_q_fury=0&adapt_q_470=0&adapt_q_480=1&adapt_q_570=0&adapt_q_750Ti=0&adapt_q_10606=1&adapt_q_1070=6&adapt_q_1080=1&adapt_q_1080Ti=2&adapt_1080Ti=true&eth=true&factor%5Beth_hr%5D=70.0&factor%5Beth_p%5D=280.0&grof=true&factor%5Bgro_hr%5D=116.0&factor%5Bgro_p%5D=420.0&x11gf=true&factor%5Bx11g_hr%5D=39.0&factor%5Bx11g_p%5D=340.0&cn=true&factor%5Bcn_hr%5D=1660.0&factor%5Bcn_p%5D=280.0&eq=true&factor%5Beq_hr%5D=1270.0&factor%5Beq_p%5D=380.0&lre=true&factor%5Blrev2_hr%5D=128000.0&factor%5Blrev2_p%5D=380.0&ns=true&factor%5Bns_hr%5D=2800.0&factor%5Bns_p%5D=380.0&lbry=true&factor%5Blbry_hr%5D=920.0&factor%5Blbry_p%5D=380.0&bk2bf=true&factor%5Bbk2b_hr%5D=5600.0&factor%5Bbk2b_p%5D=380.0&bk14=true&factor%5Bbk14_hr%5D=8700.0&factor%5Bbk14_p%5D=420.0&pas=true&factor%5Bpas_hr%5D=3400.0&factor%5Bpas_p%5D=420.0&factor%5Bskh_hr%5D=95.0&factor%5Bskh_p%5D=380.0&factor%5Bl2z_hr%5D=420.0&factor%5Bl2z_p%5D=300.0&factor%5Bcost%5D=0.1&sort=Profitability24&volume=0&revenue=24h&factor%5Bexchanges%5D%5B%5D=&factor%5Bexchanges%5D%5B%5D=bittrex&factor%5Bexchanges%5D%5B%5D=bleutrade&factor%5Bexchanges%5D%5B%5D=bter&factor%5Bexchanges%5D%5B%5D=c_cex&factor%5Bexchanges%5D%5B%5D=cryptopia&factor%5Bexchanges%5D%5B%5D=poloniex&factor%5Bexchanges%5D%5B%5D=yobit&dataset=Main&commit=Calculate) before I can pay off 2 1080tis (@1500 dollars), but I'd rather my PC earn me 1500 bucks over 250 days, then never get that back at all.
Depends on a lot of factors. If you have high electricity costs, then no, it's not a good idea to mine.

But, if you have low electricity costs, and you're mining the right currencies, then it's a good way to make back the money you spent on buying your badass gaming PC.

For example, if you were to mine Sibcoin at this very moment, with a single 1080ti, assuming 1080tis cost 760 dollars, your electricity costs is 10 cents per kWh, then you would spend 201 days before you recoup the costs of your GPU entirely. Everything after that is profit, albeit a small amount, ~3 dollars a day, leading to 1.3 grand a year. Add another 1080ti, and you're making 2.7k a year. At 4 1080tis, you're making just short of 6k a year. 

6k might not be much to some, but I can think of a lot of interesting ways to spend that. If nothing else, you can afford to build a new HEDT PC every year (with money left over).
Mining is how transactions are processed for cryptocurrencies. More miners = faster transactions (to a degree anyways, my explanation is simplified). Nobody wants to go buy a coffee and then have to wait an hour before the barista can verify that they were actually paid and then give you the coffee.

Mining is basically running as many calculations as you can so you can create/validate a block (a block is many validated transactions stuck together). CPUs are good at calculations, but what you really need is lots and lots of cores to run simultaneous calculations. GPUs have way more cores than CPUs and the more GPUs you have, the more calculations you can run and the better your chances of creating/validating a block.

Miners get paid in two ways, transaction fees and cryptocoins. If they're mining Ethereum (for example), then if they're the first to create a block (by validating those transactions and sticking them together) then they will be rewarded with new Ethereum tokens. They also get paid by whatever transaction fee you pay when you're sending money. 

Also GPU mining isn't as useful anymore on Bitcoin; since there's specialized hardware that performs well enough that it leaves normal GPU miners in the dust. When you see people with big rigs of GPUs, they're mining something else, often Ethereum.
Gotcha, I went ahead and installed the desktop client and it's showing the proper balance. Thanks for the heads up. I'll wait until any security audit/testing is done before using iota-wallet again (especially since it was giving me different receive addresses than the paper wallet and desktop client).
I saw the same review as OP's on Amazon a week or so back, and I was fully prepared to write a comment to correct them, but there were 4 people who called the guy out properly. 
This is definitely true. I was going to wait for the Pixel 2 before I decide what phone I wanted, but with this discount, they won my attention. I went ahead an pre-ordered. 

Plus, given how polished Samsung phones are nowadays, I know I won't regret jumping on this early and wonder about the grass being greener on the Pixel side. 
Sure no problem. As for the Gpu temperatures, most desktop GPUs can handle up to 80-90c without damage. At 73C under full load, that means your cooling is working well. Many folks run them years at full speed, so I wouldn't worry too much about damaging unless you see it hitting above 80-90c range. 

Nice hash is the easiest to use but there are some pools for ethereum mining. I haven't used them yet but some of the pools just give you and address to type into the command line miner (claymore I think). I think the wiki has info on pools to join and software to use, and the pools often have tips/faqs/or help sections to get you going. 
I'm doing some CPU mining just for the hell of it (don't have to pay for electricity, and I figured I'd try it out until my first payout), and I was netting 140 H/s in cryptonight on v2, but was able to get 200-240 H/s on the latest legacy miner. 
You should mine whatever currency you want. Beyond that I don't know enough about alt-coin mining to know what is the best day to day route to take

Also, I think the only reason it's showing ETH with a green border is because it's using that as a profitability baseline. It should show that ETH is perfectly 100% profitable, while every other currency is shown as being more profitable than ETH or less (93% is less profitable than ETH, while 108% is more profitable; whatever is at the top of the list is the most profitable coin).
The coins that were transferred to you were ETC coins, and you're probably looking and seeing both etherscan and myetherwallet reporting 0 ETH.

In the upper right of myetherwallet, there's a 'network' drop down list. Click on it and switch to ETC. Then go to view wallet info and type in your public address. You'll see that you have 2.247ETC in your wallet.
1. It depends on what you want to mine, or what you're being paid in. If it's [mining Ethereum in a pool](https://www.youtube.com/watch?v=Z6lE0Ctaeqs), you can check out the [Mist wallet](https://github.com/ethereum/mist). If you're mining something else, you'll need the wallet for that currency. A site like Nicehash is very beginner friendly, but, regardless of what you mine, it always pays in bitcoin; so you need a bitcoin wallet like [Electrum](https://electrum.org/#home).

2. You can, but it probably won't be profitable. For reference, I'm CPU mining with an i7-2600@3.4GHz (and only because I don't pay for electricity). I'm currently mining Monero (XMR) (one of the only coins you can actually mine with a CPU and make a profit), and that gives me 200-240 H/s. If you assume the power consumption of the entire machine is 200 watts, and that you have to pay $0.12 per kw/h, then you'll make 36 dollars after an entire year of non-stop mining. If you know the hashrates of your hardware, or hardware similar to yours, then you can use [this site](https://www.cryptocompare.com/mining/calculator/xmr?HashingPower=240&HashingUnit=H%2Fs&PowerConsumption=200&CostPerkWh=0.12) to play around with how profitable it is to mine ETH, Monero, etc. Here's [Nicehash's profitability calculator](https://new.nicehash.com/profitability-calculator), but they only have few CPUs listed, so you'll have to select whichever is closest in performance to yours. If you want to do GPU mining, [this site](https://whattomine.com) is very good for calculating your GPU's potential hashrates for different algorithms and calculates which algorithims and currencies are most profitable for your GPU.

3. One of the easiest options is [Nicehash](https://miner.nicehash.com/). Download their software, enter your wallet's receiving address (remember you have to use a Bitcoin wallet's receiving address, or else you'll lose the money they try to send you), and click start. Before clicking start, I recommend you click on the "Hardware details" button so you can run a benchmark and get an idea of how well your hardware will perform. If you use their legacy software, it'll have a lot more options, and I found that by tweaking some of them, I was able to go from 140 H/s to 200 H/s.

4. You won't have to pay taxes on the coins you receive in your wallet. The pool you're in might charge a fee each time you redeem your coins and have them sent to your wallet. Since they're still just coins, you'll have to use an exchange like [Coinbase](https://www.coinbase.com/) to turn that into fiat (USD), and transfer that to your bank account. At that point you'd need to declare the money you get on your taxes; here's [Coinbase's article](https://support.coinbase.com/customer/portal/articles/1496488-how-do-i-report-taxes-) on that.
They should work fine, especially since many use the same algorithms.

Check [what to mine](https://whattomine.com) to see what your rates would be like with your cards.
Cool. I'll have to check those out. Thanks for the info. 
Oh sorry, I was talking about switching currencies when mining. I should have worded that post differently.

I'm just curious how normal folks (folks who are running 1-6 GPUs) go about moving from mining Eth to XMR to Sia, etc. Do they just pick whatever currency is on the rise and then find a pool to join? Or are there pools/websites that handle multiple currencies, so you don't have to find a new group or make a new account each time you want to switch?


A couple, but at the time they weren't worth much and unfortunately I wasn't using a proper password manager (just chrome), so I lost that wallet. I didn't feel bad about it then, because I didn't mine seriously, I just did it as an alternative to running Boinc. Now, I definitely regret losing it. 

There'll forever be a wallet out there with anywhere from 1/4 bitcoin to 3 bitcoins that nobody can access. 
Well, I'm glad to hear it's not just me/coinbase. I've been waiting over an hour and a half for Coinbase to give me a link to my transaction so I can monitor it. Usually an hour is enough time for me to get all the confirmations I need.
True. I was going to make a quip about the waste heat of those GPUs contributing to climate change on their own, but I guess they'll certainly play their part given how much electricity they use (and their source).
There was a (Vice?) mini documentary I saw on youtube recently about mining in China.

They went to this massive factory and the cable management was anxiety provoking. Similar to the above picture, but managed a bit better so they can walk around. Still, they had thousands of GPUs in that warehouse.
Is it easy to switch from currency to currency like that?

Does your software make it easy to switch currencies? Or do you mine until you make an amount high enough that you can transfer it out and then join another pool for the new currency you're looking into?

I've been looking to get into mining again, but the last time I mined it was 2012 and bitcoin was pretty much the only thing around worth mining for.
So, using Cryptocompare, at 551MH/s, and assuming the combined wattage of your CPU and GPU at full load is 600 watts (at $.35/kwh) then you should be making 40 dollars a day.

If it's saying you're getting 551MH/s, then you're not mining ETH.
**Tl;dr:** Markets/exchanges store the coins you buy in the wallets that are automatically created and associated with your online account. It's safer to store them in a wallet you fully control though, so get a hardware, desktop/mobile, or paper wallet instead.

Long post, but I'm kinda new too, so I thought I'd share what I learned along the way. I'm also investing for long term usage, so I'd suggest you check out Ethereum as well. It's more than just a cryptocurrency, and with businesses like JP Morgan or Microsoft developing on that platform, I think its value might grow quite well.


Coinbase is very easy to use, you type in how much USD you want to spend and then click buy and credit/debit will give you instant access to your coins. You'll be paying a bit of a premium in places like Coinbase, because they're acting as a broker. [GDAX](https://www.gdax.com/) is Coinbase's exchange which lets you do trading if you want, or you can just place buy/sell orders at market prices. 

Places like Coinbase and Kraken have limits on how much you can buy/sell at first. Instead of buying an entire bitcoin all at once, I prefer to buy small amounts on a regular basis and buy a lot more when I see the price dip down. Bitcoin's price changes a lot, so while it is 4k today, it could be 2-3k next week/month, or even 5k. Bitcoin Cash was $1000 a day ago and is $750 today. Buying it regularly at smaller amounts helps me avoid any buyer regret should the prices dip or crash.

To send bitcoin (like from an online wallet to one that you control) is really easy. All you really need to do, is click ['send bitcoin'](https://support.coinbase.com/customer/portal/articles/971437) and type in a receiving address and how much you want to send. Hardware and software wallets will automatically generate receiving addresses for you, so you just need to copy and paste. 

There's a lot of options available as wallets to store cryptocurrency. Hardware, like [Trezor](https://trezor.io/) or [Ledger Nano](https://www.ledgerwallet.com/products/ledger-nano-s) (both devices support having multiple wallets for different currencies); desktop software like [Electrum for BTC](https://electrum.org/#home) and [Electron Cash](http://www.electroncash.org/) for BCH; [paper wallets](https://en.bitcoin.it/wiki/Paper_wallet) ([which is basically offline storage](https://bitcoinpaperwallet.com/wallet-tutorial-add-withdraw-funds/)), and there's wallet apps for smartphones too, but I've never used them so I can't comment on it. 

Personally, I've used Trezor (for BCH, BTC and ETH), Electrum and Electron, and a paper wallet (for Ethereum). For hardware wallets, they're available on Amazon, but the prices vary a lot based on how much stock is available. Last month Trezor was at 200 bucks, but I got one a few days ago for 100.

Software and hardware wallets will ask you to write down your seed words (which lets you recover your wallet if your device breaks or anything like that), and paper wallets will have your private keys printed on it. Until you're ready to give it to your kids, you should make sure nobody ever sees your private keys or seed words. Also, don't send BTC to a BCH wallet address, or vice versa. 

I don't want to dissuade you from investing in any cryptocurrency (but a lot of people will try to push you away from BTC or BCH depending on what camp they're in), but it's possible one of them could fail entirely (or both could lose value given how much infighting there is in the bitcoin camps). If the time comes that they are failing or losing value, you can exchange them for other coins quite easily at places like [Bittrex](https://bittrex.com/home/markets) or [Shapeshift](https://shapeshift.io/).
Yea, I'm pretty bummed about it as well, since I really want to get my build going and pull the trigger on threadripper, but I don't want to do it until I know I have a good virtualization solution for my needs. The only thing keeping me away from Xen is the fact that it assigns all resources at the host's bootup, so to free up resources after a VM shuts down, you'd have to reboot. 
I think Xen should work fine, since it seems to work well on the Ryzen platform. 

KVM is a different story though, because Threadripper, Ryzen, FX CPUs all suffer from the NPT issue; so you get to choose between good CPU performance with poor gpu performance or ok gpu performance with poor CPU performance.
Gotcha, its the same for the Xbox One. Some of my files are just too high of a bitrate for my Plex server to transcode the file smoothly, unfortunatley. Which is something that hardware transcoding could probably fix. 
Only two things I can think of are the remote streaming settings which are usually set to [720p by default](http://i.imgur.com/h9aF5sO.jpg) (assuming you're streaming to your friend's PS4 over the web), or transcoding issues. 

Plex does software transcoding for the most part (unless you're on their forum-only release, which has Intel hardware transcoding), whereas Emby does full hardware transcoding (using Intel, Nvidia or AMD cards). When you say the request timed out, or they take a long time to start, it sounds like it's trying to transcode and build up a buffer before starting playback. If the PS4 is capable of it (and your internet connection is fast enough), you should try changing the remote streaming setting to "original" to allow for direct playback (if you haven't already).

Anyways, with me it's just local playback, but my Plex server has issues transcoding certain files for viewing on my Xbox One, which is a problem that hardware transcoding would probably fix. 
I'm unsure of how well it works, and it won't have anywhere near as many features as Plex, but [Streama](http://dularion.github.io/streama/) is fully open source. Other than Emby, I think Streama is the only other name I've read when browsing the r/Plex reddit. 
Yea, I've never even considered using Emby, or any Plex alternative until the other day. I felt that Plex got everything I wanted done (except for hardware transcoding), and they keep adding new features that I can use (like Plex Cloud).

I wasn't sure if I would actually change to Emby or not, since I didn't even bother to opt-out of their data collection before (so aside from a principled stance, not much was changing for me), but I thought it would be a good time to see what options were available.

Edit: While one could say that their reaction was just due to the fact that they're losing business, or something along those lines, I'd like to say that their adding the new 'privacy tab' in the server settings, so you can see what is being sent to Plex is a really nice touch. I certainly appreciate them going above and beyond with that.
Does that mean they're ditching KVM, or adding an alternative to it?

As I understand it, the NPT issue is related to the KVM kernel, which would be up to the KVM devs to fix. 
Gotcha. That's unfortunate. 

I guess the next closest thing to Plex is something like Streama, but that's still quite a ways away from Plex, especially when it comes to features and the like. 
You mean you want to access your server when you're outside the home? Or just access the server over your local network? 

If you're talking about accessing your server and Sonarr, from within your local network, then that's a not a problem (at least not with any VPN that uses something like OpenVPN...which Private Internet Access does). Your local network traffic will work normally, but any traffic headed to the internet will be intercepted and routed through the VPN interface.

If you're talking about accessing your server when you're outside the local network (like when you're travelling or something), then you could set up a static external IP and port forwarding on your VPN, if you wanted. PIA supports both features.

If you want all internet traffic to be routed through your home's IP address, but only use deluge on your VPN, then setting up a docker container (or possibly using a sandboxing app) would work best. Others in the thread have suggested how to set up a docker container to play nice with a VPN in that way. Of course running a full fledged virtual machine would do the trick as well.
Looks like Emby does have live TV.

I guess I must have overlooked that feature when I was looking at reviews/videos of their applications. 
I'd be interested in knowing this as well.

I really wanted to use KVM with threadripper, but that's not a good option anymore because of the NPT issue. So I've been trying to narrow down which hypervisor would be best for use with Threadripper before I buy it and build my computer. 

I know Xen works, but it requires host reboots to properly assign resources (plus the unsigned drivers thing for Nvidia cards), and ESXi might work, but I wanted to game as well, and ESXi doesn't play nice with local, non-console keyboard, mouse, video access (at least from what I understand).

Still, I'd be interested in hearing about your results if you do go through with this.
No need to take it as far as raw file access or media players. 

Emby is basically the same as Plex (minus the Plex Cloud) but it's open source and it supports hardware transcoding (nvidia and AMD cards as well, not just Intel).

Edit: Emby does have live TV.
Running a full VM for this seems like overkill. I run VMs as well, but for something like downloading, I just sandbox/containerize it if I feel that's necessary. I only run an app instance in a sandbox if I think it's downloading something potentially harmful.

1. VPN: I use Private Internet Access, which uses OpenVPN (TAP driver), and that creates a new network interface. The way the TAP driver works is that, since it's emulating a layer 2 device, any traffic designated for a local address will be allowed through, but any traffic heading outside of your local network will be intercepted and routed through the VPN. So if you need to use network drives/RDP/etc, you can. Makes life pretty easy.

2. External IP: If you use PIA, setting up a static [external IP is pretty easy](https://helpdesk.privateinternetaccess.com/hc/en-us/articles/219016568-Can-I-configure-the-VPN-connection-to-always-use-the-same-IP-address-). Using OpenVPN, just type in a single server IP instead of the normal server address. Everytime you connect, you'll have the same external IP.

3. Routing Traffic: VPN kill switches can be a pain, since it usually affects all outbound traffic on the OS. Instead, you can limit certain apps by using your firewall to force traffic to certain network interfaces. I use Comodo Firewall (for its firewall and auto-sandboxing) and I have it set to force certain apps (like utorrent/qbittorrent, Chrome, and a few others) via my VPN. If my VPN connection drops out, then my torrent client loses all network/web access; but I can continue to work just fine on other apps using my home IP while I wait for the VPN to reconnect automatically. Some of my Chrome plugins need access to certain ports or IPs on my local network, so I have it set to allow just those ports or IPs. 

And alternatively, as others have suggested, you can run containers for all your apps, with the VPN passed through to those containers. 

I imagine that would basically handle everything you need in regard to downloading, automation and using less in the way of resources as well (since using a firewall + sandboxing/containers will be far less resource intensive). 
Just modify the firewall settings?

I use Comodo Firewall to lock certain applications to one network interface or another. If a network interface is unavailable (like when the VPN disconnects), those programs are blocked from any kind of network access at all.
Yea, looks like downloading the website would work best for those sites. 

By default IDM is set to not overwrite previously downloaded files, so that should do the trick I think. At least, when it comes to ripping videos off of a site, I know it doesn't really have any issues about only downloading new stuff.
Hmm not really sure about that one. Would just downloading the website for offline use work (I'm assuming it's text on the webpage itself, not text files or anything like that)? You could specify which parts of the domain to avoid and/or skip all files that aren't html/links/etc (so no pictures and stuff). I'm sure there's lots of apps that can do that. I'm pretty sure IDM can handle that without issue, but I've never tried ripping webpages before. Just ripping videos/exes/pictures/etc from a site. 

Anyways the options wouldn't be all that different to download the entire site, webpages and all. If you use IDM, run 'the grabber' from tasks menu, paste the link of the site/domain into the grabber and tell it to download the whole webpage, check the "convert the links in downloaded html files to the local files for offline browsing", (optional) select which path/domain you want IDM to explore, (optional) select which path/domain you want it to ignore, and at the end, tell it to ignore picture files and/or files over a certain size. 

It'll survey the entire site and show you the files it thinks are relevant in a big list. If you're getting a lot of unwanted files then you can go back and tweak the settings. Once you find mostly the stuff you want in that list, just hit download (or go through and select the files you want), and then save your project before quitting 'the grabber'. Then you can schedule that project to run every day, every other day, once a week, etc.
Well, how much ram did you have? 240? 1000?

[.](https://i.redd.it/ohu7x3zo2egz.jpg)
There's a lot of things that could have been behind it. Driver issues are a common cause of them. And it doesn't necessarily have to be drivers related to your physical hardware either. Some applications need to install drivers to work properly. When drivers crash, even if it's not related to physical hardware, it can often result in a BSOD.
If scannow returns results, then you should either try running [DISM in cmd](https://www.windowscentral.com/how-use-dism-command-line-utility-repair-windows-10-image), or put a windows 10 install on a USB drive and use that to repair your Windows (go to Settings > Update > Recovery > Advanced Startup). The latter is necessary if you don't have a recovery partition set up on your computer (if it's a laptop or a store bought computer, it might have one). If you need a Win 10 OS and a tool to put it on a USB drive, you can [get the official MS one](https://www.microsoft.com/en-us/software-download/windows10).
The Nano S, and Trezor, give you a set of words to write down (the 'seed'). You can use the seed to recover your wallet (onto a new device, if you buy a new one) or recover your bitcoins.  

Edit: You can use a passphrase to further encrypt your wallets, so I think to recover it on a Trezor, you need to use your passphrase as well (if you set that up). 


Trezor is pretty decent and easy to use. The password manager and U2F are a nice bonus as well (although I think other hardware wallets can do U2F as well). 

[I wouldn't worry much about the recent blogpost](https://blog.trezor.io/trezor-security-beyond-bitcoin-c99f27b18b6b) by the alleged hacker who found a weakness in Trezor's system (it was a legit weakness, but Trezor put out fixed firmware). If their hack was even remotely successful today, they wouldn't be asking for 20BTC on the clearweb to sell the tools to someone. Like every other serious actor, they would have sold it discretely via any number of tor markets, without making a big post about it. When you're selling tools to exploit something, the most idiotic thing you can do is let the company know there's a problem they need to fix by making a public blogpost about it.

At this point, the only reason they made a blog post about this, is because they know what they sell won't work, so instead they're making a post on the clearweb to get as much visibility as possible, increasing their chance of getting some sucker to pay 20BTC for nothing useful. 
On desktop, Electrum will say you don't have enough funds if you adjust the fee after typing in how much you want to send. 

I adjust the little 'fee' slider bar, then put in how much I want to send and it works out fine. I dunno if it's the same for Android, but it might be a similar issue, since funds clearly isn't the problem. 
Yea, that toaster doesn't look like it's open source at all.
For hoarding, there's [Ripme](https://github.com/4pr0n/ripme) (pretty good for reddits or users), [imgdl](http://ronfitzgerald.com/imgdl) (good for single albums on imgur and downloading an entire user's gallery), [Youtube-dl](https://rg3.github.io/youtube-dl/) + [(gui)](https://github.com/MrS0m30n3/youtube-dl-gui) (makes batch downloading of entire channels/playlists easy), and I like to use [Internet Download Manager](https://www.internetdownloadmanager.com/) as well (it can be good at ripping some sites, and is great at downloading whatever vid is streaming on the page you're currently viewing). 

For online backup (including encryption), there are a lot of options. Too many to easily list/discuss I'm sure. I haven't used Cryptomator, but it looks like it would do the trick. 

I use [Stablebit Cloud Drive myself](https://stablebit.com/CloudDrive), and also (on occasion) the encryption option on my NAS's cloud upload app. I can't access files I store encrypted on the cloud without a PC, but for my purposes that works out fine. Most of the time, I have my PC running and I set up my Cloud Drive as a shared network drive which I can access from my phone, if I need it.
Doesn't make a lot of sense that Windows wouldn't update because the wireless drivers are out of date. Maybe you could post a screenshot of the error you're seeing? Does it try to update the drivers first, and fail, and then abort the entire update process?

Another option would be to download the Windows 10 upgrade tool from Microsoft's website and try running that. 

https://www.microsoft.com/en-us/software-download/windows10
Ah ok, so it wouldn't import my transaction history and all that? I was kinda just hoping to keep it all in one place so I can view when I need it, instead of keeping the old address on hand (I'll definitely archive and keep it safe in case I need it though). It's not a big deal though, just a minor convenience thing.

Thanks, I'll transfer the coins over.
This is something I've been looking into for a while now, but I'm assuming the answer for TR is yes but with possible hiccups (based off of how it works on Ryzen and the earlier FX chips).

Yes it will support GPU passthrough and you may even get decent performance on some games, if you have NPT turned off. Which means everything else could potentially run slow. On Ryzen machines, people have reported seeing massive drop in disk and CPU performance with NPT off, to the point that it's unuseable. There's also been others who have said their VMs were still pretty useable...so it seems to vary. 

With NPT turned on, your CPU and everything else will give you close to bare metal performance, but your GPU will see a drop in performance; some saying they get less than 1/3rd of the performance in benchmarks. Some people with Ryzen report the GPU barely being useable, while others say they haven't had as severe issues (but everyone sees a drop in performance compared to using other VM software, like Xen). This also likely depends on the application/game that is running.

I want this to be fixed in Threadripper so bad (since I'm building a TR machine right now), but it seems unlikely that it'll be fixed quite yet. Last I heard, the KVM devs were made aware about the issue and we're waiting on them to fix the problem (which would then fix it on Unraid too).
Yea I was just wondering if it would treat all 0's in that way, but I wasn't really sure how SMR would handle that. But it makes sense.

I guess that makes the choice to do a burn a no-brainier. 
Well that's good. If you aren't experiencing a slow down after having overwritten the whole disk during the burn in, then I guess you probably won't suffer a slowdown later on when doing sequential writes.
That's true, but only if you assume that AMD has unlimited stock of cards available. They don't, which is why prices are higher than MSRP and why gamers are frustrated cause manufacturers can't keep the shelves stocked. At this point, miners are basically a middleman/retailer. They buy up everything AMD can offer, at full or above MSRP price, and then sell it onto someone else.

If AMD had unlimited stock available, then you're absolutely right and every time a miner sells a card after only using it for a few months, then AMD is losing a potential new sale. But as we all know, they don't have unlimited stock and they aren't missing out on any sales because miners buy so many cards that they drive up the MSRP and clean out all the stock available. If AMD could make those potential sales, then we wouldn't be complaining about high prices or how hard it is to find/buy a gpu. 

In the end, miners are great for AMD (so long as there isn't a mass crash in the market that ends all cryptocurrencies). They ensure that AMD will sell every possible card it can make at full price. That's not something the gaming market pulls off very often (at least I've never had trouble buying cards at MSRP before the whole mining craze started up). 
I know I'm very late to commenting on this and you've already gone ahead with the burn in; but I'll leave this in case anyone else finds this thread while searching (like I did).

Running a full write test on your SMR drive is a mixed bag. On the one hand, you can verify that the drive is working well with no bad sectors. On the other hand, SMR drives (due to the nature of how they're set up), will slow down significantly after every sector has been written to. A slow drive is better than a faulty one, so really it could go either way depending on how you want to use the drive.

[The write head](http://www.extremetech.com/wp-content/uploads/2013/09/seagate-smr-vs-conventional-hard-drive-writing.jpg) is twice as large as a the read head, so the read head can read single tracks, while the write head writes over the intended track and the track next to it as well. This means, to prevent data loss, for every single rewrite of a sector that had previously been written to, [your drive has to read the data](http://www.seagate.com/www-content/ti-dm/_shared/images/figure-3-writer-overlap-trimmed-smr-tracks-550x154.jpg) on that extra track before letting the drive write there. It has to do that for every sector, so that delay can certainly add up.

If you use it normally without a burn in, then it will be doing first time writes over blank disk, and then you can fill up the entire drive with content before you see any performance loss when it comes to writing. 

As far as I know, this doesn't impact lifespan in any way, and read speeds should still be as fast as they ever were, but overwriting the entire drive should make it much slower.
I certainly could be too late, but I was hoping that the recent media surrounding NEO would cause a bit of a feedback loop, so it would keep rising before a harsh correction later on. But at 50/coin it could be at its height already.

Anyways, I'll have to think about it. I was going to use NEO to play around with Bittrex and learn how to use their buy/sell orders/stop losses/etc. Thanks for the link, it looks like it'll have some useful information related to just that.
Yea I noticed after logging into Coinbase that it was just a normal USD wallet, not USDT. BTC/LTC transfer (depending on the fees) seems the way to go.

Thanks for the info.
Right, I saw that post in r/bitcoin and it's certainly a good warning. I figured most of NEO's value came from hype cause China, which is what I was looking to get in on. I wasn't really looking for a long term investment in new coins.
From a quick look, it doesn't seem like those support NEO, but I appreciate the suggestions. It'll definitely help with other currencies. 

Just another question, on ShapeShift, it says "your bitcoin refund address", when I was looking at exchanging btc to eth, is that just any 'receive' address?
That would be interesting, but such volitility would hurt its adoption I think (which would be the key to long term growth, which I'm counting on). 

Anyways I'll be buying as soon as it comes down in price. 
Yea, I bought some earlier in the year, but I didn't get much because it was sorta stable and I wasn't sure if it would go down or up. Anyways, I'm waiting for it to come down and I'll get some. 
Yea, I'm definitely waiting for that. I expected it to happen when it hit 2.8-3k,but then it skyrocketted to 4k much faster than I thought it would have. 

Anyways I'm going to buy a bunch when it comes down. 
My experience with bitcoin has always been 

2011: "I'm not investing in such a volitile currency that won't be around for a year" 

2012: "Eh, my attempt at CPU based mining didn't net me much, just a quarter of a bitcoin. I'll stop since electricity costs me more than this is worth" 

2016: "I fucked up and I dont know where my ancient mining wallet or passwords are". 

2017: "Eh, I'll invest when the prices stop going up."

Now I'm at the point where I'm wondering if I should dive head in and add more to my collection or if I should expect a crash any time soon. 
You mean you don't mint your bitcoins into actual coins so they can be spent? 

I'm starting to think I'm doing this all wrong. 
I don't know about the Aorus eGPU specifically, but most eGPUs seem to work well with the Skull Canyon NUC. I saw a youtube video of a guy using a PCIe box (which specifically said it can't handle GPUs) to game. If that thing can handle a GPU well, I'm sure the Aorus will perform better, especially since it'll have a power supply designed to handle GPUs.


There's a lot of youtube videos of folks who have tested eGPUs with chips less powerful than the i7-6770HQ (like the Asus Transformer Pro 3, which has a i7-6500U), and still had good results with it. 

As long as you're using a GPU less powerful than a 1080, I'm sure you'll see 80-90% of the performance you'd see on a desktop.
I never looked at it before, but I have a T3 and an 850 Evo (msata) that I stuck into an external enclosure, and they're both about the same size. T3 is a bit more compact, but I didn't expect they had used an msata drive in there.
I never said it was funny, I said it was entertaining. I'd liken his ventures into server builds more like watching a horror show than anything funny. And horror shows are still entertaining.

Losing data is really shitty, which is why most people have the sense not to use a setup as anxiety provoking as his was (seriously, JBOD with no redundancy is better than triple stripping a RAID 5 with that many disks). Or at the very least, hire a legitimate sysadmin to review your setup. 

But when your data isn't important (and based on his practices, it seems LTT doesn't see their data as all that important), then it is pretty entertaining to watch that kind of thing happen. I mean, even after nearly losing his server and his data, he's still pushing RAID 5 onto others (like MKBHD, who Linus set up with a 15 disk RAID 5, using all of the same HDDs, all bought at the same time, likely from the same batch). From that, I can only conclude that Linus values the views that tech drama can bring in more than he values protecting his data. 
How can they not be related? There's a bigger difference between TR and i7/Ryzen, than there is between Xeons/Epyc and TR (Epyc and TR are literally binned from the same HCC die, with the same form factor, and many of the same features). Hell, TR even supports ECC which is not available on any consumer chip (not even the i9s). The reason why Xeons/Epyc are so highly preferred in server class hardware is the exact same reasons that TR would excel at virtualized workloads; core count. 

To say that it's unproven, or you can't know the increase in performance (re: virtualization) for a TR processor (without benchmarks), is like saying you can't know for sure if using a modern discrete GPU is better for AAA gaming over a mobile SOC/igpu. The statement doesn't really make sense at all. Of course a modern discrete GPU is better for running graphic intense games. Of course TR is better for virtualization compared to other consumer chips. The core count alone is proof of that, not to mention the fact that it has a higher frequency than what server class hardware normally ships with (since core count and TDP is more important than frequency when it come to virtualization). 

Also, Linus is probably one of the last people you should consult when it comes to anything other than gaming (cinebench is pretty much the only non-gaming benchmark he runs as well; so his world view is limited to gaming or video rendering). The very very few times he even mentions virtualization, or even tries to use it, he used it to virtualize his gaming environment. He's basically an enthusiast/gamer trying out random shit; but to his credit, he's never claimed to be anything else. 

Don't get me wrong, their videos are great for people who are just getting into using computers for gaming, but they shouldn't be used for anything more than basic surface knowledge. You visit any reddit that discusses any topic in more depth (like datahoarder, sysadmin, homelab, etc) and you'll see people basically use his channel for entertainment. He does silly things like run a server with RAID 50, (a huge number of disks in a triple stripped RAID 5 no less), and then has to deal with losing his data/server. It's like reality tv show, where someone does something dumb you'd never be willing to try at home or at work, and then you get to watch them deal with the consequences. 
What? Your guess before was just a bad guess, but now you're showing that you don't even understand the fundamentals behind any of this.

If you honestly believe there's little, or no increase in productivity with virtualizing applications or running VMs with a processor like TR over older ones like i7s or Ryzen chips, then you don't understand anything about virtualization, or even basic computing at this point. Next, I bet you're going to tell me that datacenters just buy Xeon processors for shits and giggles.

Just FYI, there are a lot of people on this sub who use Linux, and I'm willing to bet more than half of them run KVM or Xen to virtualize Windows so they can game on their machines without using half assed solutions like Wine, or dual booting. They're not the only ones who have a reason to virtualize something (I work with VMs all the time and I don't run linux as a host), but their population alone should be more than enough to prove you wrong many times over.
That's an extremely low guess. Even going to a console sub, I'd still expect more folks to use virtualization (obviously not on their consoles though). 

Although I'd bet that there's less than 20 in this single thread. 
Gotcha, that works out, and hopefully it'll be fixed by then. I'm in the opposite camp. I've been postponing a build since last November, so I'm ready to pull the trigger on TR, but I just want to make sure there's a good chance of compatibility (in the near future) before I commit. 
Ah ok. I just assumed you were talking about Xen, since I've seen a lot of people pitch that as one of the better options for gpu passthrough with AMD processors (for the time being anyways).  

But, KVM is what I'm definitely hoping to use as well. The second they fix the NPT issue (dunno how relevant it will be on TR), I'm instantly hitting the buy button on a TR processor.
The only issue (that I've heard) is that with Xen, you have to reboot the host to recover hardware resources, since it's assigned at boot time. If folks are only running a single  VM for gaming, then that's probably fine for most folks, since they can just leave their CPU cores and gpu's dedicated to it full time.
Bitcoin is ok, but when people think of cryptocurrency/block chain, they always think of a digital currency that might be useless or a fad, but currency is the least of what is available/possible via the blockchain. Personally, I think the smart contract features are much more interesting than simple currency use/exchanges, because it allows exchange of services without any form of trust necessary.  

**Very late edit: see below for TL;DR**

For example, if you use cloud storage, you probably trust that Google can hold your data reliably (should they care to do so). They're a massive company, they have all sorts of redundancies, they have great uptime and they encrypt their data (even if they are the ones that hold the key, not you). You are putting your trust in Google when you use their service to store your data. You can't trust them when it comes to your privacy though, they can change their TOS, their service, and the prices as they see fit. Like Amazon did with ACD, they could take a harder stance against file encryption, or jack up prices. 

On the other hand, you probably don't want to trust a company that you've never heard of who is offering better prices on data storage than Google. You don't know if they're storing your data unencrypted, have no redundancies, whether that company will even exist in a year, or if you'll get your data back before they go bankrupt. 

With a service established on the blockchain, you can get people to offer their own extra storage as space on the cloud to create a fast and decentralized network. Maybe you have an extra 1-10TB and want to make some extra money, you can offer your storage space to others. People/clients who need to store something on the cloud can benefit from reduced prices over what others can offer because it's a decentralized network with no middleman, like Google/Amazon, to set/change the service or prices as they feel fit. You don't have to trust these unknown people with your data, because the contract handles things automatically, no human intervention needed or allowed; but could possibly be changed with majority consent. The contract could stipulate that every file will be broken down into 10KB sized pieces (for example), and each of those pieces will be encrypted and duplicated to be stored on the hard drives of 5 (or more) different providers. It could choose these 5 people based on their location, speed, available capacity and reputation/uptime (or other factors + pseudo randomization). 

The storage provider will get paid one rate based on how much data they are storing on their hard drives each month, and another payment based on how much data they upload (an option would be to have the blockchain poll all the providers with a given piece and ask them to provide it, with whomever responds fastest winning the extra upload payment), but the provider will receive no payment that month if they break the contract by not maintaining a certain amount of uptime/availability (something like 85% or higher). If any of those providers decides to quit, shuts down their PC (for more than a specified time), or loses a harddrive, then the files they were holding would be automatically moved to other providers (based on the criteria set in the smart contract).

This allows for a level of anonymization: since all monetary, file transfers, and other transactions would be public record, but it wouldn't be using your name or any other personally identifying information (whether you're a provider or a client); privacy: since providers will only have encrypted pieces of a file...they'd have to hack a lot of people, potentially all over the world, before they could even try to crack the encryption on anyone's files; reliability: like bitcoin, where you see individuals, enthusiasts and entire companies providing computing power, the same will likely be true for providing storage as well; all without needing to trust anyone in the system at all, because there are no middlemen to make sure X works this way, or money is exchanged from this person to that person. It all happens automatically, and is handled by the publicly available records/contracts on the blockchain.

Smart contracts is a newer concept (only a couple years old, and bitcoin is about 6 years old now), but I think it shows much more potential than simple currency exchanges do. Much like the currency scene (which has many digital coins competing for market share), there'll be multiple smart contracts tokens, for any given service like cloud storage, that will be vying against eachother for market share.

Also take my example with a grain of salt. I'm sure there's things I overlooked or forgot or whatever, and I'm sure my example could easily be improved upon.


---------------------------------------------

**TL;DR:** Why the blockchain/smart contracts are exciting is because you can make an exact clone of Uber/Lyft, but without the money sucking company in the middle. Drivers will make more money (since they don't have to pay Uber), and riders can pay less per ride. And the algorithms could be far more efficient (and [far](https://www.bloomberg.com/news/articles/2017-04-24/lyft-drivers-accuse-uber-of-spying-to-gain-competitive-edge) less [creepy](https://techcrunch.com/2017/04/23/uber-responds-to-report-that-it-tracked-users-who-deleted-its-app/)) because they're open source, and designed by the community.
In the US, you are allowed to own a legal backup of your digital media, like DVDs/Blurays. You are not allowed to circumvent DRM to get that backup. 

So, if you magically have a DVD/Bluray rip/backup on your hard drive, you're ok. If you circumvented your DVD's DRM, or use something like torrents to get that backup, you're still breaking the law.

It's a nice little catch 22.

As for digital media from iTunes, Google Play, etc, I don't believe you're allowed a backup, since the license agreement is more equivalent to you renting the movie. Even if you 'purchase' it, it's basically a long term rental.
I was totally going to get a Threadripper processor, but then I found out you could get a [Ryzen 3](http://i.imgur.com/r5VTU6S.png) with 16 cores, so I might go for that instead.

When I searched for threadripper to see if it's still in 'pre-order' status on Amazon, it showed Ryzen 3's image in place of the normal Threadripper box. I almost missed the threadripper listing entirely until I started looking at the prices for the those processors. 

Edit: Seems fixed now.
I only checked the OFM gaming chairs against Amazon, but they're decently cheaper there. 

[The 3086 model is 80-90 dollars on Amazon](https://smile.amazon.com/dp/B01MEGHWKN/_encoding=UTF8?coliid=I2P3ZY3XHUK1Y5&colid=1ELY14DOBHS4U), vs [120 at Staples for the 3085](https://www.staples.com/OFM-Gaming-Chair-Red/product_2573679). 

[3085's on Amazon seem to be around 90 dollars](https://smile.amazon.com/Essentials-Racing-Style-Leather-Gaming/dp/B01M1E96WX/ref=pd_sim_328_1?_encoding=UTF8&pd_rd_i=B01M1E96WX&pd_rd_r=BNJQEE5PWKVT4KGR9XFS&pd_rd_w=9XHvp&pd_rd_wg=Fqf0H&psc=1&refRID=BNJQEE5PWKVT4KGR9XFS).
Is this the same monitor that you get a coupon for in the Vega bundles? 

I remember reading it was a curved 34" Samsung WQHD IPS Freesync monitor. 
That's a 6TB drive so it should have a normal WD Blue drive. I've taken two of them apart and gotten normal Blue drives each time. 
Yea, Enterprise is the only one that can fully control their system. Even Pro has restrictions on deferring updates, but I've only ever used Pro or unpaid versions of Windows 10. 

But I don't get why everyone is complaining about ads. If you don't want ads, don't use Windows Store apps. Seems pretty straightforward to me and I've never had to deal with a single ad from Windows (even though I still allow Windows to use my advertising ID).

Edit: Just checked MS Imagine and I can only get Windows Server 2016 via my school. Which is good, but Enterprise would have been great too.

Edit again: My college apparently uses another site called OnTheHub to deliver Windows 10 Education for free.
Yea, this is probably one of the best routes. 

I got my last few hard drives at $160 which comes out to 20 dollars per TB, which is pretty good. I think I've picked up about 11 or 12 of them from the various Best Buy sales on this drive. 
On one of my accounts, I encrypt everything. On another, I use it just for Plex Cloud (nothing is encrypted). 
Nope. I have encrypted backups and I've used it for Plex Cloud. Haven't had any issues with either. 
https://gsuite.google.com/

Any step that takes more than pressing the mouse will have a "Help" link next to it. If you get stuck, click on it and it'll walk you through any process you need to do.
Ntfs on main computers, ext4 on VMs, and btrfs on my Synology NAS (which is the default option). 
That's a great tip. I'll have to add that to my list of monitors I'm considering then. 
Well, I was surprised it wasn't already posted on this reddit, so I figured maybe 699 was a normal price and the 200 dollars off was misleading or something.

Anyways, when I was searching, [699 was the lowest](http://i.imgur.com/9WHWAdx.png) I could find without looking at refurbished or used versions of this monitor. [CamelCamelCamel](https://camelcamelcamel.com/Acer-Predator-XB271HK-bmiprz-Widescreen/product/B018MYTF4W) has Amazon's lowest price at 760 dollars.

If you find a new one at 650, let me know, cause I'm actively monitor shopping right now. 
"Built in speakers" means the monitor has speakers built in. "Build in speakers" means the seller is suggesting you build speakers into the monitor. Like Ikea, some assembly is required. 

Just in case it's not obvious, I'll add that I'm not being serious and /u/M3L0NM4N is right about what 'build in' means in this case.
Do you live in Canada by any chance?

Could be Linus's old mouse.
Is Amazon Cloud Drive still unlimited outside of the US? I thought it was limited to the same pricing scheme as Google's consumer Drive prices. 
Right, I'm using a 256gb u3 microsd that I got from Samsung when I bought the Note 7. Even if I didn't get it for free and I only needed something fast enough to record 4k video, it'd still be cheaper since it's 44 dollars for a 128gb u3 on Amazon and, 150 for 256gb. 

Ideally, it'd be best if manufacturers used a UFS + microsd card slot (to give folks more choices), but I don't know how likely that is to happen since I haven't heard anything about UFS memory cards since Samsung said it could make them and the UFS+microsd slots.
Is there a lot that S8 users are missing out on by not having 7.1? I don't have either of those, so I'm genuinely asking.

Looking at a list of features introduced in 7.1 (not including aesthetic changes on the Pixel), it looks like the S8 already has most of them, or is getting them soon (ie Daydream VR). 

Unless there's something big I missed (or wasn't listed on the site I was looking at), I'd be more concerned with security updates than a number change on my phone's OS. 
They will eventually. I mean, the only direction I see for the flagship market is to do away with the headphone jack. Simplifies the design for them, and it'll save manufacturers money (we won't see any of the savings though). 

I have no problem with companies doing this eventually, but I don't think the time is right yet. Last thing I want is to do is buy new headphones when my current ones work great (and likely will for the next few years), or buy blutooth ones which will be yet another thing for me to plug in/charge. 

I'll be happy if Samsung (and others who still have the headphone jack), keep it for another generation (ideally two). But I'd be surprised if the S10 had a headphone jack.
I've never been able to justify paying the higher prices that device manufacturers have on their larger capacity devices.

On the one hand, the storage is fast, so it's quite useful if you want to download a lot of games, but my primary use case for large storage has always been to store ebooks, photos, music, videos, etc. Things that work well, even on slower SD cards (which are orders of magnitude cheaper, also).


Gotcha, makes sense. 
I'm kinda new to all this, but I didn't think it was possible for there to be that massive of a discrepancy in the value of a cryptocurrency (even if it's unstable). 

Does this mean that people can just go on Bitfinex, buy BCH at $360, transfer it directly to Bittrex (who seems to use BCC instead of BCH), then trade/sell that BCC at $700?

I mean, if that is possible right now, it kinda seems like a way to get free money. 
That's great, I'll try that out. Thanks for the help.
I'm jealous of your note taking ability. Whether I take notes on the Surface Book or in a notebook, my notes are all over the place. At least on the Surface Book I can cut and paste what I wrote to make things seem more coherent.

Just curious, when you take notes, are you using the clipboard by itself or attached to the base? I've found that using the clipboard by itself is a lot easier for me to write on, but the battery doesn't last long enough for me to finish taking notes.
Nice. Learning to use Arch (and linux in general) has been on my to-do list for a long time now. 
I never once said that "more cores means more power", because that's exactly as absurd as saying that clock speed means more power. What kind of chip benefits you depends on what your workload is. 

Maybe the appropriate choice of words would have been "gimped for the price you pay". I think 2017 should have made it abundantly obvious that they have indeed gimped consumer chips for the price you pay. Just a few months ago, the highest core count (consumer) cpu you could get (which was still binned from their LCC silicon), was the 10 core 6950x at nearly 2k in price; before that it was a 8 core for nearly the same price. Now, thanks to competition from AMD, they're releasing their first HCC silicon chip (14+ cores, up to 18 cores - 36 threads) to the consumer market for 2k. If they followed their past trends, of releasing their best LCC silicon (ie priority binned to have the most working cores) to consumers as their best enthusiast processor, then we should have expected the 12 core to sell for 2k (again, that's not happening cause of AMD bringing some competition). It should be very clear that they could have been offering HCC silicon to consumers at the prices they charged for their LCC chips. Or they could just continue to charge 2k for the 'gimped' versions of the chips they should be selling at that price.

Does the average consumer need that many cores? Of course not. The average person would be fine with the current Pentiums, or i3s. Most people are using office/web/skype/etc. The average gamer would be fine with 4 cores (depending on the game they play, since some modern games are designed to scale well with more cores; ie Last Light). 


In my case (primarily running VMs), more cores is better, so long as most cores have a decent clock speed. This basically meant that for most of my time, I'm looking at server chips rather than consumer hardware, but I'm always buying generations late because of how expensive HCC server grade chips are priced (again, courtesy of lack of competition, and businesses are willing to pay higher prices). Now, I don't have to buy an old gen Xeon, I can instead get a Threadripper or i9, which will have higher clock speeds since enthusiast consumer chips are binned first for clock speeds. I lose out on a lot of features that get turned off compared to same silicon that's in server chips, but consumer silicon is still cheaper.

In my opinion, given the prices they wanted consumers to pay, they have absolutely been gimping their processors when it comes to core count. 
I agree. I almost always find youtube videos to be a poor medium when it comes to discussing serious topics like this, but the guy did a pretty decent job. 

This was the first video I've seen from the guy and I subscribed immediately. I watch a lot of science channels on youtube and they don't come close to providing the level of links/sources that this guy did when they're arguing a topic.
I posted it twice under the same account. I didn't see anyone else post that video even once when I first posted it. Maybe two posts linking the same video is a little much, but I honestly didn't think anyone would be all that upset by it. Anyways, I'm glad I didn't take the lazy way out and link to my first post (which I thought about doing), cause then I can only imagine it'd look even worse. 

But I agree the video can be a bit preachy. It's especially annoying how that guy kept using links to legal documents, government/court webpages, or articles from news outlets like Ars Technica as sources to back up their points. It's too bad they don't follow the reddit method of throwing out accusations without any semblance of proof.
That's true at the moment, but it wasn't necessarily true in the past. AMD has so little market share that there were plenty of times when Intel had the best products by default (being that AMD was in no state to offer any real competition). If there were any semblance of honest competition, I have no doubt that AMD would be holding the crown today for more than just price to performance. 

The war over clock speeds was most relevant back in the day when everyone was still rocking single cores, and AMD held that crown for a while but still made very little in terms of market share due to their inability to bribe companies on the levels required to compete with Intel. Back when AMD had superior processors (in speed and price), they tried to offer HP a million of them for free, but HP declined because they were too dependent on the bribes from Intel.

I think things would be very different if AMD were allowed to legitimately gain market share after they put out a superior product. 

The video has a dozen or two links in the description. If you want an article, pick a few of those.

I'm not willing to link anything I haven't read myself first, and frankly, I'm way to lazy to read through even half of them (I loathe reading through courtroom/legal documents). I'll likely read through the articles, but not today.
Yea, I never liked Intel's practices because of how they gimp consumer hardware (by gimp, I mean they only offer low core count chips while charging huge margins since they had no real competition), but it wasn't until I started looking into that I realized how scummy Intel can be.

https://www.youtube.com/watch?v=osSMJRyxG0k

^ That guys sums is up pretty nicely, from a competition standpoint. 
A huge problem that Intel has had, is that they don't make the best products, they're just the best at bribing or strong arming companies into using their products. https://www.youtube.com/watch?v=osSMJRyxG0k

They entered the mobile territory late, and nobody in the mobile market was willing to play ball by taking their bribes or willing to be strong armed by Intel. At least not in large enough numbers to make it worth it for Intel to continue to waste resources on the mobile market.

Just look up the dozens upon dozens of cases brought against Intel over the years for anti-competitive behavior. 

People in r/android think that Qualcomm is terrible for exploiting patents to keep themselves relevant by forcing themselves into the US market (and I agree with these folks), but they should be thankful that Intel never made it into the mobile market. 
Given how much people complain about bloat on r/android, I honestly kind of expected most folks to be Arch users. 
I came across a website a while back that did the same thing with humans, only it was a partially paid, partially free service. Basically 20-30 year old couples who go about living their normal lives, but come home to an apartment that has cameras all over. They'd obviously do random little things like walk around naked to keep folks watching interested, or start fake drama, etc.

I told a friend that if they had a 24/7 dog/cat cam service, where you could watch a cat/dog all day, that's something folks would want to do. After discovering the other site, I spent more time switching cams around the house just so I could watch that couple's dog and see what he was doing all day.

I'm really glad I saw OP's link, cause this is exactly what I was looking for.
Yea, this is something I've talked about back when Linus made his Intel sucks video.

Intel, for the longest time, has been selling consumers their low core count (LCC) silicon for very high prices, while saving all of the high core count (HCC) silicon for their server line (where they knew they could charge their business partners an even higher premium). It's not because they couldn't make HCC chips available to consumers at a price that consumers could afford (and still make a huge profit), but it's because they knew they could pawn off even cheaper silicon onto consumers and still charge huge prices; since there's no real competition. It's why, year after year, you see almost no real progress in consumer line chips. The most progress that was seen was when they had a 10 core chip (6950x), which they charged 2k for and it was still binned from their LCC silicon.

Basically, their roadmap would have been to add 2 more cores in 2017 and release a 12 core chip for 2k (still made from LCC silicon). Thanks to AMD, they can't do that anymore, so instead, for the first time, they're releasing a HCC chip to consumers for the price of 2k (their 18 core i9). 

I've had a lot of people try to argue that Intel needed to charge those prices to fund their research, or that this is how all technology evolves and other bullshit like that. That's not even remotely true since server chips are their bread and butter, and consoles are the only technology that evolves deliberately slowly the way Intel's consumer chips have been (for consoles, it's because they don't want to alienate customers by releasing a better console every 2 years and alienating customers who bought one 2 years earlier; not an issue in the PC space). 

I don't like what Intel did, but I don't blame them either. They had no competition and any monopoly would have charged high prices for inferior products, because they can. What I dislike was how 'tech enthusiasts' used to praise Intel at every possible turn when you could just look at their server line and their consumer line (since they're both made from the same silicon with the same *potential* features) and see how much worse consumers have it. 
Interesting. Kind of sounds like the SMS notification+reply in Windows 10. If you put Cortana on your phone, it'll let you see SMS messages and reply from your computer without any extra software on your PC.
Some of the things the community has backed up (in terms of websites/archives) has been somewhat controversial at times, but for the most part they're backing up dying services with unique content before that content is lost forever.

And there's a lot of places to discuss what people are hoarding, but this isn't one of them unless a person asks for help on the topic. There's lots of posts about "how do I organize my tv shows" or "how do I rip this from a website", type posts where the OP makes it clear that they're talking about. If they want to talk about it, that's fine, but if they say "linux isos" it's generally understood they don't want to talk about it; regardless of whether it's a legal reason, or maybe they don't want to admit that they're going to store 50TB of porn or something.

Also, if you check the sidebar, you can get an idea of what is being hoarded by different folks. r/DHExchange is exactly the kind of place that you're looking for when you mention your example of 'learning about an old game'. People there offer their archives or request archives of different things from eachother (textbooks, ebooks, manuals, porn, tv shows, old movies, games, comics, etc). There's other reddits out there that do that kind of thing as well, but DHExchange is specifically for DataHoarders (the folks here) to exchange their data with others.
eFax?

Either way, 40c is within the norm for a WD Red drive. At least according to the manufacturing specs ([pdf](https://www.wdc.com/content/dam/wdc/website/downloadable_assets/eng/spec_data_sheet/2879-800002.pdf)). Operating temperatures are 0-65 (c) for WD Red 8TB drives.
1 million eh? 

With the release of every new console iteration, more folks realize building a PC is more economical than buying a new console every 3-4 years. 
Well make sure you guys post your buttcheeks together, so we can get an official collage of PCMR buttcheeks going.
You need me to explain to you what you just read? I didn't think what I wrote was difficult to understand.

"Do dropped frames really matter if you can't tell if there's any frames being dropped?" Followed by an example of why I didn't think dropped frames were a big deal.

I was fine with your initial question of asking them to rerun with gpu profiling to see how many frames are dropped; nothing wrong with asking that. My post was in response to your bitching about downvotes and then saying "i just wanted to see if there really isn't **any** dropped frames". 

Which made me wonder why you think dropped frames matter if nobody can tell that the frames are being dropped. 

I know I wrote even more words this time, but I hope you can muddle through this essay and answer the question I originally had (which you didn't answer): Do dropped frames matter (in your mind) if nobody can tell they're being dropped?
I'd say that's pretty good, especially since you had screen recording on at the same time as well. 

I dunno about anyone else, but some of the times my phone has lagged the most was when I tried recording the screen (probably didn't help that I was trying to record the hot dog guy on Snapchat).
Do dropped frames really matter if you can't tell at all if there's any dropped frames without gpu profiling turned on?

I mean, I get it. I'd prefer my PC play all games at 120 FPS, but I'd be lying if I said I could tell when it dropped to 119 FPS...or even to 90 FPS for that matter. And honestly, the dropped frames don't affect gameplay that much (nevermind how little it affects using the start screen on a phone).
As I understand it, if they find copyright infringing material, they'll disable sharing of those files (possibly disable sharing account wide).
I was reading about a deal for Zoolz. Back when I used them, they were primarily used as a cold storage, cloud provider, but you should do your research on them before buying into anything, of course. I left their service cause I bought in when they were very early in development and it was almost unuseable for me.

The deal, on CNET/Engadget/etc, was for 1TB of storage space on Zoolz (500gb for normal, google drive type storage, and 500gb for cold storage), for a one time payment of 30 dollars.

So...you can get a lifetime of storage right there. Although in this case, lifetime likely means however long Zoolz decides to support this plan/option, or until they go out of businesses (although they have been around since 2010 and have some big name partners).


Keep things like the following in mind too. Encrypt before you backup to the cloud. 

https://www.bestvpn.com/avoid-zoolz-backup-service-if-you-value-privacy/
I'm not sure what I'm doing wrong, but browsing/typing in any folder on the network drive, even root, always leaves [the main screen empty](http://i.imgur.com/vP3kaFM.png). 

I hadn't considered that mapping it as a network drive would work when the other method didn't, but it does work just fine. So that's a decent work around for the time being.

Thanks for the heads up, this'll save me a lot of time.
Trust me when I say that Bing is by far the superior search engine with nothing that can come close to matching it.....^^for ^^porn

But in all seriousness, it seems to be the only thing Bing excels at. Unfortunately I'm always in incognito mode, and never want that tied to my primary MS account, so there's a hell of a lot points I'm missing out on. 
Yea, usually it's been both. My local store only had those drives in stock for one sale (I guess large hard drives aren't very popular around here), so most of the time I purchased them online. 

I'd check the Bestbuy website every now and again, and also see if someone posts a link in here about the sale.

Most of the sales I've seen were priced at 179.99, but the most recent sale post said it was 200 dollars. So I don't know if they changed things up, or if it was an unrelated sale.
Well, the MyBook uses a white label drive on the inside, which folks usually say it's equivalent to an 8TB version of 
a WD Blue drive. Blue drives usually act as general PC internal drives and tend to have faster spin down times, but I can't say if that's true about the white label drives.

The Easystore has a WD Red drive inside, which is a NAS drive, and it good for running 24/7. So this means they're designed to spin down less (but they will spin down if your computer's power settings tell them to), but they're generally more robust in that they're designed to operate longer, have longer warranties (not really a consideration if you're buying it in an external case) and usually cost more than Blue/white label drives.


Neither of them are archive drives, so you don't have to worry about speeds decreasing over time (after you fill up the drive), they're both normal drives. 

You should hold off on buying either of those drives right now if you can. Bestbuy has frequent sales on their Easystore drives, in which they drop the price to 179.99. Given how frequently the drives go on sale, I feel like BestBuy is trying to clear out their stock of EasyStore drives. I think I've seen them on sale at least once every month or every 2 months, so if you can hold off for that long, you'll likely see a sale before then.

Edit: Just looked at the screenshot and it looks like every file has a unique name. I usually use Bulk Rename Utility for changing how a group of files are shown. Like adding the name of the show to the start of the file name for every episode. Doesn't seem like this would be as useful in your situation. 

I use Bulk Rename Utility and it seems to work well for me. It's entirely free and I use the portable (no-install) version of it.

The only issue I have is that I can't seem to edit files over the network, only my local machine. They might have fixed that in newer versions, but I've never checked.

http://www.bulkrenameutility.co.uk/Screenshots.php
The amount of carbon stored in the Sun has a greater mass than the total mass of all 8 planets combined. 

So the sun has all the resources we need, and we just a volunteer to run in and grab it. Or, if nobody volunteers, we could slap a giant particle accelerator near/around the sun and use the generated magnetic field to extract mass from the sun. 

Should be able to keep most of Mercury if we only use it to build the stuff we need to extract elements from the sun. This allows people from the future Dyson Swarm to vacation on Mercury, or Venus.
No idea, I've never looked into the issue to determine the root problem. I just saw a post online saying that MPC-HC was where it was at for 4k playback so I tried it out and it worked. 
I hope someone keeps it alive too, because VLC doesn't handle 4k well on any of my computers (constant stutters), whereas MPC-HC plays it like a champ and with far less resource usage.
Ah ok. Yea I can see how that would be annoying. 
They don't, the S series has always been like that, whereas the Note series has always had smaller rounded corners and a more professional look overall.

It's just how it's been for a long time. I've never liked the look of the S series, but it seems a lot of people do.
Same, I thought I'd be able to go longer with that phone as well. Maybe even up to 3-4 years if the battery lasted that long. 
Yea I made the same move. I think it's gotten slightly better since the 7.0 update, but still not on par with the Note 7.
You can still run Windows if you wanted to, in a couple of different ways as well.

You're basically just running virtual machines on top of a barebones OS (which you only need to access if you want to change the hardware you assign to virtual machines), so you could just run a virtual Windows. It should still have close to bare metal performance. 

Otherwise, if you wanted, you could do what I plan to do when I start building my PC, which is to dual boot the system. Have a Windows install that uses up all the computers resources (so like a normal PC), but if I want to run virtual machines, I can reboot into the virtualization OS (vSphere, unRAID, etc) and run multiple other OS's on top of that. 

I'd probably use the virtual OS more often, and use a virtual version of Windows as my daily driver (for browsing, games, work, etc).
Yea, I can certainly understand that. I've got about 1/2 that much data, and about 75% of that is backed up, but to cover the rest means buying new hardware, which I've been putting off for a long while now.

And that's very true. Drivepool could be considered more resilient in certain ways over some RAID setups as well. If a couple of drives (or more) die, then you only lose the data on those drives (unless it's duplicated), and not the entire pool. Plus, no need to worry about things like UREs during a rebuild.
I don't use Crystaldiskinfo often, but i did have it set up to make a noise when there's an issue with my disks. You can probably set it up to run all the time in the background and to send you notifications somehow*, but I haven't looked into it and I'm not at my computer right now. Normally I run it for an hour to get info and quit out. 

It doesn't protect files from being corrupted and neither does Stablebit Scanner. That's a bit of a different issue altogether. I know Drive Pool copies your data across multiple drives, but if the corruption occurs in the original folder you have set to be duplicated, it would either ask you how to resolve the conflict and say the disks aren't properly pooled, or it would copy the corrupted file into the duplicated folders. Which happens depends on how your file becomes corrupt (silent, or the result of an error in copying a file to your pool). 

There are backup programs that offer file versioning, which I think would work if you spot the corruption in time. If it gives you 60 days of file versioning then you have 60 days to spot the corruption and tell the backup program that you want an older version of that file back. Many programs let you set how long you want that to last. So you could have 30 days, or 5 years (or more). Depending on how the backup program works, this could take up more space, but if it uses incremental backups, it shouldn't take up much. 

There are also file systems, like Btrfs (and refs I believe), which can protect you from silent data corruption if it's set up right (like if it's used in conjunction with RAID). 


*Edit: I just checked and in Crystaldiskinfo 7.0.5 you can set it to email you, or make a sound when there's a problem.
Having another 42tb worth of disks to back up onto is a good option. Or at least backup what you think is important. You could just use a drive bay with enough bays to hold your data, a raid enclosure, a bunch of external disks, or buy a NAS/build another server with enough disks to cover your collection. 

Raid isn't a backup, and Raid arrays can die entirely, but you can use RAID on your server if you aren't already to keep it running in the event of a disk loss or two (depends on how you set up your raid). So that's something to consider as well. 

Edit: Reworded for clarity.
They are different programs with pretty different purposes, so a straight comparison isn't easy. It's like asking if you should store a priceless work of art in a bank to protect it, or get insurance on it. You should do both, and one service isn't better or worse than the other, just different aspects are being covered. Same with the software you mentioned. 

Scanner is primarily for scanning the drives (doing read/write tests and seeing if you have bad sectors) and reading the SMART data of a drive which helps predict when a drive is failing. It tries to give you a warning before the drive dies, but that's not always possible. 

Drive pool is for creating pools (multiple hard drives acting as one large hard drive) and for allowing you to select which files/folders are important to you and setting those to be duplicated across multiple drives. So if one drive dies, you won't have lost those important files. 

So they both serve very different purposes. Scanner warns you when a drive is dying, Drive pool let's you duplicate data so that when a drive does die, your data doesn't go with it. If you use both of those together, Scanner will warn Drive Pool when a drive is dying and Drive Pool will automatically move the files of a dying drive to a good drive (I've never tested this out). 

Whether you go with Stablebit programs or programs from somewhere else, you should have a program that makes backups of your data (which is the only good way to protect your data) and software that scans your drives and reads their SMART data.  

There's plenty of free and paid versions of backup and SMART tracking software. Drive pool is good at what it does, but my experience with Scanner has been mixed (works for a lot of my drives, but not all of them). 

I also use CrystalDiskInfo which is free, to scan SMART data, but it works a bit differently than Scanner and isn't a true replacement for it. I only use it when I suspect a disk might have an issue and Scanner can't read the smart data on that disk. 
Gotcha, it's very different in the US. I've never seen it advertised in any real way where they say "Samsung Pay is accepted here" like they do with Apple and Android, but they support a lot of major and smaller banks in the US. Most of my family and friends who have Samsung phones have all of their banks/cards supported here.

Hopefully they do start to put some focus on countries outside the US, because it's unfortunate that folks would miss out on that, especially if they're already Samsung customers. 
Isn't the best part of Samsung Pay that you get rewards back with it? I mean, I get 5% cash back on my credit card, and during the period that I've been using Samsung Pay, I've been paid more by Samsung in the form of pre-paid Visa cards, than my credit card has paid me.

Is that not available in the UK? Because if it isn't, then there's nothing that separates it from Android Pay, and it's understandable to use either or. But as long as there's free money on the table while offering the same ease of use/experience, I'd go for that everytime.
In my opinion, the Note series always looked better and more professional than the Galaxy S series. 

Note 7 looked way better than the S7/Edges.
Ah ok, thanks. It's good to know it works that way. 
That's a very good point if it makes requests to the site on both people's phones to load the preview. If it doesn't then the onus is on the receiver to be smart enough to not click on it.

If they use the sender's phone to make the request to the website, and then pass on that preview to the receiver (without making a request to the website on the receiver's phone) then it's not really an issue.

I don't know how likely it is they have this kind of thing set up (where it passes the preview along), but it doesn't seem that the video tested how it works on the receiver's phone. Someone really should test that out to see if the requests are pulled by each phone or just the sender's. 
There's nothing wrong with the way they explained how IPs work when browsing the web, but you still don't want whatsapp leaking your IP. If you're on your work wifi, and you're talking to your friend about some sketchy site you came across the other day, and you type in the URL for your friend to visit later, you probably don't want whatsapp to make a request to that site using your work IP, letting the site owners know that someone in your office building visited their site. A random and very unique scenario: A rival company uses an unlisted website...for some reason or another, and you send your friend that link; you probably don't want that company to see that whatsapp made a request to their website with an IP belonging to a rival company.

Option 3 is the best route, since it gives the user the option to visit the site when they want to. I've never used a VPN when just using whatsapp (because it's encrypted E2E, so using VPN seems like an unnecessary precaution), but if I tell my friend to check out some video on pornhub.com, last thing I want is for whatsapp to request that site when I'm on office wifi. Typical offices will allow some social media content and messaging, but will block certain things like porn sites, and on top of that, and if they're like the IT dept I worked at in the past, they'll know exactly where and which device made the request (which router, and the mac address of the device...even easier to figure out exactly who if it's a work phone).

Obviously the best way to deal with this is to use whatsapp over vpn, or be careful about when typing urls to avoid making a complete url (like saying 'reddit dot com' instead of 'reddit.com'). 

-----------------------------------

There's another security implication involved from the way whatsapp makes the requests (not just leaking your IP, but because of how they make the requests in the first place), but it's more complicated and unlikely that anyone could ever break whatsapp encryption using that method. Either way, option 3 is the best route since it would prevent this potential (if very improbable) security issue as well.*

*Edit: I guess there's other security implications involved, but I was only thinking about a possible (if improbable) issue related to encryption, not anything else.

*Edit x2: Looked over the Whatsapp E2E whitepaper and the concern I had regarding weakened encryption isn't an issue at all. 
The common argument for why the phone was explosive was that it was rushed to market and my point was that it was unlikely because [the reports](http://www.androidauthority.com/galaxy-note-7-dangerous-battery-design-733889/) say [that Samsung knew the risks](https://www.forbes.com/sites/bensin/2016/12/04/samsung-knew-note-7-had-a-dangerous-design-but-took-the-risk-anyway-say-analysts/#584495dc6943) but still pushed for an [aggressive battery design in their phone](https://www.usatoday.com/story/tech/columnist/baig/2016/09/29/samsung-battery-bust-shows-pressure-innovation/91171994/). 

If they were truly pressed for time and had to fall back on a 'boring design' then one would think that they would have used the industry standards for battery design (this would have been safer, and faster from a design standpoint, but also easier and faster to [manufacturer since the tolerances wouldn't need to be so strict](https://news.samsung.com/global/infographic-galaxy-note7-what-we-discovered); see pdfs) rather than push the boundaries in an attempt to be 'innovative', leading to more time spent on prototyping and testing those batteries (which would lead to many more hurdles in QC). 

Lets assume you're right about them picking the boring design and they went ahead and wasted even more time on the battery because you can't just pick a case design and slap any old battery into it.

Obviously the next point to make is that they skipped QA testing to make up for lost time, and it's entirely possible they did minimal QA testing. However my second point was that if you know about QC/QM in SCM, how QA testing is done and the [six sigma standard](https://en.wikipedia.org/wiki/Six_Sigma#Quality_management_tools_and_methods) (which is one of the highest standards for QA and QC/QM), then you'd be able to see that even if they adhered to the six sigma standard (I doubt they did, since not many companies do), this entire situation would have likely happened anyways. When you do QA testing, you don't test every single product you make, you don't even test half or a quarter of them; you only test enough so that defects are statistically unlikely. Given how [low the numbers were on confirmed reports](https://www.cnet.com/news/why-is-samsung-galaxy-note-7-exploding-overheating/) of [phones going up in smoke](https://www.cnet.com/news/samsung-recall-galaxy-note-7-again-consumer-product-safety-100-dollars-credit/), compared to the [total number sold and manufactured](http://www.greenpeace.org/international/en/news/Blogs/makingwaves/Samsung-Galaxy-Note-7-ewaste-trash-recall/blog/57889/) it's easy to see this could have happened whether they followed the best known practices for QM in the mobile industry or not (statistically, it's unlikely they would have come across a defective device unless they started testing far more than what's required by best industry practices). Given how low the numbers are, and how rarely companies [actually strive to hit six sigma standards](https://en.wikipedia.org/wiki/List_of_Six_Sigma_companies), I can't see how anyone else would have fared better in the same circumstances (as far as QA is concerned). Either they legitimately did the QA, or they're some of the luckiest people on the planet that this problem occurred in such low numbers.

Could they have skipped QA testing altogether...sure. Could they have been rushing the phone, on top of everything else? Absolutely. Could they have hired Nicki Minaj on an NDA to design the phone which lead to her adding more junk to the trunk and getting an explosive battery too? Unlikely, but within the realm of possibility, because that's all you seem to care to offer; possible scenarios and your opinions. But possible doesn't really matter. Evidence does. 

You ignored the most important part of my comment that flies directly in the face of every comment you've made so far. I specifically stated, there is no evidence, in any credible report that the phone was rushed. Anyone making that argument does it solely out of speculation (like saying that unicorns exist on Saturn; impossible to fully disprove until we go there, but there's a lot of objective information to make the case why they don't exist). The reason there's no evidence is because every aspect of the problem was explained without resorting to a lazy excuse like "Samsung screwed up because they rushed the phone". Still, I encourage you to spend as much time as you can to find a credible source to prove me wrong. Absence of evidence doesn't make something true/false, but having evidence goes a long way to making your point, so don't be discouraged if you don't find the evidence.

In your last comment

>"You have no actual information to add, you are just making stuff up in your head, and somehow feel it is worthy to put down in a comment". 

You accused me of 'making stuff up in in my head' and proceeded to offer nothing but things you made up in your head. I liked your use of the double negative earlier because I appreciate that you are confident in my ability to understand things, but the hypocrisy in your statement above is...just...not good.

Just FYI, everything in every comment you've made has been entirely subjective information (not evidence or facts, but only conjecture), but what I've done is use objective information (evidence or facts) to reinforce my argument. I didn't include sources in my original post because this is r/android and the Note 7 was discussed to death (that's how I got most of my news on it back in October). But since you are new here, or maybe you missed all that, and seem to have thought my points were "made up in my head", I've provided them for you in this comment. 

Does this mean my case is airtight? No, of course it isn't. It's possible they rushed the phone (even though there's no evidence). It's also possible that Santa Claus is real, but I'm sure I can get a bunch of objective information (ie evidence and facts) to make the case that he isn't. I wrote this because I genuinely hope you can come to understand the difference between subjective and objective and use it to form better arguments in the future.
[Well I'm touched by your confidence in my ability to understand that](http://archive.is/BpYRp). 

If you think my long comment meant nothing (as opposed to the first sentence which we've both established is just an opinion), then I think you need a refresher on how subjective and objective information works...or maybe you just didn't read past the first line.

Either way, I like your go getter attitude and I hope you keep up the sharp wit and the healthy skepticism when reading reddit comments. I hope you have a good rest of your day or evening. 
That's very true. Since that sentance was literally me stating my opinion (the "I doubt" part should have been a dead giveaway), I didn't think I had to add in a disclaimer that it's an opinion and shouldn't be taken as fact, nor that it has any special meaning behind it. 

Anyways I'm glad you added this comment for anyone who isn't familiar with how subjective and objective information works. In the future, I'll be sure to add the explanation in my original comment so you can spend more time adding to the conversation instead. 
Ok, thanks.
It's all about the Pixel now.

Although Nexus devices are good ones. I'd buy a refresh of the Nexus 7.
You absolutely can do that, but I doubt anything like that happened, since they usually start development of the next phone before the previous phone even goes on sale. 

They could delay any part of the development process (like taking too long to decide which prototype to go with) which would mean every other stage would have to get their work done on a shorter schedule; but the argument that most people made in regards to "rushing" the phone, was that they rushed the phone to put it out before the iPhone. There's no evidence of that at all, especially because the explosion part has been thoroughly explained and isn't a symptom of a phone being 'rushed'. It's a symptom of poor supply chain control (even though it's unlikely any company could have caught that prior to sale if they follow the six sigma standard), and an aggressive battery design. 

Had the phone been released before August, then we could certainly say it was rushed by comparison to previous models (like the Note 5 or the Pixel which were both made on timelines shorter than a year). 


How big is the entire thing?
Sure...but that's a cheap Nexus phone. 

Pixels are the new greatest thing.

Although to be honest, the new Pixel does look pretty great.
If they followed the same convention they had for the Note 4 and earlier Notes, I'm guessing the 836 would be in the Note 8 like all the other phones that will be released in the second half of the year (compared to the 835/821s that goes into phones released at the start of the year). In the past, it normally had 1gb more RAM than the S series, and the camera was usually better in terms of sensor, aperture speed, resolution, or other little things like that. 

Since the Note 8 is rocking a dual camera setup, compared to the S8 and S7, I'm willing to say it'll be decently improved over both of those phones. The sensor itself might not be radically different, but the overall experience should be better.
The Note series used to ship with more ram and a better processor than the S series (along with other improvements like camera/display, and of course the stylus). The Note 4 had more ram and a slightly newer processor than the S5.

The Note 5 had a better camera and display, but the rest was the same. The Note 7 was virtually a clone of the S7. The Note 8 looks like it'll have a better camera setup than the S8, which is nice. 
The Note series used to ship with more power under the hood (in various ways, but also the CPU) than the S series. Note 4 had more ram and a newer processor than the S5.

The Note 5 changed that and they started using similar builds for both phones, but with a bigger display, camera and stylus for the Note series.

Note 7 was a virtual clone of the S7, but it looks like the Note 8 will at least have a better camera setup than the S8.
It wasn't rushed. The Note 8 isn't either. 

Both phones came out 1 year after the previous, and designs on that phone likely started a long while before that as well.

If putting out a phone a full year after the previous one is rushing it, then every phone manufacturer is guilty of this. Which is why I never understood the "it's been rushed" argument people make. 


Technically, the Note 5 was "rushed" in the sense that it came out a couple of months before the previous Note phones had. No other Note phone, before or after the Note 5 has been "rushed".
Yea I was pretty dissapointed by that. When I heard the Note 7s were coming back, I assumed they'd be much cheaper, especially given that the Note 8 is around the corner.

It's a fantastic phone, and if it was released earlier in the year and a lower price, I might have bought it (again) instead of waiting to see the Note 8 first.
LG is fantastic...

So long as they're making a phone for Google. By the Pixel 3 (assuming Google uses another manufacturer), folks will be back at it with the LG jokes. 
That's unfortunate. 

Well, if it helps, I usually leave it on custom settings on the first page (I can never get it to work if I use a non-custom template...unless it's a template I made myself), and specify the type of files I'm looking for on the last page. You'll also want to make sure it's set to grab links/files off site as well. On the last page, might be best to leave "download from the following domains" and "don't download from the following domains" unchecked.

Otherwise, I'm not sure what else will help since I can't really run it myself on that site.

Good luck otherwise, if you find an application that works for you, let me know, just in case I ever need it in the future.
Sure no prob, glad I could help.
Is [this](http://i.imgur.com/HT079Ns.png) the kind of thing you're looking for ;)

I like to follow the philosophy of security through unnecessary confusion to keep my Plex library secure. If you can't figure out how to navigate your library, then nobody else can either. /s

-----------------------


In all seriousness though, that isn't my stash if linux isos. Just a small glimpse of the data on my to-sort (someday) list. In the directory above that picture, there's 24 folders named "new folder", there's 40 of them in that picture, and inside many of those, there's another hierarchy of folders named 'new folder'. All adding up to a total of 211 folders named "new folder", and every single one has family photos in it (following some sort of pattern/organization, but I've never put the work in to figure out what that pattern is). 

Rescuing that directory structure from a dying hard drive is a blemish on my otherwise, mostly well organized collection of data :/
Right, I forgot to add the part about using a static IP address. Their method works, and another method would be to [set up the IP address you want to assign to your iMac in the router itself](http://i.imgur.com/qrCyw3N.png). I just prefer using the router so I can avoid any potential conflicts, and I can see all the static IPs in one place. I don't imagine an IP address conflict would be much of an issue for you since it sounds like your iMac isn't usually fully shut down.

There's plenty of apps, free and paid for iOS to wake on lan, but the rest of the guide looks good. For your use case, setting up port forwarding would be easier and faster than setting up/using VPN to access your home network. So after you set up a static IP on your iMac, you should be good if you follow the rest of that guide. 

Edit: After you're fully set up, the only thing you'll need to keep track of is your home's external IP address. ISPs don't usually assign you a new IP all that often, but if your modem reboots, or once in a blue moon, they might assign you a new IP. So before going on a long vacation, it might be good to use www.whatismyip.com, just to make sure your IP is the same. I think it's been almost 5 months since the last time my home's IP address changed, so it's not something that happens often.
If you set up VPN type access on your home wifi router (many modern routers have some sort of remote access feature), then you can connect to your home network from wherever you are, and send a magic packet (aka wake on lan) to your iMac and wake it up whenever you need it. Connect to VPN, send wake on lan, wait for iMac to bootup fully, stream.

This allows you all the benefits of allowing your device to sleep when you're not using it, and also being able to wake it up no matter where you are in the world so you can stream something to watch. No additional costs or equipment are necessary (if your router supports this).

The wake on lan part is pretty easy, since there's dozens of apps for mobile/desktop/laptop that will let you wake up another device with the press of a button. I've never used wake on lan on a mac before, [but it seems you just need to check a box in the power settings](https://its.uiowa.edu/support/article/910)?

The VPN setup will vary from router to router. I know that many of the newer models of Netgear routers make it kinda easy. Basically, [you enable the VPN option](http://i.imgur.com/EGxPq0z.png), change the ports as you see fit, then download the configuration files from your router, and download the OpenVPN app (from the appstore on iOS/Google Play, or from the openvpn website) and follow the instructions during install. 

If you go this route and have any questions, I'm more than willing to help as much as I can.

Edit: Clarified steps for VPN setup.
Dunno if it'll help you, but I've used [Internet Download Manager](https://www.internetdownloadmanager.com/) (paid app with a 30-60 day trial) in the past to rip galleries/videos from certain websites in the past. 

I'm not really sure how it would do in a forum, but maybe you can have it [set to explore X many levels on the forum](http://i.imgur.com/Nr4S1NF.png) and 1 level off site (in case the link is to an image host that uses a gallery instead of a direct image link), and disregard any [image below a certain size](http://i.imgur.com/33pDBdJ.png) to help weed out the images you don't care about (ie avatars and other webpage elements or something). On that second setup page that I linked (step 4 of setup), you could set it to ignore content from the forum itself, since you said all the images you wanted are linked to other sites, not hosted on the forum itself, so enabling that setting would help too.

Might be worth a shot to try it out on a section of a subforum and see if it works for you before doing anything more. In order to get every thread of every subforum, I'm guessing you might need to have it set to crawl the entire site, which would take forever and then some (I'd imagine, since exploring the whole site would have it go through every page of every post as well).

Edit: [It also has options to enter a username and password if it's necessary.](http://i.imgur.com/IKQTBNx.png)
[Looks pretty normal to me](http://i.imgur.com/xFKcFnn.png).

But in my family's household, it's currently just netflix all day (usually not 4k) + me downloading/uploading of linux isos. And my bandwidth usage hasn't hit 8TB in the last couple months.

Unfortunately our upload bandwidth is terrible, so we can't afford a decent home surveillance system (we've got a few arlo cams which are motion activated before uploading anything). I've even given up on ever trying to get my linux isos backed up to the cloud, even though I have a GSuite account. 
Yea, I was just going to nuke the entire thing and start over from scratch. Luckily, my most important applications are from Docker, so it should be as simple as copying and pasting those files to get back up and running for Plex/Sonarr/etc. It'll just take forever for me to transfer all the data back to the NAS.

I have everything backed up right now, but I need to figure out a better/more realtime process before I start moving over to a SHR2 system.
Yea, right now I'm rolling with two separate (SHR/Raid 5) disk groups, but I did that because it was convenient at the time, not because I thought it was a better idea or anything.

I've been meaning to make it all one large volume with SHR2/RAID 6, so I'd have some breathing room if a disk died, but now I'm reconsidering that as well. 

I might need to figure out a better backup solution before I make that change. 
Is it worse to risk using two raid 5 setups (one on each unit), or a single raid 6 setup, across both units? 

I dunno what would be worse. Dead disk + an error/dead disk on rebuild (not as much of an issue if you smaller disks, or less of them), or an expansion unit dying/disconnecting and knocking out your array.
Haha no. I've been looking into meal replacements for quite a long time, and I used to use protein shakes since those are better for you than things like Boost. But protein shakes were the kind of thing you could only replace one meal a day, whereas I was looking for something I could drink for every meal of every day if I had to. It wasn't long after that I read about Soylent (which had just been founded as a company). 

It's been available to the general market for years now. It might not be at 7/11 yet, but you could get it from the Soylent website or order it on Amazon. 

I originally bought into them early on (in the 1.1 days), but I couldn't stand the taste, so I stopped using it until 1.5 and 2.0 were released. I've been using it since, on and off. Some days I'll drink nothing but soylent, some days no soylent at all, but most days I just replace 1-2 meals with Soylent. 
I don't know. It's a pretty popular cultural reference. Folks who are 20 years old know the reference even if they've never seen the movie. 

I'm sure some folks will have no idea, but I feel like it'd be hard to miss, especially if you Google soylent. 
Tl;dr: Drinking only Boost or ensure will lead to problems due to malnutrition over the long term. Soylent was designed so it could be consumed at every meal over the long term. 

The former is trying to fill you up with calories, the latter is trying to meet your nutritional needs for the meal you replaced. 

-------

It's definitely better than Boost and ensure. Those are designed to be meal replacements, only used sparingly throughout the day. It's basically a sweetened drink with enough calories that you need (some carbs and protein too to ensure you don't get hungry too quickly) and a multivitamin mixed in. 

Soylent is built from the ground up so you can drink it everyday and still be healthy since it's giving you all the nutrients your body needs, rather than just trying to pass along empty calories. 

Nestlé and such companies actually do have products that are similar to Soylent, but when Soylent was first released the only way to get those products was with a prescription from a doctor. Usually only given to those on extended hospital stays, in comas/paralysis, or folks with issues eating solid food. 

They haven't released those to the public yet, partially because they can charge a hospital a lot more than they'd charge consumers (especially when they have competition from folks like Soylent and the dozens of other similar companies that have popped up), and also because it would conflict with their current products/brands (like boost). 
If they offered rewards similar to how Samsung Pay works, I'd be using Bixby all the time, even if it turned out to be terrible and never gave me the right answers.
It's to try and incentivize people to speak more often and gain more data so Bixby can form better responses. Unlike other companies out there, Samsung doesn't have the voice data necessary to determine how many ways their assistant should be able to answer a given question (ie: What's the weather? vs How's it looking outside?). That's almost entirely due to the fact that nobody used S-Voice, even assuming S-Voice data is compatible with their current assistant (S-Voice only ever responded to specific commands, so it's unlikely it'd be useful anyways).

Other companies, have had lots of time to gain voice data before they were integrated into a phone assistant. Siri was an app on the appstore before Apple bought them, Google had Google Now, MS had voice input from Xbox and Windows Phones, etc.

Man, I wish you'd let game developers know that.

It seems a lot of folks are using betas all wrong.
I actually made a link to it 215 days ago, apparently. 

https://reddit.com/r/DataHoarder/comments/5g8ev3/whos_up_for_a_100pb_heist_split_it_5050_amazons/

Unfortunately the heist never even made it to the early planning stages. Maybe it time to try planning it again with our fellow datahoarders, now that Amazon Cloud Drive has bit the dust. 
If you wanted to, veracrypt has options to encrypt the entire disk, rather than making an encrypted container (which is the option folks are discussing here). 

And as I pointed out further down, if you need to expand a veracrypt container, you can look inside the folder where veracrypt is installed to find an application to expand volumes. 

If you stick with encrypted file containers (rather than encrypting the entire disk) you can download a portable version of Veracrypt and save that onto your hard drive. So if you go to your parents or friend's house and they don't have veracrypt installed then you can just run the portable app off of your external hard drive. 

I do the same thing with the USB drives. Anytime I put an encrypted container on a disk, I keep a version of a portable veracrypt on there as well in case I need it. You need Admin rights on the computer that you use the portable app, since it temporarily installs a driver, but other than that, you can use it on any windows computer. 
You can expand it. I've had to do that a few times. In the veracrypt install/portable folder there's other, stand alone, applications and one of them is a volume expander. It can take a very long time, depending on the state of your drive and how much you're trying to expand the volume size. 

I don't know if this is an issue on current versions, but trying to expand a dynamic container can cause issues. [See "dynamic" for an explanation on what I mean by dynamic. ](https://veracrypt.codeplex.com/wikipage?title=Creating%20New%20Volumes)

So for most folks that won't be an issue since they aren't looking to create dynamic volumes (which can present their own headaches). 
Is that what happened? It's been a while since I saw the video, but I thought I recalled him saying that something about his setup (on the failing hardware rack) had caused the replacement raid card, that he stuck into it, to become corrupted. I don't really know much about hardware raid cards, so I don't know if that's true or not, but it seemed to be what Linus thought (I think, I'll have to re-watch the video at some point). 
You're saying that it's safer to run downloads in a user environment than in a sandbox. Edge operates similar to a windows store app and has a sandboxed app data directory, which is not a system folder. 

I've never once heard anyone in the security industry suggest that running downloads with full user rights (as if it were downloaded to a user download folder) is better than running a potentially untrusted download in a sandbox. 
Everytime I open this in my reddit app (slide), it [shows this picture. ](http://i.imgur.com/4mQmKwe.png)

But when I open it externally, it shows George. 

He truly is a magician. 
It's available in the Google Photos app. 

[Settings for photo quality](http://i.imgur.com/cnVpnb9.jpg)

Edit: this is on Android's Google photos app. Go to settings then click on 'backup and sync' and you should see it there. 
What a/v codes do your files use? In my experience the roku is a champ and plays almost everything I can throw at it. It doesn't handle subtitles well, or at all on many of my files. 
Not just that, but all of our current nuclear power plants can makes weapons grade materials if we need them too. With thorium reactors, that's very difficult to achieve. So much so, that's its probably cheaper to build a new reactor than try to extract the uranium or plutonium from the thorium reactors process. 

Of course this would also mean we could start giving developing nation's nuclear power without worry of them making weapons... But like you said, that would cut into our fossil fuel exports. 
So it's a site specific issue? 

From what I'm seeing on there, it just seems people are using the copy password button or manually copying it which results in them losing passwords. The app should be updated to include the "copy password" button, or maybe just auto save all passwords generated in case someone manually copies it as well. 

Either way, I've been using the "use password" button when I want last pass to save the password and haven't had any issue so far. 
An application I use often  is Internet Download Manager for windows. It's not free but it has a free 30 or 60 day trial. Anyways it has a site rip feature. Tell it you want photos (above a certain size to avoid getting ads or something else) and videos, and it'll do its thing. 

You can have it preserve the original directory structure as well so you don't get a huge mess of items in one folder. Of course that depends on how well SG labels their directories. 
What platform are you using it on, because it sounds different from my experience. In my case, when I generate a password, it will save that password immediately. I usually have to go in and delete the saved generated password after I complete registration and it adds the site. 
You should look into the AAK plug-ins. Doesn't work on every site, but the more popular sites that try to ask you to disable ad block usually work just fine. 

A lot of sites like Forbes or Android news outlets or porn sites ot whatever will think that you're running a browser with no ad blocker installed. There's a version that works with unlock origin. 
Yea, I can echo that. I was buying some smart devices for our home to make it more energy efficient, and while I was at it, I thought I'd toss in the echo dot which might provide some nice functionality with the other devices.

I hope Google releases something that cheap soon, because I'd love to buy it and try it out, but 100-200 is too much for me to spend on something that might be a nice gimic (like Alexa is right now in the house).
I think [this link,](https://www.extremetech.com/computing/240878-western-digital-announces-new-high-capacity-12tb-14tb-helium-filled-hard-drives) to the actual article would have been a bit more useful.

Maybe you should delete this one and repost it with the link to the article.

https://www.extremetech.com/computing/240878-western-digital-announces-new-high-capacity-12tb-14tb-helium-filled-hard-drives
As far as I know, OneDrive uploads the original photos. I use OneDrive and Amazon Cloud Drive because they keep the original photos. 

But really, it's as easy as installing the OneDrive app, logging in and then going to the settings and selecting which folders you want it to back up/search for pictures in. 
I think he's talking about the factory workers, not the engineers. There were issues a short while back where workers in California were complaining about wages and working conditions/safety concerns. Factory workers aren't the kind of people who are making enough of an income that they can just quit as easily as that and they likely live paycheck to paycheck.

I don't think it's fair to blame Elon Musk for that though. These kinds of issues get handled (or ignored) by middle management and I'm guessing Elon Musk wasn't even made aware of the issue until union reps needed to be brought into negotiate with management. At which point I believe Musk tweeted that he'd take a personal interest in fixing the situation. 

Edit: I distinctly remember reading an article in the local paper about that back when it happened. Elon Musk said he had no idea any such situation was happening and that he'd handle it personally. And I believe that, because Musk is running two companies, he's not going to be briefed on every complaint that workers have.
I just asked if it can rap, and the exact response was "I'm not much of a rapper, but I can sing 'Happy Birthday'"

I wonder if Happy Birthday is still copyrighted or not, cause I know in TV shows, they never sing more than a few words of the song to avoid paying royalties. 
That would be a great way to go about it as well, using crowd sourced info for development, rather than rely on Samsung devs to add functionality for any particular app. And it would makes sense for them to not add a module unless you had the corresponding app installed. 

At the moment, Alexa only works entirely in the cloud as well, and even though there aren't really any apps for it to interact with persay, I think they limit the skills is so it doesn't end up with 10 conflicting results from 10 different skills when I ask it for a chicken parm recipe. Not something that would be an issue on a phone since folks probably aren't going to install 10 different recipe apps.

Either way, sounds like Bixby certainly has a lot of promise.
Right. With Assistant, Alexa and Cortana, you can install these modules that they call "skills" to give the AI new functionality. When I searched for recipes with Alexa, it'd read out a result and then ask me to check the Alexa app for details. After installing a random cooking 'skill' (I don't remember which developer made it), I can ask her to find a recipe and she'll read out the ingredients and steps to me as. 

Since Bixby seems to interact with apps, I imagine its skills would be different and more about adding app compatibility. I'm guessing Bixby will support certain apps by default (like whatever is listed in Bixby labs at the moment), but I'm wondering if they add support for a new app later on (like Textra, which is the texting client I prefer to use), will they push that out to every phone, or will users enable the "Textra skill" or something like that.

Anyways, I'm probably jumping the gun by asking that. It might be something that won't be available until the beta is over.
Yea, so am I. So are the commands enabled all the time (assuming you have the app), or does it prompt you to install any kind of module in order to interact with that app? I'm assuming all of Samsung's own apps (mail, texting, etc) will be included by default, but for Google Music, did it need to install anything else?

I've been playing around with Cortana, and Alexa lately, and both of them use installable 'skills' to tie in other services into their 'AI'; so I was wondering if it's the same for Bixby or not.
I thought they would be months behind the Google Assistant (and in some ways they probably will be), but if it can interact with apps in that manner, that just might let them close the "we need to attract devs to our platform" gap entirely.

I'm still hoping for some Viv like demonstration, in which it can perform functions like calling an Uber, without needing the app installed, but in the meantime this is an impressive feature.
The last point is a good one that many Americans always seem to gloss over. Many believe extra taxcuts for the wealthiest will lead to them investing in ways that create more jobs, when often, they invest in businesses that can better streamline operations so less expenses (like jobs) are needed, or businesses will use investments they receive to do exactly that. The goal is always to make more money, not to give handouts to companies who are trying to keep Americans employed or get them better jobs.

When you increase the amount of money that the poor/middle class receive (whether through UBI, minimum wage, or providing better services in the form of healthcare/education/etc), it acts as an economic multiplier*. Those in poverty have no choice but to spend all the money they receive because they have to pay for rent, or food, or other such basic accommodations. Giving them more money allowed them to access more goods/services, leading to increased businesses from a previously untapped market, which in turn provides better paying jobs or more jobs as those businesses earn more money and are able to expand their business. 

The common argument against this is inflation and raised prices, but the cities who have drastically raised their minimum wage have found this isn't the case. People and businesses making more leads to higher tax revenue, which can be put back into paying for services people need (police/fire, education, healthcare, etc). That doesn't account for everything, but using the cities that have raised minimum wages as an example, you often see that prices haven't increased (when you consider a year or more after the wage increase), but competition has, as more business pop up. In San Jose for example, there was heavy criticism saying that restaurants wouldn't be able to afford a minimum wage increase and they'd have to close/raise prices. The initial response was for a few restaurants to raise prices, a couple closed, but shortly after a huge number of new restaurants popped up as those businesses were experiencing better than normal business. The results were so impressive that San Jose has started to do studies on how effective 18 and 20 dollar minimum wages would be.


*There's a specific term for how much value a dollar has in the hands of different wealth classes. The poor have the highest value since that dollar will circulate through the economy, and the wealthiest folks have the lowest value as their money will sit in long term investments and banks. For the life of me, I can't remember what the term/concept is, but I do know it was updated regularly by the Fed (Department of Labor, I think).

While I think our (I live in the US) military spending is very bloated, and we fund to many projects with very narrow use cases (only to see most of them scrapped), the military might be useful in this case. 

It's definitely much more ideal if the government would fund this directly, but the military is looking for alternative fuel sources because having an easily disruptable and exhaust able fuel source is a major problem (especially for FOBs). 

Lockheed Martin is working on compact fusion reactors (it's debatable on how likely that is to work, since most folks seem to believe it's easier to control heat with a larger reactor) for the military. I certainly hope they make progress, because they'll surely want to sell it for civilian use as well. 
The investment into fusion is one with an indeterminate payoff and that's the calculation many nations make. Yes, we'll probably nail it one day, and the payoff will be quite rewarding when we do, but will it be in 5 years, 50 or 100?  

With the US government, there's always more to consider though, since it's no secret many of our politicians are paid (in various ways, like campaign financing) to put the interests of certain industries or companies first. It could be that a given politician may just have a lot of constituents who work in one industry (like coal) and they don't want to jeapordize those particular jobs by funding an alternative. 

One of the large companies with influence who's working on fusion (Lockheed) doesn't need to lobby congress since they're developing compact fusion reactors with the military in mind. If/when they crack it and look towards selling it for civilian applications, then they'll have to out lobby the other industries for congresses favor. 
If Google wrote the survey's I'm sure they'd have included more options.

What's your demographic info by the way (if you're willing to share)? I never get any interesting surveys, just "did you visit one of these places today?" type surveys. It's super dull.
People already are buying PCs with similar amounts of power, that's not the problem and isn't the issue here. It's pretty trivial for devs to add options to disable X textures or AA and whatever else. It's much easier to build for the best possible PC (ie the insane machines running 1080ti's in SLI) and then allow the game to scale down on PC, which is why many devs allow for such large range of hardware to play their games. 

What's not easy is to spend a lot of time optimizing a game for a console/fixed hardware and then expecting those devs to have the time and money to push PC hardware to the limits as well. When you have fixed hardware, you have to make choices between how many AI elements you want to run because the hardware in question only has so many cores, or whether you want to eek out that extra bit of graphical power to improve the visuals, or focus on adding more frames per second. It takes a lot of work to get it right when you only have so much power you can use. With PC, there's a larger margin for error and you don't need to optimize it for every graphics card out there, just let the user turn things on and off depending on how it works for them (it won't be nearly as precise, but it works). With consoles, that won't fly because you want your game to look good and perform well and you can't just say "we'll just turn X things off until it falls in the range of that hardware", because then you risk it not playing well, or not looking as good as it should.

If every developer made games for PC first and consoles as an after thought, it'd be better for the industry, but that wouldn't be simple either (at least not when time is concerned for the developer). Either way, that's certainly not the case because publishers and console manufacturers go through a lot of work to ink out deals that allow them to influence the direction a game takes or which platforms are prioritized (Nvidia and AMD try to pull this kind of BS at times as well). So, regardless of sales, there's immediate financial incentive to work for consoles first and PC later, which is why people in this thread, and developers (especially those beholden to parent companies/publishers) don't like the current state of the gaming industry.

I'm just glad that Microsoft and Sony have finally decided to release a new console every couple of years. That should help alleviate the problem, but it'll still be there.
The console userbase cannot be larger, especially by the comparison methods you were using earlier. If even 1/5th of the people who own consoles also own a netbook or laptop and play casual games, then the console industry is minuscule by comparison. Regardless the statistics don't back you up on this. The enthusiast grade PC gaming market (not the general PC market which would include people buying laptops to run MS office and is in steady decline), is valued at 31 billion and is growing 6% YoY, and consoles at 6 billion as of 2016 (check out JPR and Superdata Research). Either a small group of PC gamers are building $5k-10k+ machines and buying a lot of games, even the same ones 100s of times to make up the difference, or there's a lot more PC gamers than console players (especially when we use your definitions of gamers; ie everyone contributes).

And I never once said that consoles (or PCs for that matter) have to 800 dollars, or even 1000. If you've ever been to any of the numerous PC reddits (and PC gaming reddits), you'd know that a lot of people are rocking 400-600 dollar PC builds. I literally said that we can't compare netbooks/laptops to consoles. My opinion is that people who won't spend 50 bucks on gaming hardware, probably should count as casual gamers, while others are hardcore gamers. I happen to believe that consoles are dedicated gaming machines used by hardcore gamers (so I don't believe they belong in the same category as netbooks). 

Some better comparisons to make would be to compare computers of similar specs to consoles. A better comparison would be based on price because consoles have a long R&D process and by the time they release to market they're using dated specs, so it's easier to build a better PC for the same price. Or one of the best comparison methods would be to compare people who play AAA games on their computers to people on consoles (regardless of whether those specs are higher or lower than a console). Because I think AAA games are a pretty good standard for what constitutes hardcore gaming.

My only point was, that I thought it was ridiculous to compare casual gamers to people who are going out of their way to buy dedicated gaming machines (whether PC or console) and willing to spend as much as 400-500 dollars on them; and that's why the Steam hw survey is utter garbage in this regard. 

If this is some kind of dick measuring contest for you, and you feel the need to show consoles are superior, then whatever, I concede and you win. I own and play on all platforms (except the Switch, but it doesn't have a large enough game library yet), and I really don't care about that kind of thing. People should buy whatever they want, I just don't want game developers to hold back progress because of consoles (which they do). Anyways, the only reason I responded the first few times is because I do care about accuracy, and comparing the casual gaming market who won't go out of their way to spend 30 dollars on a game to the hardcore gaming market just made no sense in my mind.
That would certainly be more useful information. At the very least, there should be a baseline set for comparisons. If a baseline isn't set, then I think another good comparison might be to take the most demanding AAA titles and see what specs their playerbase runs. For example, The Witcher 3 is a AAA game from 2015, works well on the PS4, and as some youtube channels have shown, you can mod the hell out of that game to make it run on hardware that gives you PS2/3 level graphics.

So I think it'd be interesting to know, are most of the folks who are playing The Witcher 3, running specs higher than a PS4, or are people modding the game to make it run on computers lower than the PS4 or lower than the minimum recommended settings?

That way we can, more accurately, weed out folks who only use their devices to play casual games.
Exactly. I know it's anecdotal, but I've only ever known one guy who owned a gaming PC, but no laptop or tablet. 

Most folks have a laptop for work/school, and decide to toss Steam on there, because after a couple years of Summer sales, you'll rack up a lot of casual games that can run on just about anything.
So in your mind, someone who buys a laptop to run office products, but then puts Steam on it in order to play some casual games is directly comparable to a console gamer who is willing to spend 400-500 dollars on a machine that is dedicated and built around hardcore gaming? (Or are you looking at this the opposite way and saying that consoles are so low powered they can't be considered hardcore gaming platforms and should be in the same category as netbooks?) Not to mention, some of those console owners probably own a low powered laptop that they put steam on to play casual games when they're away from the home. That only serves to further skew the results, since I can't see console gamers spending money to buy a gaming laptop when they already own a console at home.

Do you think anyone is buying a PS4 Pro with the intention of running office apps and then decided that since it could handle a game or two, they'd toss a platform like Steam onto it? Or do you think anyone is going out there to buy a 400 dollar PS4 Pro with the express purpose of playing casual games like Stardew Valley?

I guess I have to ask, where's your cut off point? If you consider people with ultraportables/netbooks/etc (hell even rasberry pi's run steam), to be directly comparable against hardcore gamers, and given that some of those games on Steam are about as computationally demanding as a Facebook game, should we consider Facebook gamers against console owners as well? Given how low the bar has been set, should be include mobile gamers to further pull down the average in Steam hw surveys? I mean, there are some games on mobile which are more demanding than some of the games on Steam, so it does kind of make sense if we're willing to compare hardcore gamers to just about anyone/everyone.
I doubt that's anywhere near accurate though.

I'm willing to bet an overwhelming number of people put Steam on their laptops, even those who own gaming rigs. A person with a gaming rig and a laptop is effectively cancelling out their contribution to the survey by giving results on opposite ends. Some might be like me who keep around old laptops/desktops to re-purpose them as servers/htpcs. I have 2 laptops at the moment with Steam, one mini-PC (with an igpu, which I use as an htpc in addition to my xbox one), and gave away my old gaming PC, so I can build a new one over the coming months. I'm quite negatively impacting the hw survey. 

Anyways, I have friends and family members who only have laptops (some of whom give the Xbox One/PS4 a run for their money), who also use Steam, but they aren't trying to run the latest and greatest games on it. They use it for WoW, LoL, Dota 2, CS, etc. The same can't be said for Xbox One or PS4 users, who are fully expecting to run the latest AAA games on under powered hardware.

My point is, many folks with gaming rigs are cancelling out their contribution, while anyone, with any hardware can run Steam (even console gamers, who have a cheap laptop that they want to use to play casual games). We shouldn't be comparing casual gamers who want to play Stardew Valley, to people buying consoles or gaming rigs with the intention of playing AAA or big development games (as referenced in this post). If you want to make an apples to apples comparison, Steam hw survey is the wrong place to do that.
I do the same.

This was something that was sorta thrown out there as a random idea by Linus Tech Tips, but they were saying with how many services there are out there now with unique content (Netflix, Hulu, HBO, Showtime, CBS, Amazon, etc etc) that it'd be great if Plex could act as a single portal through which you can access all that content.


And it's starting to sorta seem necessary for someone to offer that kind of service. You had cable providers who bundled everything and gave you access too all these different stations, and then cable didn't seem as necessary because Netflix had just about everything, on all your devices, for a low convenient price. Now they're focusing on their own content and same goes for every other station out there (creating their own apps/webpages). Now all these shows are spread out and it seems that you have to go to each app/webpage to stream the thing you want. 

It'd be nice if you could access all your subscription services through Plex.
I was talking about the new x299 motherboards with the LGA 2066 socket. Those motherboards need to support all the new CPUs, from the $240, 4 core i5-7640x with its 16 PCIe lanes and two channels of DDR4 memory, up to the $2k, 18 core i9-7980xe which has 44 (I think) PCIe lanes and 4 channels of DDR4 support.

Basically, if you wanted to save some money and opted for one of the new i5/i7 (both of which should be good for gaming), you're still going to spend more on the motherboard than you should have to because all x299 motherboards are built with PCIe lanes and extra RAM slots your CPU won't be able to use. If manufacturers could make multiple variants of the motherboard, then they could make a cheaper version with less bells and whistles to match your CPU in terms of features and cost.
I don't know about the Duo, but for the other enclosures (specifically the Easystore), they won't work unless you break a few of the contacts on the circuit board. I tried that but I wasn't able to get it to work. There's a few youtube videos out there about it though.
I've seen folks in Plex complain about ffmpeg's hardware transcoding on Nvidia GPUs as well, so it seems to be a common trend with hardware transcoding on some devices.

I've never tried out any hardware transcoding options, but I guess I'll have to try out quick sync for myself sometime and see what the quality is like. The only devices I need to transcode to are iPhones and iPads, is the final result so bad that it'd be noticeable on a screen of that size?
Tl;dr: Price wars can only be avoided by oligopolies that have equal market shares. Short of that, it's more like a monopoly and the dominant player calls the shots. 

Long post:
-----------------

You're not wrong, and the cell phone industry is the perfect example of what you're talking about. The price signaling between Verizon and At&t led to higher prices (technically lowered prices, but they removed unlimited data in favor of limited data + overages, so it's higher prices when the value of the plan was considered), and they both went along with this because they knew that competing with eachother would lead to less profits than if they just allowed their prices to artificially rise. 

And it makes sense as well. Split the country down the middle, half with At&t and half with Verizon (sure some smaller players are still around), but you know your opponent is big enough to equally throw down and counter your every move; so you'll never make a dent into capturing their market. You can't price goods so low that you make little profit (or even a temporary loss) kind of like how a corporate giant would starve out the small/local competition, because Verizon is massive and can go toe to toe with you for as long as you decide to make that foolish move.

So instead, you announce you'll raise the prices, and you wait to see if your opponent follows suit, and if they keep their prices low, then you just reverse course (companies test the waters in this way and reverse course all the time). Soon after, Verizon announced the same thing and then both companies were profiting more than they ever could have if they had tried to compete against eachother.

If it wasn't for the FCC/gov rejecting At&t's bid to buy T-Mobile, then we'd likely still be in the middle of those same rising costs with lower value/plan. After that, T-Mobile started their uncarrier initiative and brought some semblance of competition to the market again.

----------------------------

The **huge** difference here, is that it's not the same type of oligopoly. In the previous example, At&t and Verizon were the two biggest players and had large, and mostly equal, market shares. AMD and Intel aren't anywhere close to having the same market share, even if they are, technically, the two biggest players in the game. Intel was/is much closer to a monopoly, and AMD has a lot of work ahead of them to capture the market (with both businesses and consumers). 

So even if we only have 2 companies competing, AMD, and their small market share, is in no position to try and make any unspoken deals with Intel (the way Verizon/At&t could). If AMD tried to raise prices the way Intel was, they'd lose more market share to Intel. Up until now, Intel was able to get away with charging high prices for processors (like charging 2k for their LCC silicon processor, the 6950x) without any regard for AMD. 

AMD has brought back competition with Threadripper, which is why Intel is finally allowing better processors for the consumer market (ie using their more expensive HCC silicon, which is usually reserved for business partners). If it wasn't for AMD, we likely would have seen an iteration on the 6950x, which means a 12/14 core processor on their LCC Skylake-x wafers for 2k (saving the HCC silicon for business partners who will pay far more). Now they're only charging 2k for their HCC silicon processors, which means they must have been making a real killing on the 6950x.
Yea a lot of that stuff will rely more heavily on the GPU, than CPU. Plus the i7-7700k comes with an igpu, so you could take advantage of that where applicable (like multitasking; using your gpu for rendering and your igpu's quick sync for transcoding/streaming videos to other devices). 
I might be misinterpreting what you're saying, but if the midrange i7-i9 has enough CPU performance that you need, and you want to save some money (possibly by not getting as much accessory hardware), then Intel is kind of screwing you over. 

Since all of these chips share the same socket, that means motherboard manufacturers can't make cheaper/more expensive versions of their motherboards based on what your CPU can support. Now, they have to make 1 motherboard that has to provide all the features that the highest end CPU can make use of. Which means providing more PCIe lanes, and other features that you can't take advantage of if you get a cheaper CPU; and providing those extra features also means a more expensive motherboard.

If Intel didn't limit their CPUs in this way, then it'd be less of an issue. If you have a cheaper CPU, and have to pay for a more expensive motherboard, but you can use all the features on it, then that's still a decent value. Even if you never make use of it, you still could if you wanted to. In the current situation, you could be paying for a more expensive motherboard that has features you won't be able to use, and paying for something you can't take advantage of just feels like wasted money.
Yea, the right click and search thing is one of the things I miss most, I think.

That and the extension 'HoverZoom'. Other than that, it has a lot of the features I want. Another bonus is the getting rewards points for using it. I know it's kinda dumb, but I do enjoy some of those quizzes they give out, if it's on a topic I know anyways.

When I'm travelling, or outside of the house, I almost always use Edge, but if I have easy access to power, then I'll switch back and forth.
You still get all the updates that Microsoft issues, whether critical, security or normal system updates. You can even enroll in the Windows Insider Program with an unactivated Win 10 install.

Basically, it'll act and feel like the real thing, minus your ability to customize themes/desktop directly from the Settings app. Whether you have full control over telemetry really depends on what version of Windows you're running. If you have an unactivated Windows 10 Pro, you can turn off everything via Settings and Group Policy. If you have an activated or unactivated Windows 10 Home, you won't be able to turn everything off without registry hacks.
Activating Windows registers it with MS as a legal copy of Windows.

In previous versions of Windows, if you didn't activate it, they would; show that banner in the bottom right, change your desktop to a black background every so often, or even shut down every 2 hours (I think Vista had that?), and things of that nature to get you to buy a legitimate copy. With Windows 10, it doesn't let you change the background (although I think you can find a picture and right click on it and select 'set as background'), and you have that watermark in the bottom right. 

Pirated software comes with KMS activators which basically tricks Windows into thinking it's been activated, so it's not as much of an issue there; but if you download a legitimate copy (which I recommend everyone do, even if you don't plan to pay for Windows) and you don't activate it, then it shows the watermark you see above in the picture.
First thing that came to my mind was that it looked like a F-117.

That mouse is going to be deflecting all kinds of radar.
Right. I think most AAA games, or any fast paced game certainly needs at least 60fps (or just an unlocked framerate), but there's indie games that simply won't benefit in any real way from 60fps. 

The art style, visuals, gameplay/mechanics of any given game might make bumping up to 60fps unnoticeable. Some types of games will always benefit from 60fps, but on some it would just be a waste of processing power.
Well, my gaming experience isn't diminished if Game Dev Tycoon ran at 30fps, but if folks in PCMR feel 60fps is necessary, then perhaps we should push for our own platforms to mandate 60fps before we mock other platforms for not mandating that either.

As any poor PCMR member knows, 60fps is almost never achievable on the minimum recommended hardware for any given game (even on the lowest possible settings). We should push Steam to mandate that devs change their hardware recommendations, so that on the lowest settings, 60fps is achievable on their minimum recommended hardware.

We should also push Steam to require that unlocked framerates, or at the very least 60fps, before a dev's game is sold on their platform. There's a huge list of games that are locked at 30fps on Steam.

After we accomplish this, then at least we'll be justified in mocking the CEO of Xbox because he's not forcing all devs to optimize for 60fps.
Not all games need 60fps, but the folks with 4k TVs will likely want all their games to be 4k compatible. 

Hopefully any game that matters (ie competitive games) will be at 60fps, like Halo and Forza.
They do care about 60fps, which is why more games are transitioning to 60fps (Halo and Forza at least, and I expect competitive games that want to be taken seriously will as well). But his point is, none of them care if games like Lego Batman or Minecraft run at 60fps. Unlike fast paced/competitive games like Counter Strike, you're not going to see improved gameplay from forcing smaller games/indie devs to use 60fps. It's better to let developers decide whether their game is the kind of game that could benefit from extra fps or pushing that extra power towards visuals instead.

Steam doesn't mandate that developers ensure their minimum requirements allow for 60fps gameplay on the lowest settings, nor does Steam force devs to provide more than 30fps, or use unlocked framerates; and Xbox isn't mandating that all developers optimize for 60fps over visuals. It just isn't necessary for some games, and on a fixed hardware platform, it makes more sense to leave that choice to developers.
Well he is in charge of a console division, which naturally makes him the enemy in many people's eyes. Makes it that much easier to take cheap shots at him with out of context quotes to make him seem as dumb as your average 'peasant'.

Personally, I like Phil. I think he's making positive changes, like Xbox Play Anywhere, bringing games that used to be Xbox exclusives to the Windows market again, said he's sick of the "buy this game on this console and get this cool skin/level/etc" exclusivity bullshit, also said that he believes the industry will be better off if both Nintendo and Sony thrive, and just a little while ago he called out extreme console fanboys as destructive to the video game industry. 

That last one pissed off many folks in the Xbox reddit, but only cause he phrased it as saying "console wars should end" instead of "flame wars should end". Most of them didn't read the article and assumed he was saying competition was bad, even though he literally praised competition several times in that article.


Yea, it works really fantastic with Google Drive. I've only tried Google Drive and Amazon Cloud Drive, and Google Drive works great, and Amazon has always been a hassle, so they don't officially support it anymore.

If you buy a license from them, it won't expire and entitles you to updates from then on. I don't think they'll go out of business, and they've got some plans for bigger projects coming up. Either way, if something like that should happen, the software should continue to work just fine, you just wouldn't get any updates. If for any reason you can't get access to the software, they've made (and are making) decryption applications. Basically you just download the contents of your "Stablebit CloudDrive" folder from your cloud provider onto your hard drive, and run their decryption application. I haven't used it, but I think it creates a read-only drive that you can use to extract your data.

Just a heads up, much like Veracyrpt, you can't mount the same drive onto 2 computers at the same time. Since it works at the block level (basically recreating a hard drive; unlike Expandrive which works at the file level), like veracrypt, doing something like that would dramatically increase the chance of corrupting your files; since at any given moment the two computers could be trying to upload different changes. They are working on having a read-only mode, so you can mount a drive on multiple computers at the same time.
Well, there's two ways to use Stablebit CloudDrive in this scenario.


The first method is to achieve a goal similar to what you/others have said rclone can do; which is to only upload the changes. If that works, then it's probably easier to stick with veracrypt.

Either way, option 1 is to use Stablebit CloudDrive to create a local drive on your computer. While veracrypt stores all of it's information in one large file container, CloudDrive stores it in chunk files (you can chose how large you want those files to be when creating the drive). So when it comes time to upload, you will only need to upload the chunk files that have been modified, rather than a large file container. Other than the fact that CloudDrive stores information in chunks, while Veracrypt stores it in one large file, they're both similar applications. If you want to use non-AES encryption, it might be best to stick with Veracrypt.

Another way to use Stablebit CloudDrive, is to use it as it was designed to be used. Connect CloudDrive to your cloud provider, and it'll write all changes directly to your cloud provider, inside a folder called "Stablebit CloudDrive". In this scenario, Expandrive isn't needed at all, since CloudDrive can mount your encrypted drive directly from the cloud storage provider. You can use it to mount several drives at once from the same provider if you want, or several drives from several different providers (although Amazon Cloud Drive isn't supported anymore).

https://stablebit.com/
Yea, I saw a thread in PCMR about this yesterday and that's when I tried to log into write my review. I wrote the same comment in that thread as well.

My gaming PC has been out of commission for a year, and I haven't been using Steam much, so I had forgotten all of that stuff until I read my review. Thinking back on it, folks being banned from GTA Online, even though they only used mods in single player was a big issue for a while until Rockstar came out and said they won't be doing that anymore.

Edit: And I remember I was originally upset about the 'fake sale' issue primarily because the regular version of GTA V, without the in game cash, wasn't available for purchase during the period of the sale. I took it to mean they were just screwing folks by pretending their game was on sale when it really wasn't. 

After reading up on it, it seems they claimed it was a pricing error which caused the normal version of GTA V to be unavailable throughout the sale. Of course, I'd say the same thing after the fact as well, regardless of whether it's true or not.
I went to write a negative review for GTAV and found that I had already left one back in 2015.

2015 me was upset about the fact that they were banning people for using single player mods, and the fact that they raised the price of the main game from 60 bucks to 80 bucks (and threw in a small amount of in game cash), and then immediately dropped the price back down to 60 dollars so they could claim their game was on sale. 

It was during the 2015 Steam summer sale, so doing this would have given their game more visibility without actually dropping the price. Which, past me thought was unfair to the developers who legitimately participated in the Steam sales without using such tactics. 
True, then they could have charged 60 bucks for GTAV and then charged another 20-30 bucks for GTA Online. Given the popularity of GTA Online, and some decent marketing to push it onto people, I'm sure they could have gotten away with it too.

I mean, given how the video game industry is going, where many games are riddled with microtransactions, day 1 paid DLC, seasons passes, and where every little gun/character skin costs a dollar, I have no doubt that's what they would have done if they decided to separate the two.
Right, sorting by people sounds like another thing that offline software, or Amazon/Google could help with. I needed a picture of myself in sunglasses once and I just had to type "me in sunglasses" and it brought up all the pictures of me in sunglasses. You don't need to worry about sorting photos into categories of you and everyone else. If you ever need a photo of a specific person, just click on their face or type in their name if they have names associated with them.

As for the dates on old photos, yea those can be tricky. Photo software and cloud software will usually use the metadata to figure out the date; which means it'll end up grabbing the day it was scanned in.
If I have a container that I'd want to upload, I'd probably use Stablebit Cloud drive instead. Create a local drive with it, then upload the pieces, and I'm the future you can use a backup client that only uploads the parts that have changed. 

Anyways thats the best solution I've been able to find. I've been looking for a way to conveniently split a veracrpyt archive (while keeping it in a usable format) so you don't have to upload the entire thing to the cloud drive every time you make a small change. 
Well my mom is the one who keeps the family photos organized and she does the folder organization by dates. 

2010

--March

----12th-20th Trip to Oregon

Some multi month items get their own folder, and same for items that span years. We keep the videos separate but they're organizes by date/event as well. 

Don't know if this is the best way to do it or not, but really we use Amazon and Google photos for sorting and searching. I think it's probably better to use something like Google or an offline application that lets you search by any term you can think of "Oregon", "2010", "family vacation", "boats", "me in sunglasses", etc. 

[I left a steam review, which is something I rarely do](http://i.imgur.com/v0yNWf2.gifv).


Edit: Apparently I had written a negative review already. Seems like past me wasn't a fan of how they banned people who used single player mods, and I apparently didn't like how they temporarily raised the price of the main game from 60 dollars, to 80 dollars (and threw in a small amount of in game cash), only to cut it back down to 60 so they could claim their game was on sale. It was during a Steam summer sale in 2015, so doing that would have given their game more visibility while maintaining the same price. 
I'm not positive what will happen exactly, but the drives are reducing in pressure as the helium escapes. Oxygen has different diffusion rates for different metals, and I've never looked up what materials are used to make helium drives. 

So a couple of things could happen and it'll depend on manufacturer specs (if that info is even available to the public):

1. The drive will leak helium until it the pressure equalizes with the surrounding environment, at which point atmospheric gasses can enter.

2. The drive doesn't allow larger gasses in, so the drive will leak helium until it reaches pressure equalization with the surrounding environment at which point it will stop.

3. The drive doesn't allow larger molecules (like oxygen) to enter, so the drive will continue to leak helium until it reaches equalization based on how much helium is in the surrounding environment (which is a very low concentration in our atmosphere). 

So based on manufacturer specs, it will be either 1 or 2, or it could be 1 or 3. I'm not familiar enough with the physics behind it to say whether it's 2 or 3 that will happen if the drives don't allow larger molecules in.

Either way, you're not going to lose that much pressure until it's well after the expected lifetime of the drive. Traditional failure methods, like mechanical failure, are still going to the primary concerns for helium drives.
Tl;dr: Helium will start escaping immediately after the drive is manufactured, and it'll continue to happen at a, more or less, consistent rate. WD/Seagate could give you a 20 year warranty on helium leakage, and you'll never get a chance to RMA a drive.

What's happening isn't wear and tear causing leaks to become more common; so it won't happen any faster when the warranty is up (unless the drive is physically damaged). It's the fact that the helium particles are so small that they can pass directly through solid metal. Different sized particles have different diffusion rates through different materials, but helium is small enough that it can diffuse through most materials. This same process happens to metal helium tanks as well, but it's such a slow process that helium losses are almost always negligible. 

If a WD 8TB drive is sitting a store shelf for 20 years, and you buy it, your drive will have less helium than it would have had 20 years ago. But even still, chances are, you'll never get the chance to use the hypothetical 20 year helium leakage warranty from WD, because you probably won't have lost enough helium to affect performance.  

Suffice it to say, cheap, high capacity SSDs will likely dominate the market before one of these drives loses enough helium through diffusion that it affects the drive's performance. And chances are, you'll suffer mechanical failure long before that.

Edit: Spelling and sentence fixes.
I read that helium will slowly leak out, due to the nature of it being such a tiny particle. But by the time enough helium escapes, you'll either have junked the drive long ago, or you'll have started using 15TB SSDs cause it's cheaper than trying to maintain your ancient 3.5" drive bays.

Anyways, I'm not a physicist, I just go off what I've read and I'm not concerned at all about leakage. I've only had them for less than a full year, but SMART shows no leakage at all across the dozen drives I own.
I've been trying to find the changelog info for this update, but every link I've tried will only show me 6.1.1-15101-4 as the most recent version. Clicking on the link in this post shows me the same thing except for the RS2416+ device. 

The update shows up on my NAS, and I see it in [Synology's download area](https://usdl.synology.com/download/DSM/release/6.1.2/15132/), but for some reason I couldn't find the changelog. 

Anyways, good to know what the update is before installing it. Thanks for posting the changes.
Are you serious? Do you not understand the difference between the stupid flame wars that extreme fanboys engage in and acknowledging that the consoles aren't mirror images of eachother? Simply acknowledging there's a difference isn't bad, it's the whole essence of competition.

I guess we should call bullshit on everyone at Xbox for having the audacity to put in features that other consoles don't have. Lets go ahead and call bullshit on everyone in the Xbox marketing team for advertising any aspect of the Xbox that isn't 100% similar to the Wii U or PS4. Instead of punishing Xbox or PS, maybe the right path is to have every product standardized with a specific template, to ensure there's no differences between the Xbox, PS, Switch just because we don't want any company to advertise their product in a way that could outshine the others. /s (in case it's not clear)

Sorry, but your comment is entirely out of place. You're trying to call out the guy, whose entire job is to sell the Xbox, as being at fault for trying to sell the Xbox by advertising it as a more open platform. 

Look it up and tell me how many times Major Nelson has personally insulted for choosing a different product, or where he's spouted bullshit facts that have no basis in reality in order to prove the other person wrong; because fanboys can't consider that one product might be objectively better in some ways and worse in others. Show me when he's gone out of his way to troll a particular person, group, forum/reddit for weeks, months, or years on end, simply because those people chose a product he didn't chose for himself. Find me a few examples of him going to the PS reddit/forums and concern trolling non-stop about how worried he is that PS's feature/game/product is under-performing X way.

Differences in products is the essence of competition. Nobody is saying people can't talk about that, because the differences are the whole reason why people should choose one thing over the other. What Phil Spencer is saying is that the bullshit extreme fanboyism is toxic and doesn't help the industry grow or compete.
Not really a solution, but this is something Samsung has stepped in to fix, within their own product line anyways (it's not like they could force other manufacturers to adopt their fix anyways). Samsung Cloud basically backups all the stuff Google doesn't, from app data, to custom apks, phone settings, etc. But I agree that it should have been fixed long ago and no manufacturer should have felt the need to fix it themselves. 

Also, I've been out of the rooting scene forever, but there is that...Magisk? app or something like that. It hides your root well enough that folks in r/android say they can use Android Pay.
If you read the article, you'd see that when he said "console wars" he was specifically talking about extreme fanboyism.

He specifically praised the competition in the industry and said it made MS stronger as whole if Sony and Nintendo are strong as well. The guy isn't here to say he's against competition, just that extreme fanboys who will always buy from one company and mock/put down everyone else isn't good for the industry as a whole.
Yea, it doesn't seem like anyone actually read the article attached. He was only talking about the extreme fanboyism that can be seen on either side of the aisle. If they read his comments/the article, they'd have seen him say that "he believes that a stronger industry in general--including Sony--is better for Microsoft." and "We don't have to see another company fail for us to succeed. It's not part of the math for running a business."

The article is literally about him praising competition, while saying that extreme fanboyism isn't healthy for the industry. 

And it makes sense, people should buy what they think is the best product for them and not do it out of some blind loyalty to a company. If everyone was the flame war starting type of fanboy, then there'd be no room for growth, companies would have a fixed market/base, and they'd feel no reason to make a better product (cause they know their base will buy their product anyways, and there's nobody else to sell it to). It's just not healthy for the industry at all.
Competition is always good, but I think Phil Spencer is a better Xbox head than his predecessors were; and I think there's a certain level of truth to his words. 

He was never badmouthing competition, but instead was taking aim at the extreme fanboys on either side who start flame wars (which he made the mistake of calling "console wars" and causing so much misinterpretation in this post).
You're absolutely not wrong, but that isn't what he had meant by "console wars".

If you watch the full clip of his interview (or read the article linked above), you see that when he was talking about console wars, he really meant the flame wars type things that happen between the Xbox and PS camp. He specifically referenced the kind of thing that happens on Gamespot's user forums as an example of what he meant. That kind of thing isn't healthy to the industry or competition. If everyone takes up that kind of extreme fanboy mentality, and retreats into their own corners, then companies will have a fixed base (with no room for growth) which will lead to far less competition. 

He also went on to say that he thought Spiderman on the PS looked great and he was glad/enthusiastic that the Switch had such a blockbuster opening because all of this helps keep the industry healthy ("and that he believes that a stronger industry in general--including Sony--is better for Microsoft."). He said a few times that as a former developer, his goal was to see the industry driven forward, and he specifically said "We don't have to see another company fail for us to succeed. It's not part of the math for running a business."

I'm quite inclined to take him at his word, because under his leadership, Xbox seems to be doing much better, and he brought around the Play Anywhere initiative. Whether you want to chalk that up as a purely business move in an attempt to regain the Windows gaming market or not is up to you, but it's good for consumers all the same; and his predecessors didn't think it was worth letting people play on Windows without re-purchasing the game.
It seems like nobody actually watched the clip in which he was talking about 'console wars'. He was specifically talking about flame wars that happen between Xbox and PS fanboys. He specifically referenced the kinds of things that happen on Gamespot's user forums as an example of what he meant by console wars. He doesn't see that as productive, and having people badmouth others for having the audacity to buy a different product isn't healthy for the gaming industry as a whole. If everyone retreats into their own corners with this "screw the other side" mentality, then there's no reason to make better consoles because you know that regardless of how great or terrible your product is, your market size won't change.

He's not against competition, and he's reiterated a few times that as a former developer, he wants to see the industry driven forward and that's why he came out and said that Spiderman on PS looked great and that he's glad the Switch had a fantastic launch. If they do well, then it's good for the industry as a whole and will drive companies forward. Phil Spencer isn't like the previous Xbox heads who only care about snuffing out the competition.
I'll have to check that out. Thanks for the tip.
I'd really love to, but after those Best Buy sales...well my bank account said I can't make any more withdrawals. 

Don't fret though, I have a foolproof plan to make a million bucks and split this listing with you 50/50. I'm going to sell folks an investment which will only pay off if they sell that same investment to 10 other people. It'll create this type of hierarchy, or pyramid if you will, which will have me raking in the dough. 
That's good. When I watched the video there wasn't a single comment on that, and I browsed pretty far into them. It's was mostly jokes about Linus or jokes about storing porn, etc. 

I had actually come here to post this same video and vent about how terrible this setup is, but someone had already posted it and everyone in this post was already saying exactly what I wanted to say. It's kinda nice when things work out like that. 
If you have a specific DNS configured in your router, then your PC will likely default to using that (unless you specify a different DNS server for your PC to use). If you haven't specified a DNS server in either, then it's likely using your ISP as the DNS server.

An easy way to check is to use something like https://ipleak.net/

It'll show you your IP, WebRTC, DNS, and you can check the IP address that ipleak receives from your torrent client too. Click on the IP address (or addresses) you see under DNS, and see if any of those belong to your ISP. If they do, then your DNS server isn't being changed by your VPN.
I don't know about you, but my main issue has always been the exclusivity mentality that some console owners bring to the table.

I mean, I find consoles to be just fine, I own an Xbox One and use it on occasion (sometimes for gaming as well), but I dislike that exclusivity that Xbox, or Sony, or anyone else has when it comes to games. 

I know it's necessary because console sales would tank if there were no exclusives, but it's still real shitty; and I dislike with a passion the console kids who cheer each time a game becomes an exclusive.
I'd hazard a guess that the vast majority of people who use consoles are fine and understand PC's are objectively better in many ways, but they choose consoles for various reasons.

But there's a sizable number who think a 300 dollar console will be vastly superior to a PC 3x the price. PCMR posts examples of it all the time, and it shows up in youtube comments quite often (especially youtube chat in livestreams, which is far worse than the normal comments).
The only time I feel the need to be careful is when I'm getting software of any kind. Most torrents with media aren't as big of a deal to me, because any extra non-media files can be deleted or I just don't download them at all.

With software (which I rarely ever download anyways), I take the extra precaution of running the torrent client in a virtual environment. I used to do a full VM, but given how rarely I need it for this purpose, I found using an entire OS to be overkill (also drain on resources as I usually run VMs for other uses). I stick a portable torrent client into Comodo Firewall's sandbox, download the files and run it against virustotal, compare signatures/hashes, or any other action I want to take. While I do sometimes compress the files and save them to my normal hard drive, for the most part I'll just use that software right inside that virtual environment and never need to take it out.


There's plenty of other applications like that out there like Sandboxie or Bufferzone for Windows, but I needed a decent firewall to monitor my connections anyways, so I figured I'd just use Comodo and kill 2 birds with one stone.


Of course, I take the other standard precautions like using a VPN, virtualizing the browser when browsing anything I don't completely trust, ublock, noscript, etc.
I don't know about you, but unless I specify who my DNS provider is, my computers/tablets/etc default to using my ISP as the DNS provider.

My VPN service takes care of this by changing my DNS provider for as long as I'm using the VPN. If your VPN service doesn't do this, and you only use the VPN strictly to torrent, then it's not a big deal. If you're browsing torrent sites while connected to VPN and the DNS still defaults to your ISP, then that's not really helping you to keep your browsing habits private. 

So if you use your VPN for more than just torrenting, it'll probably be beneficial to change your DNS provider, if your VPN doesn't already.
For a consumer, making something is probably a better route. For a Youtuber, like MKBHD, it's better (and easier) to get a company to give you their product for free.
I was searching all through the youtube comments, expecting at least 1 person to question the move of using 1 parity drive out of 15 of them.

I can always rely on r/datahoarder to have the right reaction to these kinds of things.
Yea. I just googled it and it's a method I've played with in the past, but I never knew there was a name associated with the process (rarjpg). But yea, it's definitely the same basic idea.

In this specific use case (uploading to Amazon), it'll probably be safer to use an application that is resistant to steganalysis, rather than the copy command which is transparent.

Amazon doesn't seem to parse photos for hidden information at the moment (so that method would work), but if folks abuse this service (which I'm sure some will), they'll probably start to implement algorithms to weed out the obvious photos with hidden information. 
I haven't checked in the last 2 months or so, but they weren't doing that before. It's one of the primary reasons that I use Amazon to store all my photos over Google, is that Amazon doesn't compress them for the 'free' tier. 
No, it has to read as a photo. Someone in r/datahoarder has experimented with prepending the file with code that would match something like a .png photo, and they've said that has worked. I don't recall who said that comment, but it was from the "Amazon is ending their unlimited storage" post in r/datahoarder.

Personally, I think it'll be easier if you look into steganography, which is something I used to play with back in the mid 2000's. There's a few apps out there for the different OS's and some are definitely more user friendly than others and some are more secure than others.

Basically, all you need to do is: separate your files with something like 7z into smaller sizes (ideally between 1-5MB pieces, but there might be some leeway on that), then insert them into actual pictures using your steganography application. As long as your photos aren't edited, resized or altered, your data should be intact. To use them: download the photos, run the steganography app to retrieve the files and put them back together with 7z (or winrar/winzip) when you need it.

Don't be obvious about it either. A 3 megapixel jpg/gif shouldn't be 5-10mb in size. And it might be easiest if you split up a large file into many pieces then put all the photos containing pieces of that file into the same folder, so it's easier to download the right photos when you need it.
Yea, it doesn't cover videos. It only covers 5gb of "other" files. So you can have up to 5gb of documents/videos/etc, but that's it. It's only pictures that are free.
As of January 2017, JPR estimated that the enthusiast PC market would continue to have 6% growth year over year; and the gaming market broke the 30 billion dollar mark 2 years ahead of expectations (it was expected to happen in 2018). On top of that, as far as gaming hardware goes, [the PC market is still twice as large as all consoles combined.](http://hexus.net/gaming/news/industry/81424-gaming-hardware-market-worth-67-billion-2014-pcs-dominate/)

Low end PCs might be a dying market, but the gaming PC market only continues to grow. I expect it'll grow faster as people find themselves to be shelling out 500 bucks for new consoles every couple years (it's bound to happen, technology just advances too quick for a 10 year cycle).

Anyways, I'm just reiterating what everyone already knows, the title of that article is just click bait.
They weren't, they paid (or possibly convinced) Twitch to stream their conference live right after the Bethesda conference. So many of the folks watching on Twitch (and some other places), could have gotten impression that it was live at E3.
If you have Amazon Prime then your photo storage is still free, even if it takes up a few TBs.
It might be a good idea to run chkdsk /r after you backup the contents of that drive. It'll check and see if there are more bad sectors and if it's failing it'll probably find a few more. 

It's possible (but less likely) that, if the drive isn't used often or only some parts are used, that the file system took this long to find bad sectors that had accumulated over time. If that's the case then you can probably get some more time out of that harddrive (you should still make regular backups). 

If you do run scans regularly, or HD sentinel runs extended Smart tests regularly, and all of these popped up in the last week then your harddrive is on its last legs. 
Basically, the way bitcoin (and related cryptocurrencies) work is that you need someone to process transactions. Lots of transactions are stuck into a big block which requires a lot of computing power to process (the level of difficulty is increased as necessary to help prevent abuse and keep the system secure). The people who are able to successfully process the block are rewarded with new bitcoins.

The math involved in mining is better served with a lot of cores, rather than a few powerful cores. So GPUs are perfect since they have a lot of cores that are capable of processing that kind of math in a timely manner.

Ethereum is newer than bitcoin and it provides a lot of features that bitcoin doesn't have. I don't really remember the differences, but it's certainly popular enough to cause this spike in mining (and bitcoin/ethereum prices)
Raid 5 is obsolete? That's definitely news to me. Were they saying it's just an old technology or talking about it in regards to UREs?

I wouldn't worry about reading that kind of stuff on google though. I read a long post the other day from some guy who was claiming that RAID 5/6 are so prone to failure that even RAID 0 is a better option, because, in their opinion, a rebuild during RAID 5 or 6 is nearly guaranteed to fail (they pointed to unrecoverable read errors as the reason why a rebuild would fail). They aren't entirely wrong, but they're also working off the assumption that UREs happen like clockwork at every 12TB of data transferred and ignoring how large and how many drives are in the array. If you're sticking 30 6TB drives on RAID 5 or RAID 6, you're drastically reducing your chances of a successful rebuild. If you're putting 6 8TB drives on RAID 6, you'll probably be fine.



Either way, I didn't put much stock in it. UREs do happen, they probably have happened to enough people during rebuilds, but the odds seem fairly low that such a thing would happen during any particular rebuild, so long as you aren't using a huge number of disks with only 1 parity disk. And if that still isn't enough to re-assure you, running regular data scrubbing to find the UREs before they become an issue, is a good idea.
They never would have been able to get away with using ACD for business purposes. 

There's been people in here who have reported having issues with temporary bans for using too much bandwidth. A site like eroshare would use far more per minute than most people here could manage in an hour or more.
Right now, I think the Seagate Backup external drives are the cheapest 8TB archive drives. Honestly Seagate archive drives are the only ones I've seen in the 8TB capacity.

But it also costs the same as the WD Easystore drives that Best Buy is currently having a sale on. (Both are 180)

So you could get Reds for the same price as Archives. 

Unlimited works in theory, but rarely does it play out well in practice (at least when it comes to things like data storage).

The way unlimited plans work is that you need to have a certain number of users before you can start to balance out the costs incurred by heavy users. The problem when it comes to data storage is that the early adopters will almost always be heavy users. So to offset that you need to actually market to normal users and get them to buy into your service (something Amazon didn't really do; and instead it was presented more as a side service). 

Get enough normal users (people who pay for the service, but only use a small amount of data) to offset the heavy users and you have a viable business model. 

I guess in this model, I would have counted as a normal user. I had issues using Amazon, so I never used it for anything more than photos and backups of the games I bought from Humble Bundle/Gog; all adding up to less than 600gb.
I should have figured that stegonography would have already been mentioned. I was writing up comments to tell folks that they should try this since it should work better (in theory) than appending a file to make it look like a photo. But if enough people do it, especially in a sloppy way, I'm sure Amazon will start running some kind of steganalysis program.

Anyways, I've never tried either of those programs, but I did use steghide once (just to show a classmate that I wasn't bullshitting when I said you can hide stuff in photos/other files), and ...whatever Steganos is calling their application these days. 

I used that application quite a bit back when I was a kid, it was a very easy to use and user friendly application back in the Windows 2k days. Don't know how useful the application is now, but it got the job done back then.
If you want it to show up as a legitimate photo, you can always use steganography tools. Best of both worlds. You can hide data in a real photo, and it will appear like a normal photo to everyone who uses it.

But like you said, any attempt to edit that photo could result in the data being lost. 
I know you're joking, but I think most phones coat the lens with oleophobic coating.

Samsung certainly covers the lens and screen with it on the S7. Of course rubbing alcohol and hand sanitizers drastically reduce the lifespan of that coating.
Will do, thanks!
Ok, thanks. I had qbittorrent figured entirely wrong. I never would have realized that behavior wasn't normal and was instead related to my incomplete torrent folder option.

I'll be sure to check out the api for WebUI. Thanks again for the help, I've managed to migrate entirely from utorrent/transmission to qbittorrent on all my OS's.
I [saw these options](http://i.imgur.com/0Hka3Ta.png) and set it up like so. The settings looked pretty straight forward, so I never thought that there might be any restrictions on how download directories could be set up, or anything like that, and that's my own fault for not reading the wiki/documentation prior to using qbittorrent. It wasn't until Xlltt was kind enough to point out that qbittorent doesn't create randomly named folders in the default settings, that I realized this wasn't normal behavior for qbittorrent. Once I turned off the "Keep incomplete torrents in:" setting, it started working normally (no more randomly named folders being created). I never would have figured out that it was related to that one setting, so I probably would have continued to assume that creating randomly named folders for downloads in progress was normal behavior for qbittorrent.

Anyways, all of my issues were definitely user error. I used qbit for the first time a couple months ago, and mistakenly assumed its "Keep incomplete torrents in:" setting would act like other torrent clients that I've used (utorrent, Vuze, Transmission, etc). Setup with those are simple and straightforward: you set up the new client's "incomplete torrent location" setting to point to your 'incomplete' folder; add the .torrent file to the new client; at that point it'll recognize the files are already there, do a recheck and pick up where the old client left off. Since I occasionally boot between linux and Windows, I have Transmission and utorrent set up in this manner so my downloads will finish regardless of which OS I'm using; and I was looking to replace both with qbittorrent. As I said earlier, I couldn't get qbitorrent do that before (because it was creating randomly named folders, instead of recognizing the folders already there), but once I turned off the "incomplete torrents" location setting, it started working normally.

I haven't been using magnet links, and I don't think there's anything wrong with the .torrent files that I've gotten. They seem to work fine in all the clients (qbittorrent included); the only issue was that qbittorrent wasn't allocating the files until it started downloading them.

The reason I wanted to pre-allocate files was entirely related to the issues I had with it putting files into those randomly numbered folders, in my "Incomplete" folder. After qbittorrent created one of those random folders (instead of recognizing that the partially downloaded utorrent folders were there), I copied and pasted the torrent folders (that utorrent created) into the randomly named folder, overwriting qbit's folder. Then I could run a re-check in qbit and it would pick up where utorrent left off.

My thought process was, if qbittorrent pre-allocated all those files, then all those randomly named folders would be generated and I could replace them with the partially completed torrent files. It would be a tedious process, but if I could do that, then at least I'd be done with utorrent and could move away from it.

The problem I was having, was that even though I was using .torrent files, it still wouldn't create those random directories or allocate files until it actually started downloading (which didn't always happen because some of those torrents are waiting for a single seeder to come back online). So, since it would never enter that "downloading" state, it wouldn't create that randomly numbered folder, even though I had asked it to pre-allocate the files.

I know I got a lot wrong when it came to using qbittorrent and a lot of that stems from me assuming it was similar to other clients I already used. Either way, none of this is an issue anymore, since Xlltt was able to help me out and show me where things were getting messed up.

Huh, I just tried it out with default settings and that worked; no random folders. I honestly never would have thought it acted differently between default and using a different folder. That's definitely progress and makes switching so much easier. Is there some setting that I can use to disable the creation of random folders if I want to use the incomplete folder option? If I can't do that, then what's the method you use to easily separate finished torrents from incomplete ones (for example: easily copying all the completed torrents to a folder on my cold storage drive)? I've noticed that I can go into qbit, manually select all the finished torrents, select the "set location" option, then put it into a temporary folder called "finished torrents" and then just copy everything from there to my external drive. Is there an easier/faster method than that?

I haven't been using magents or magnet text files. Since I was trying to migrate from utorrent to qbittorrent, I've just been dropping my archived .torrent files directly into qbittorrent. But this issue isn't really a problem for me anymore since I know where to copy the partially completed files (as opposed to before with the random folders). Now, it'll do a recheck immediately instead of waiting for peers to download from before creating the files.
You've never looked inside the incompleted torrents folder for qbittorrent? Or maybe we're using different versions; I had grabbed the latest version about 2-3 months back. I don't imagine they've changed this setup in the later versions, as it seems to be a core behavior of qbittorrent. 

Anyways, this issue is mostly relevant for when trying to move from utorrent to qbitorrent, but it'd also be convenient if I could turn off the way qbittorrent stores the torrent files, so it'd be easier for me to browse the incompleted files.

With utorrent (and some other torrent clients), it sticks all the incomplete torrent files and folders into a single folder (in my case, it's called "Incomplete"). If you're moving from one utorrent install to another (or to some of the other torrent clients out there) it's easy and all you have to do is point your new torrent client at the folder where you keep your incomplete torrents. Then you add the .torrent files to the client and it'll realize the partially complete torrent files are already there in the "Incomplete" folder at which point it will re-check all of them and then pick up where it was left off. Qbittorrent doesn't work that way.

With qbittorrent, everytime you add a torrent for it to download, it will stick them into a folder with a random 7 character name inside my "Incomplete" folder. I just tested this out again, by starting to download a popular torrent in qbittorrent and it put the torrent contents to a folder named "b13857a". Of course once it's finished, it'll move it to my completed torrents folder ("Finished") but it won't be inside that "b13857a" folder anymore, it'll just be the torrent contents there.

If qbittorrent started allocating the entire torrent and creating the torrent files right after you added the .torrent file, then it wouldn't be as much of a big deal. I could go through the tedious process of figuring out what is in each of those random folders, and then manually copy the torrent contents from the incomplete utorrent folder to the randomly named folder that qbittorrent uses. I tested that process with a couple torrents, and it works just fine as long as you force a recheck in qbitorrent. The problem is, it doesn't show that folder until it actually starts to download the torrent. Which can be problematic since many of the torrents I have lingering in utorrent are old/low availability ones which will finish up when select folks log back in and start seeding (as they randomly seem to do).

If you don't believe me, just find an old torrent with extremely low availability (little to no peers online). Qbittorrent will say "stalled" (which is fine, since it doesn't have anyone to download off of), but it won't create that random folder or the torrent files until it actually starts downloading (utorrent, for contrast, will allocate the space and create the files after you add the .torrent file, even if there are no peers to download from). Once it goes from 'stalled' to 'downloading' then you can right click on the torrent in qbittorrent and go to "open destination folder" and it will show you the incomplete torrent files, but not before that.

Anyways, since it's not really intuitive, there's actually a few tools that folks have developed so you can import torrents from other clients into qbittorrent, but I've never been able to get them to work on my computer. So I'm just using utorrent for the forseeable future, at least until all my old torrents finish up.
Ah ok, thanks for the more thorough explanation. 
I like qbittorrent, but I'm not a fan of how it sticks the files for a torrent into random folders, or how it won't create the folder+files until it starts to download the torrent. That's even if you have it set to pre-allocate disk space.

Until that changes, I'm stuck using utorrent 2.2.1 portable.
Hmm, ok, I'll look into that a bit further then.


Ah ok, I'll try that out with the USB-C to HDMI. Thanks.
So it's kind of like the Calibre or Plex of ROMs?

It says the goal is to help validate software, does it run hashchecks to ensure you've got an untampered with version or something?
True and that'd probably work. I haven't downloaded any of the isos here since I don't need to play with anything other than Windows 10 (and I have SHA1 for that already) and linux for the moment, but I'll also be getting access to MSDN in 2 months or so. So I, myself, don't need anything specific right now.

Maybe if OP of these comments, or anyone else needs access, you can post it directly under the top comment. I imagine the older OS's (XP-7/8) and such shouldn't change much either. But I don't know what files they're grabbing or looking for exactly.
Well, nothing specific, but SHA1 values is what we're trying to figure out how to obtain.

I don't know how a good way to get them are though. Maybe /u/Digmarx has some input on the best way to get them?

Some archive.is type site?
[Internet Download Manager](https://www.internetdownloadmanager.com/)? [It's working for me on this page.](http://i.imgur.com/LJiqPG4.png) It's going through and checking the links to get info on them before it downloads, and the files seem to be enumerating properly.

It is a paid application though with a free trial.

I believe Wget is available on Windows as well. I haven't had a chance to try that yet.
Ahh ok, that makes more sense. 
Yea, it kept linking me there last night and I had given it a shot, but I didn't see anywhere that I could get SHA1 hashes. Maybe I'm just not looking in the right spots. 
Well they're not exactly wrong either, as a lot of people have money riding on the US going green. Even the biggest coal producing states in the US were happy with the Paris Agreement because they were also some of the states who would benefit the most in allowing their current workforce to move to clean energy jobs. 

Coal just isn't effecient enough to compete with solar without government subsidies, so moving their workforce away from coal and into solar was a big part of everyone's plans. As it is, solar already employs more Americans than natural gas, oil and coal combined. 

I really hope that trend continues, because the US pulling out of the Paris agreement is China's wet dream come true. They could end up dominating the worldwide energy market for decades to come, if the US clings to outdated and inefficient energy production methods. We continue to hope to sell the rest of the world our oil and coal but even the dumbest analyst can see that the entire world is moving green (even North Korea has plans to). It's just idiotic strategies all around from this admiration, no matter how you look at it, from an environmental perspective, financial, jobs, economic, energy security, etc. 
Ah ok. That's pretty nice. And this Ebuyer is a UK company too? Cause I've never heard of them until this post. 
I didn't know/remember that, but he didn't need it for that. He was putting it in a custom built laptop which was fully decked out, but back then I think 6-8gb was the general limit for laptops, even in a gaming laptop. 

The worst part of all this was that he used his 360 to game, the laptop ended up as a glorified web browser with a GTX card in it (280M I think). 

Dude was a jerk to a lot of folks (myself included), but I tolerated him at times, just so I could do things like pick up a brand new 512gb Razer Blade 14 (2013) off of him for 500 bucks. He had ordered the Blade, but then decided to pickup a MacBook Air at the Apple store before he even received his Blade.
I'm sure if it were windows 10 he would have bought pro, simply because it is more expensive. 

That sounds like a bit of a pain to set up, but it allows RDP so long as you're on the same LAN? Windows 10 Home doesn't allow that, even if you're on the same LAN as far as I know. 
Not exactly. If there's a page that I know I want to save, I've just used the default "save as" thing in the browser which grabs the html file and any assets it needs to run that specific page offline.

Other than that, I don't have anything set up to cache and archive websites as I visit/use them or anything like that.

Do you have any suggestions in that regard? Cause I can certainly see it being useful to set something like this up on my desktop.
Yea, I never did that cause I didn't think MS would revoke access from the public. I've managed to login for a couple years with just my normal MS account, and it wouldn't let me download stuff, but it always let me view the SHA1 values.

If I knew they planned to revoke that access, then I definitely would have saved the hashes while I still could. I guess it's just poor planning on my part that I never thought to make a backup just in case.
I knew a guy who purchased Windows 7 Ultimate. The only reason he bought it was because it was more expensive than Windows 7 Home Premium (which is what would have come on his system). Dude had far more money than sense, and he'd gladly waste money on something, even if he didn't know what it did, just so he can say he has the best version.

I can't remember if there was anything else on Windows 7 Ultimate other than Bitlocker, but he was the kind of guy who would have a hard time understanding what encryption is, much less make use of it. 
But also OP, cause of that 2 day shipping. 
Huh, I tried accessing MSDN's site just a month or two ago to get SHA1 values, even though I don't have a subscription, but I still managed to log in with my MS account and look at the SHA1 hashes. I couldn't download anything until I signed up for a subscription, but I could at least see the hashes.

Now I can't seem to access that part of the site at all. Kind of a bummer.
I imagine they would work fine if burned to a dvd.

Might be easier to just get a USB drive and and make it bootable on there. There's a few ways to go about that.

If you want just normal Windows, you can download it directly from Microsoft using their download tool (which will also give you the option to download an iso and optionally make a bootable USB).

Otherwise, there's applications like [Rufus](https://rufus.akeo.ie/) which can handle a wide variety of OS's.

Or [Yumi](https://www.pendrivelinux.com/yumi-multiboot-usb-creator/)

Or...well there's lots of them out there. At the moment I use Yumi to stick a bunch of Linux Isos, and various Windows and tools to fix Windows on my USB drive.
I laughed pretty hard at that. Asks for mercy from Linus, gets an IDE. Has his cameraman go cheat and grab him a drive, gets another IDE.

Poor bastard.

Although those drives probably worked fine. He probably didn't have the jumpers set up properly on the IDE drives. I had to work on one of those drives from forever ago, and you need to set the jumpers on master for it to be properly recognized by modern systems. Putting it on slave, having no jumpers in at all, or anything else would cause it to not be recognized by the Windows 10 system I was working on.
Yea, that's what is says in the article. It just seems odd that a year or two ago, I was thinking the definite limit was 7nm, but the folks who wrote the article (that I read back then), or maybe even Intel themselves didn't think to shrink the parts around the transistor, or surround the transistors with the gate. Achieving that, vs just having it as a concept, is something else entirely, of course.
Yea, I'm wondering the same thing. I remember reading something from Intel a while ago about how they didn't think it would be possible to shrink transistors much past what they are at now. The reason they specified was that if it gets too small you have to deal with quantum properties like the one you mentioned. 

I guess I always took that to mean that 7nm would be the smallest we'd see in traditional computers. 
Here I was disabling her via group policy, but denying Windows access to her exe sounds much more satisfying. 
Huh. Didn't know that old My Books were still around or that they made the switch before the new My Books came out.

I thought that was the whole point of trying to sell all the old externals was because they had the Reds in them, whereas the white label is what they want consumers to have.

I guess it's good that Best Buy still has these Easystore drives, even if they are trying to get rid of them.
Yes, before they stopped selling the old My Books, the 8TB versions contained Reds. Easystore are just old My Books, but they're relabeled for Best Buy to sell.

The white label drives didn't show up until the new My Books started rolling out. Before that, the only 8TB consumer drives they had were Purples and Reds, so they put the Reds into external cases.
I dislike her because she keeps trying to get into the spotlight and that only serves to remind independents and republicans why they hate democrats, and as you should know, we don't live in a country where popular support matters; I've been arguing against super delegates and electoral college for a while, but every mainstream democrat I've come across has called me an idiot for thinking those systems didn't work in our best interest

Anyways, I've come to hate politics (and political posts) and won't be involved in the process again after the 2016 primaries when I lost all faith in the only party I had ever supported, so I hope you appreciate that I took the time to write this.

My dad is a longtime (casual) republican and recently a Trump supporter. With every stupid action Trump has been taking, he's been moving away from Trump, and also the entire republican party. Surprisingly enough, he does believe in some really left wing ideas (ideas that democratic politicians would never tolerate, unless in rhetoric only), like universal healthcare and universal education, and it seemed like he was close to moving and staying an independent. He even would have voted for Bernie over his own party because he trusted Bernie's honesty as his rhetoric actually matched his track record. 

But once Hillary started getting attention again as she blamed everything under the sun for her loss with that list a couple days ago, and all of his news sources (from CNN to Fox News) started reporting about her, he snapped right back into team red. He wasn't a fan of Clinton before the election because he felt that she wasn't honest (and I've tried to explain to him that there's no difference between Hillary and the republicans when it comes to honesty; but he wouldn't have it), he was far less of a fan when he felt he was being called a "deplorable" person, or a gullible Russian stooge, so any mention of her is basically reminding him of what he hates about the democratic party. Even with non-republicans; folks who wanted some kind of change because of their wages kept going down, bills keep adding up, and the "economic recovery" under Obama was just a massive number of minimum wage and part-time/temporary jobs being added to the market (which looks good on paper for Obama's unemployment numbers, but at the individual level it's nervewrecking having no job security or good pay); those folks who were interested in Trump, because he was a businessman who was making grandiose promises, also felt they were being called "deplorable" by Hillary. She was shooting herself in the foot in places like Wisconsin (which is usually pretty liberal at the state level), by pushing away all these people who just want to see their wages start to go up again. Also keep in mind, that she didn't think it was necessary for her to come to Wisconsin even once during the general and reassure these people she'd work to help them; something that only drove my father (and many of his colleagues) farther away from her as they felt she didn't think people in Wisconsin mattered. 

When it comes to burning bridges, if you were ever a Bernie supporter you can probably empathize, since her campaign was in full on bridge burning mode during the primaries; and her followers are still like that today and deplore progressives and Bernie supporters; see r neoliberal if you don't believe me. If you're real brave, make a comment praising Bernie in EnoughTrumpSpam and Neoliberal and see how long it takes until your inbox is full of outright hate, as they blame you for the loss, think of you as little more than uneducated teenage idiot, a complete and total sexist (they naturally assume you're a horrible person who hates and degrades women), and belittle any viewpoint you might have, even if those viewpoints are similar to their's.

She lost, and her blaming Obama, the DNC (after the primaries, her blaming the DNC is really the icing on the cake), the Russians, Comey, clickfarms in Africa/Asia, it doesn't matter what made her lose and it's been discussed to death. Russia has been all over the news lately, and anyone with half a brain can see the role Comey played in this election (I don't blame him, he was doing his job when he notified congress of having to re-open the investigation).

I don't think you remember post-election Gore or Kerry. They weren't hated by team blue (then again, maybe they would have been if they ran scorched earth campaigns and had a DNC that was willing to show only them a huge amount of favoritism), but they sure as hell were mocked by everyone else (independents and republicans). Gore with his recount (which I think was a fair move since it's his right to ask for one), and Kerry with his "Bush rigged the election". 

The way you get everyone to hate you is to: burn every bridge you can just for the short term victory, imply that your primary opponent's followers are racist, sexist and violent and come up with clever labels like "Bernie Bros" to further dehumanize them, ensure people like Biden can't enter the race (even if he wanted to) by tapping every one of his fundraising sources dry in the very first moment you hear the rumor that he's considering entering, and most importantly, get the DNC to bend over backwards for you despite there being a huge amount of support for both campaigns. If it wasn't for DWS doing things like leaking info on the Sanders campaign to the press or limiting the number of debates, and Hillary didn't use her right wing attack dogs to smear progressives in every way they possibly could, then I doubt Hillary would get as much hate from both sides. 

Edit: Fixed oddly phrased sentence.
PCIe lanes are basically the pathways that provide data from your PCIe devices (like graphics cards, SSDs, etc) to your CPU. More lanes = more PCIe devices can used, or more data intense devices can be used.

RAID = 2 or more harddrives working together to either improve your speeds (RAID 0), or provide redundancy (RAID 1, 5, 6, etc). In redundant RAID, if you have 2 harddrives in RAID 1, and one of your hard drives dies, then you still have all your data on the other hard drive and that will keep you running until you can replace the bad hard drive.
Given how often this sale keeps coming around, within such a short span from the last sale; it seems like they're trying to sell off their remaining stock of Easystore devices or something. 

I'm not complaining, I'm more than happy to take a few 8TB Red drives at this price.
Yes, the [old 8TB My Books have Reds](https://www.wdc.com/content/dam/wdc/website/products/personal/network_attached_storage/my_book/wd-my-book-external-storage-product-dimensions.png.imgw.1000.1000.jpg). Bestbuy's Easystore is just a relabeled My Book.

The [new 8TB My Books](https://www.wdc.com/content/dam/wdc/website/products/personal/network_attached_storage/my_book_new/my-book-new-dimensions-v2.png.imgw.1000.1000.jpg) have the white label drives that are supposed to be equivalent to the WD Blues.
Nobody is saying they're creating these chips out of thin air, and I'm absolutely not saying they're creating these chips from scratch. The process of going from wafer to die is about 3 months (by Intel's own admission in 2016, + for testing and binning); so given that they started on the wafers long ago, it completely makes sense that they can't release these high core count chips on the same timeline as AMD, but they are coming out later this year or next year.

The process that takes the longest is the creation of the wafer. Luckily, they've been binning i7 Extremes (and chips similar to HEDT) out of Xeons, so we don't have to wait for a whole new piece of silicon to be designed and built. Given the specs on their new processors, it sounds like that's exactly what they're doing right now with their i9 series (from their new HCC Skylake Xeon processors due soon). It wouldn't make sense for them to create an entirely new wafer just for i9 Skylake based chips.

So, if it's business as usual: release a chip with 2 extra cores and charge the same (or higher) price as the last chip (see: 6950x). All HCC silicon can be reserved for business clients who will pay far more for HCC, lower TDP chips even if it comes at the cost of frequency.

If AMD throws a curveball, and Intel needs to bring HCC chips to the consumer market, they're looking at being 3-5 months behind, as opposed to a year (or more if you include designing the silicon).

------------------

But lets assume that I'm totally wrong. The i7's and i9's silicon is nothing like Xeon processors; Intel has never used a wafer to create dies for both Xeon and HEDT processors, and every processor/family that that Intel makes gets its very own wafer (no cross family binning). 

Why did Intel and AMD both wait until 2017 to bring their high core count silicon to the consumer market? More importantly, did they both agree ahead of time, a year or two ago when they started designing and manufacturing the silicon, that 2017 is the year that they'll both decide to make oddly large HCC consumer CPUs that look suspiciously familiar, especially in size, to their server class offerings? Don't get me wrong, I'm glad AMD and Intel both chose this year, but they could have been doing this for many years now, why 2017? Turn off the features of the Xeon class chips (like they've already been doing), and give us access to the HCC chips, even if they come in a bigger form factor. 

Should we just count our blessings that they're both bringing chips with good performance to price ratios for the first time in a while? Either way, if Intel and AMD both came to that conclusion independently, and long enough ago for them to create and fab entirely new products that would arrive in 2017, then I hope the employees, at Intel and AMD, got raises when they proposed that idea.

You know that I think that AMD brought the HCC silicon to consumers, and Intel is following, but if they aren't, then they both must have had 2017-2018 in the books for when they bring their enterprise grade HCC silicon to consumers. 

Edit: Spelling and grammar. Removed repetitive statements.
You can call it "focused" on other things, but in reality it's just that they had no real competition, so they had no reason to improve their desktop line products.

If they didn't have any competition in AI, IoT, VR, etc, then they'd stop improving those products and bring small iterations at the same prices each year; just like they did with their desktop line. They have multiple teams of engineers who work on all of these projects, so there's no reason they can't keep working on all of these things simultaneously. But if they feel that they can make a small change, charge the same price, and still know they'll get the majority of the business out there because there's no competition, why try to make a better product?
Wanna know what pisses me off, and it's something Linus sort of hit on during his video: 

Intel never had any plan to bring their high core count CPUs to market. This was yet another year where they thought they were going to dominate AMD, so they made no effort to bring anything better. They had a tiny increase in core count and they would have kept last year's prices. The 12 core chip would have cost the same as their current 10 core chip (nearly 2k). And that was it.

Then rumors about AMD's Threadripper started dropping and they realized that AMD might bring something better to the table than them. So, at the very last minute, they announce a bunch of high core count chips that didn't exist a couple weeks ago. That's why none of them will be available until the end of this year, or well into next year.

Thank god for AMD bringing some genuine competition.
Gotcha. 
That's what I was doing too, but my ebay account was shut down unfortunately. I have a terrible upload rate, so it had taken me forever to get those up there. My current Gsuite is only for encrypted media.
Yea, Amazon Cloud Drive. There's no transfer costs because it's a consumer product. 60 dollars a year for unlimited storage. I'm not saying it's free for Amazon to transfer stuff outside of their system, just that they won't pass the cost on to you.

There are folks on here who use it all the time and they've never had issues with downloading 10-15TB after they need to restore a backup, there's some who said they've had issues with temporary lockouts (from running an extended slow speed download and such), but they can solve that with help from support. But the thing is, lately applications like rclone and acd_cli have been having issues with ACD. So if you don't expect to be able to use those, then I think you'll be fine.
They retired the Green series and now all the lower end drives are just called Blue, at 7200 and 5400.
It should have about 1-2 years on it still.

The default warranty is 3 years, but they extended that by 1 year for products with those Intel chips in them.
Anyone using Gsuite to store Plex streamable linux isos without encryption?

I'm debating right now, whether I want to set up a Gsuite account for that, or if I should join someone else's gsuite (which could be mutually beneficial, they get an extra user, and I get to use Plex Cloud).
Look, I already I said I don't play the game that way. There are people who do play the game that way. Maybe they're just masochists who want to play modern games without the hud even though that's impossible because the Withcer 3 isn't made the way you guys want it to be made. All I said was that I'm glad the dev's left in the controls so the people who do play the game that way are able to do so, but I don't play it that way.

If you guys really want to yell at people how they should make and or play games, go yell at the people who are making it that way and the ones who are playing it that way. 

Or hell, just don't buy the game if it offends you so much and go find something more to your liking. It sounds like AAA games won't be your thing, because they rarely want to spend 10's of millions on a game only to have it target a niche group, but there's thousands upon thousands of indie games in Steam, so I'm sure you can find something more to your liking there. 

Edit: Frankly, we just have different interests and viewpoints on this. I can't possibly imagine playing a game like Elite Dangerous, Star Citizen, Witcher 3, etc without nav/quest markers. I think size definitely plays a part in that, but maybe there's mods for all the games out there to remove all maps/navs/etc and add in NPCs or whatever works in your opinion.
You're right. I don't recall being asked once to go to the opposite end of the map by any farmer or town/village that was in danger. Actually, many of the side quests are slaying monsters, and those monsters are rather close to where you pick up the quest. Obviously the town that provides the quest and the bounty for it won't care about some monsters on the other side of the map that aren't attacking them; they only care about themselves and their village.

When it comes to annoying fetch quests like that, the Witcher 3 has far fewer than most other games in the genre (I can't think of any specific ones at all, but it's been a while since I played the game). There are still monster slaying quests, which can come closest to being a repetitive and annoying side quest, but I mean...he's a Witcher, that's literally his job. It would be more odd to not have those side quests in the game.

The main quest does get you to explore the world, but it doesn't have you go to every corner of the map, or every abandoned settlement, or cover every nook and cranny in the game. It'd probably be a terribly boring story if it dragged on for that long with so many unneeded stops.
That's kind of how it goes though. I mean, they can't have all the side quests take place within a couple hundred feet of where you currently are. Sending people to other areas on quests is the best way for them to discover and explore that new area, the quests and treasures there as well. 

I don't know if dividing the map into smaller parts is the way to go, because that just sounds like your average non-open world game. We've already had a few decades of smaller maps and loading screens (ie Witcher 2). I'm sure there's smaller indie games who still follow that kind of game play, if you're interested in that kind of thing.

If you stick enough NPCs in the game to replace the quest marker system, then sure, I guess that'll help some folks out, but seeing random NPCs in the middle of nowhere, who are only there to guide you to the nearby nest that you need to destroy would be pretty immersion breaking for me. Maybe there's a mod out there to inject a bunch of NPCs into the game where quest markers normally would have been? Or maybe that's the kind of thing someone could make (I'm not big on the modding scene, so I don't know where someone would ask for a mod)?

And like I said before, I agree that this game is much easier with quest markers on; it's obviously meant to be played with quest markers and the hud, or else the devs wouldn't have bothered to program them in. I was only saying that while you or I can't manage to play the game without the markers/mini-maps/etc, I'm glad the devs kept the option to turn them off for the people out there who prefer to play without them.
Yea, it doesn't matter how many leads the game gives you in a world this large. They could have programmed every NPC to give you directions to your current quest anytime you asked and you'll still spend more time lost than not. When a world gets to be a certain size, the only real way to deal with that is to add a system like quest markers; it's just not practical any other way. But I'd rather have a large, immersive, open world with quest markers, than have to walk back and forth in the same small area, over and over for every quest because there's no where else the quests could take place.

And it's not necessary to do the quests you think will be boring, unless you're a completionist (in which case, there's probably a lot of games you should avoid, starting with Assassins Creed and Skyrim). They're side quests, they usually just pay out in small things, and half the time you know what you're going to get before hand, or if it's the type of side quest that will lead to others.

Modern AAA games aren't designed to be small or slow paced; and spending a couple hours lost with no idea where to go without any NPCs in sight is the definition of slow paced. No matter how great the developers are, they're still going to want to make enough money to keep their company afloat so they can work on the next project. Creating a AAA game that appeals to a specific niche isn't a good way to go about that.

From what you're describing, it sounds like you're looking for something more along the lines of indie games, not AAA titles. Those games will be smaller in scope (less quests, less markers on the maps and smaller maps), with systems, gameplay and objectives that don't track with normal AAA titles (or follow the 'AAA formula'). 
Don't take it up with me, take it up with the folks who play the game that way. Hit up the steam forums, some of the folks on the witcher reddit, or take it up with those folks who do that on youtube.

Personally, I don't play TW3 that way and I prefer to play the newer games with huds, maps and other options the devs give you, because [games today are much more massive](https://i.redd.it/keapxqkvexay.jpg) than games from the early 2000s. Without quest markers and maps, even if all the NPCs in all of The Witcher 3 were programmed to help you out and give you directions, you're still gonna end up lost more often than not. Some people like playing that way, where they just explore new areas, map it out in their head and spend a decent amount of time being lost, and I respect them for it, but it's not for me.

In a game like Gothic 2, the [maps were incredibly small](http://www.worldofgothic.com/images/g2addonkarten/shrine_triptych.jpg) by comparison. If you didn't want to listen to the NPCs, you could have just wandered around and you still would have found the quest area and various objectives. It takes less than 25 minutes to walk from one end of the map to the other. In Witcher 3, it takes 45 minutes to get from one end to the other on horseback, in just Novigrad. We can't just make simple comparisons to old games because those games never had the resources or the scope that modern games have.

But, I am thankful that the developers left these options in for the people who want to play the game that way. I can't do it, and it sounds like you can't either, but I'm glad that those folks can play it the way they want.
Well sure, that's what it says before you sign up for it. Doesn't seem to have stopped people in here from uploading and storing dozens, or more, TBs to their account. I myself have about 2.5TB on it, even though I only have 1 user.

But if you're a stickler for following rules, there's still ACD for 60/year. You might not be able to use Stablebit CloudDrive, rclone, or acd_cli with it, but you can still store a lot on it (see the post about storing a petabyte of porn on ACD).
You can play the 3rd Witcher game like that too and plenty of people do.

They have options to turn off the mini map and hud, filters to clear everything off the main map, and you don't need to use Witcher senses to complete a quest.

But if OP used those settings to change the game to his play style, then he wouldn't be able to make this post to score the "modern games are too easy" karma.
First of all, you can turn off most of the stuff you're complaining about. What you're doing at the moment is the equivalent of putting a shooter on the easiest setting and then complaining that today's games aren't challenging. 

You can turn off the mini map (and the entire hud), you can go without using the Witcher senses in quests (I've done it myself and if you go the right way, the quest will update accordingly), you can disable almost all of the main map with the filters, and you can wander around aimlessly as long as you like. Nobody is forcing you to use these convenience features that you seem to dislike. So I'm not really sure why you're playing with them on and then complaining about it.

Personally, I prefer the Witcher 3 method to Gothic 2. There's games I enjoy and can easily sink thousands of hours into, but given the sheer size of the Witcher 3 game, I'd find methodically covering a map that large to search for side quests to be as entertaining as the flag collecting in Assassins Creed 1 (the exact opposite of entertaining). 

That's what would have to happen in modern games with maps this large though. Just keep in mind, that you're comparing [this](http://www.worldofgothic.com/images/g2addonkarten/shrine_triptych.jpg) to [this](https://i.redd.it/keapxqkvexay.jpg). Reading online, it seems to take 25 minutes to walk from end to end on Gothic 2; so it sounds like you could wander around aimlessly and still find the quest area rather quickly. In the Witcher 3, it takes 45 minutes on horseback, to get from end to end in Novigrad (not including anywhere else). It's not a small map.

Older RPG games had you traverse the same small area 100 times on 100 different quests, going from end to end multiple times to make the quests seem longer than they actually were. With larger maps, you get a more immersive experience since you don't need to put the player through all that. You can find space in the map to designate to that quest, rather than have them travel from one end to the other a couple of times to make the quest seem longer than it should be. But the larger the map, the less likely people could find things on their own, so a good way to compensate is to add quest markers. Doesn't mean you have to use them, but it's there in case people do want them.
What about Gsuite for 10/month.

Then you'd pay 10/month for storage, bandwidth and to download all your data.
Why not both?

I run Stablebit CloudDrive on my NAS.
~~It's only on new devices. It was on the Note 7, and now it's on the S8/+~~

Edit: I stand corrected. It looks like they've started rolling it out to devices running Android 7.0. Their site officially says the S7 and S7 Edge are supported.
If it's like the implementation on the Note 7, it'll grow and take as much as it wants. I think it stops short of taking all the space on the system if you only have X space remaining, but I never tried to store that much in it.
Gotcha, what do you run?
AV Comparatives is one of the more respected outfits when it comes to anti-virus comparisons, and many [companies use their ratings](https://www.avira.com/en/company-awards) to help [sell their products](http://www.avg.com/us-en/awards).

They only do performance tests once or twice a year, so the last test was in October of 2016: http://www.av-comparatives.org/performance-tests/

But they do [monthly "real-world"](http://chart.av-comparatives.org/chart1.php) protection tests. https://www.av-comparatives.org/dynamic-tests/
You should consider running some of those applications or games (if you torrent those) through VirusTotal. There's lots of stuff that Windows Defender will ignore, but some AVs will pick up on (there's also some that some might be false positives). 

If you use Windows Firewall, consider getting an extension application that lets you monitor the connections Windows Firewall allows, blocks, etc in real time and ideally with some easy to filter logging. 

I think a recent version of IDM released on Rarbg is a good example of why extra precaution might be a good idea. 2 days after the torrent was made available online, I checked it and Defender and about 10 others said it was fine, some didn't report back, and only 4 in VirusTotal picked it up and classified it as a trojan (Win32.Generic) or similar. A hour after installing it in a VM there were 6 calls to an IP (196.58.32.30) managed by an ISP, named Fibergrid, in Massachusetts. No idea what was sent (it was over https and therefore encrypted), but it could have been harmless, it could have been reporting the specs on my system (applications, Windows version, open ports, anything else that's exploitable), or it could have sent something else entirely. Had I not checked, I probably would have used this application for a year or two without thinking there might be something off about it.

The retail application, for reference, will only make checks for updates when idle. Any calls it makes will be to an IP, like 169.55.0.224, that's associated with the hostname: internetdownloadmanager.com.

Edit: If the uploader/cracker's goal was to prevent it from checking in with IDM servers, the best option would have been to use a loopback address. 
There's some truth mixed in there, but it doesn't really hold water, in my opinion.

Norton does have a pop up that comes up when your subscription is about to end at 30 days out, 7 days, and on the last day/when your subscription is over (at least that was true a year ago when my parents had Norton). I don't think that's unreasonable though, as many subscription apps/services do this kind of thing. And like every modern AV application, Norton has full screen detection which automatically puts it into silent mode, so that claim is years out of date.

In regards to system performance and comments about the databases, it's completely contradictory to independent testing done by organizations like AV Comparatives, given that it out performs Defender and many others.

I'm not saying Norton, or any 3rd party AV is worth the money, but they aren't as bad as everyone makes them out to be. For the average user, it's probably a step up when it comes to performance and protection.
[The real struggle is when you're in the middle of history class and you have to figure out how to work "And I use linux" into a discussion about ancient Romans.](http://www.reactiongifs.com/r/mth.gif)
Haha, you weren't kidding. Even multiple times in just this post.

I use multiple OS's for school/work, but I never knew that using Linux was something to brag about. I'm so out of touch with what kids think is cool these days...with their OS brags and their fidget spinners.
You aren't wrong about the unnecessary bloat that comes with Norton, ie Identity Safe, performance monitor, etc. An old version of Norton managed to run a Windows defrag operation (not TRIM) on my SSD, which still ticks me off to this day.

Your statements are a bit off when it comes to your other claims though (at least according to respected independent testing; like AV Comparatives). Norton scored much better on performance (day to day tasks and PC Mark 8 were tested, gaming wasn't specifically tested) and better on prevention/detection than Windows Defender. Not many scored worse than Defender when it came to performance, but Defender still does much better than many when it comes to detection rates of known viruses (easily beating out products from Emsisoft, Crowdstrike and Seqrite for example).

Average users would probably benefit significantly from using select 3rd party AVs, whether their goal is eek out every bit of performance on their machine or better protection in day to day activities.

In my case, performance isn't important to me at the moment, I virtualize everything, and I re-image my computers as often as I need to, so I'm fine with Defender.
This is true. A huge factor in the 'lack of flexibility' is cost; which I imagine would be very relevant in government programs that face regular funding cuts. The IT environment can be hostile in the sense that administrators/executives often don't understand the ramifications of not paying for the upgrades needed to secure the working environment (they'll still expect you to do it). Without budget increases it's difficult to run proper assessments of what the risk factors are in order to attach a more tangible dollar figure to the risk; telling them you're saving X per day by mitigating risks is something administrators/executives would better understand. 

It happened to a former boss of mine. At his old job he was asked to secure their networks with no budget increase. They wouldn't budge and expected him to pay for it out of the money that was already allocated to running services, maintaining licences/contracts, hardware repairs, staff, etc. He walked off the job because he refused to be held liable for security problems that he wasn't given the budget to fix.
Same man. I've played with some cryptoware before and some of them do this exact same thing where you'll see CMD flash uber quick. I thought I had something really bad that was laying dormant only to hit me later.

I ran various scans, offline scans, and even reinstalled windows once, only to see it keep coming back. I figured at that point, I was either fine, or I had some NSA grade malware that could survive disk reformats.
Welcome to the club. Feel free to pick up your complimentary data packages from the stickied posts and reddits in the sidebar, and be sure to enjoy all the free space while you still have it. After a period of time that will seem entirely too short, I'm sure you'll start pondering whether it's better to buy bigger disks or a device that can handle more disks. 
I'm sorta in the same situation. I bought my 916+ a couple of months ago and after seeing this I was wondering if I should have waited out longer.

So far, the only confirmed change (other than how it looks and everything) is the processor bump. But it's not much of a bump at all, so I'm not really all that concerned.

Plus, I don't know if you know, or have access to it, but Plex is currently testing out hardware transcoding for various devices, including the DS916+ (the build is available in the plex pass forums). The DS916+ is supposed to handle something like 3-4 1080p x264 transcodes at the same time or 1 4k transcode (and if you use video station, you can get that kind of efficiency), so once Plex roles out hardware transcoding, your system should be able to handle things better.
I'll have to check for updates, but I had used this as a second monitor with my old(er) 2014 laptop and didn't have any issues then. 

That was running Windows 10 and used the HDMI port as well. 
Yea, that's most certainly possible. It would certainly explain why it happens to some and not others. 

Hopefully others can chime in with what monitors they have. I've been looking to get a new one for a while but I'm not going to get one unless I know there won't be a conflict. 

I'm not at my computer, but I'll add my monitor into the OP when I figure it out. 
I haven't seen any of his videos yet. I basically just saw a pic of the DS918+ earlier today, googled "Computex ds918+", saw this page, scrolled down to see the specs listed and that's all the info I needed from that page. I still haven't read the entire page but I didn't think it would have anything important that the specs wouldn't have (although it seems they might have taken some liberties with those specs). The original source did have useful info on other Synology platforms though, so I did give that one a read through. 

Every other link I clicked on before reaching this page only said that the DS918+ existed and had a picture of the lady showing it off. With just a picture and a name, I didn't think it was worth mentioning, much less making a post about it. 

I guess next time I'll give the page a read through and watch the videos before posting. 
I haven't tried it personally, but it sounds like it happens to others as well. And I know it's a driver issue because it didn't happen when I used the generic MS driver, and it doesn't happen on Ubuntu, or during the bios. It's only happens on Windows 10 after the Intel drivers are installed.

But I haven't seen posts about this in a while, so I was hoping maybe someone figured it out, cause it happens to some folks and not others, but it also seems to be a software issue.

https://www.reddit.com/r/intelnuc/comments/69dqxu/nuc7i3_screen_flickers_occasionally/

https://www.reddit.com/r/intelnuc/comments/69b86h/nuc7i5bnk_black_screen_flickering_4k_60hz_with/

https://www.reddit.com/r/intelnuc/comments/69tzn7/any_updates_stories_about_screen_flickering_how/

Edit: Didn't see how poorly written those sentance were until now. 
Huh, I didn't know that span.com was looked upon unfavorably. Then again, I've never really read anything from them before either. I didn't know what their original source was so I figured it was just information that was revealed at Computex and would later show up on Synology's website, but the original source definitely has more info on Synology's products.

Anyways, this was one of the only sites I came across during my quick googling that offered anything more than a picture and the name of the new NAS's (DS718+ and DS918+), so I figured I'd share it.
Just be aware, the 320 dollar one is for 8TB total across 2 drives (so it has two 4TB drives). 

The one I was talking about earlier (16tb for 390) has 2 8TB drives, which retails for 499 on Amazon and other sites. 

If you don't need the 16TB version, then the 8TB My Book Duo will also be cheaper on the student store because normal retail sites follow the MSRP, but WD's student discount is usually around 20% off the price of MSRP (sometimes more). 
Ah ok. My uncle had a first gen iPhone, but, despite being a huge music guy, I never remembered him using headphones with it (which he did constantly with his iPhone 3g), so I guess I assumed it didn't have one. 
No reason at all. When you have the option, I'd recommend the Duo everytime; for the price savings, super easy shucking (it's made to be user serviceable so it has easy to remove drives), and the fact that those still come with 2 Reds. 

If you aren't aware of this already, the WD online store has a huge discount for students (you need a .edu email address, or borrow a friend's). They aren't in stock often because they sell out quick when they are in stock, but you can get the 16TB My Book Duo for about $390 with a student discount. 

Sign up for the mailing list, and check in to the store once or twice a week and you might rack up some major savings. Getting the internal 8TB red drives costs a bit more (210 per drive), but it's still cheaper than everything else out there and it's in stock more often. 
Yea, I had to take one of those apart for the 6TB Blue drive inside. I must have had to use as least 3-4 hotel cards to get it to open. 

I almost (unintentionally) managed to open it up without breaking a single tab. The older my books/easystore are much easier. I took one of those apart the other day in about 3 minutes. 
I can tolerate the headphone jack being killed off but not for a while still. 

If they can perfect some sort of standardized NFC type replacement for Bluetooth (specifically the power transfer aspect), I'll be much more open to the idea. As it stands, the last thing I want is to have yet another device that needs to be charged semi-regularly.

Of course, it goes without saying that the audio should be at least comparable to the wired headphones we have now (not perfect, but should be mostly indistinguishable to the average person).
The first iPhone didn't have one either. It was the iPhone 3g (the 2nd iPhone) that introduced using a standard 3.5mm jack in smartphones. Before that, many smartphones (including the HTC Tilt2 that I had, which played Wolf3D and Doom amazingly) and other non-smart phones had headphone capabilities, but they all used non-standard ports and dongles.

At least, I'm not aware of any phones that used a full sized 3.5mm headphone jack before the 3g.
I'm a big fan of no bezels, but the only good implementation of a full edge to edge screen would be if they could put the front facing camera below the screen and have the screen turn transparent as necessary.

If they do this, and put the camera in the corner, then that works, because you still get the full screen real estate for watching movies, but you can still use the camera as needed by turning off a small portion of the top right corner of your screen.

Short of that scenario becoming a reality, the screen shouldn't wrap around the hardware. Even if it's minimal, with every video I watch, I'll be wondering what I'm missing under that tiny part that is blocked (which is likely nothing, but I'd still wonder).
Even if that's legit, it's still seems less intrusive than what the essential phone has going on. If I wanted to watch a video on that iPhone render but didn't want any of it to be cut off, there's just a tiny sliver at the top that would be black.

With the Essential phone, that sliver is much larger and it's larger only to cover a single front facing camera.
Then you must have had one of the newer My Books (the ones with an external case that looks like the one in OP's pic).
Looks like Amazon has the same price as well:

https://smile.amazon.com/Book-Desktop-External-Drive-WDBBGB0080HBK-NESN/dp/B01LQQHLGC/
I took one of these apart a while ago, and it was a Blue. 

I think only the old 8TB My Books come with Reds. Anything smaller and it's a Blue.
Since you had plenty of free space, and don't use deep sleep, it sounds like it could be a failed update? Or it could be something else. When I googled "synology disk space is full" those 3 were the top hits and seemed to be the most common answers/solutions.

I'm not really sure which route will work, but I'd still recommend calling/emailing Synology support to get their input on what to try.

Hopefully putting them in while the system while it's running will cause DSM to recognize it as a volume. All of the disks together should equal a degraded state SHR volume. But if you put them in one at a time, it'll look like random information (even if you put in 6 of them), so up until disk 7 it'll see them all as individual disks. After inserting all 7, I don't know if it'll see it as an SHR volume or as 7 individual disks; you'll have to let me know if you try it out.

Either way, I'm inclined to say it's ok to test putting them in when your system is booted up on the new 6TB drive. As far as I know, DSM makes no changes to the disks until you choose to do something with them from the control panel. I had put an NTFS formatted disk into my DS916+, but then took it out a minute later to copy some files I had missed before. That seemed to work ok.


Hmm, if you log into your router, can you see if it's given an IP at all?

If that's not working, then maybe you'd be able to connect a computer to it directly with a crossover cable and see if you can ssh in?
That sounds like it could work in theory, but there might be some conflicts that arise from this. For example, if both of your disk groups are labeled volume 1 and they both have DSM on it, I don't know how DSM would handle that kind of thing during boot. I'm sure you can relabel the volumes after it's booted, but I'm wondering if having 2 versions of DSM would mess it up. I don't really know enough about how DSM works to say whether this would be an issue or not so I'd probably contact Synology support before trying something like this. *

Reading online, some folks seemed to encounter this issue back in recent years (some of them were from a while ago, so those causes might not be relevant anymore). 

[Was the diskspace on your system actually full](https://sindicatoesp.wordpress.com/2014/11/20/synology-cannot-login-to-the-system-because-the-disk-space-is-full/)? Did you have [DSM set to auto-update, or did this happen after you tried to update manually](http://www.drbig.co.uk/blog/2016/05/synology-cannot-login-to-the-system-because-the-disk-space-is-full/)? And do you [let your device enter deep sleep mode](https://forum.synology.com/enu/viewtopic.php?t=77121)?

It seems most people are still able to ssh into their unit, some of the folks from DSM 4 say it happened because their /tmp/ folder was full from issues related to deep sleep mode and the sleep file growing to an unreasonable size; some of them seem to say it's from a failed update, and one of them suggested sshing in and deleting files until you have enough space to log in.


If all else fails, you should be able to access your data via a linux machine (I imagine you'd need to hook up all 8 drives to it though).

https://www.synology.com/en-us/knowledgebase/DSM/tutorial/Storage/How_can_I_recover_data_from_my_DiskStation_using_a_PC

If necessary, you could probably delete files via this route and see if you can put it back in after that.

*Edit: Not to mention, if it works, you'd only be able to operate your 7 disks in a degraded state. So the setup you're proposing would only be good if you wanted to use your new 6TB drive (with DSM on it) to delete some files from the 7 disk group, and then remove the new 6TB drive and try to boot from the 7 disks, and if that works, then add any (reformatted) 6TB drive to repair the RAID.
[How to reset your NAS.](https://www.synology.com/en-us/knowledgebase/DSM/tutorial/General/How_to_reset_your_Synology_NAS)

[Link to Synology Assistant if you want to use that.](https://www.synology.com/en-us/support/download/DS1815+) I haven't used Synology Assistant before, so I'm not really sure how useful it would be in this situation.
I believe most apps and users have access to the root (not sure if it's read only or not for low level apps/users), but the File Station app itself won't let you access root. 

If you want to browse the root, using ssh to connect to your NAS and browsing via terminal might be one of the better options. If there's any app files you need to modify/change, this is how I would do that.

You can manually update it, and Plex makes it one step easier by downloading the Synology version of the Plex app directly to your PC when you click on "update" in the Plex settings.

A good alternative would be to run it via Docker, which is what I do for every app that I can. I think it makes life a lot easier, especially since you can make Plex install to any folder you like (so you can access all of Plex's files without needing root). Which is nice when you want to make a manual backup of your Plex server files, or if you want to easily install things like 3rd party plugins or [the unsupported App Store](https://forums.plex.tv/discussion/202282/unsupported-appstore-v2-as-in-totally-unsupported) into Plex.
https://github.com/ncw/rclone/issues/1417

https://forum.rclone.org/t/acd-ban-alternatives-discussion-error-http-code-429/1792/286

https://forum.rclone.org/t/warning-acd-cli-is-exposing-your-files-to-others/2194/3



Seems like it had to do with the fact that their tokens weren't being properly obfuscated, or something like that. Either way, it seems that Amazon revoked their tokens and then stopped accepting new developers, meaning these folks couldn't fix their apps.

I'm not really up to date on the situation, and I don't use either acd_cli or rclone, so I have no idea if these issues were resolved or not. I just know there were a lot of posts in /r/DataHoarder last week about people trying to figure out the best ways to move from Amazon to Google because of the rclone issues.
As /u/Hammer_the_Screw said, always have backups, and that's a good rule to follow no matter what sized hdd you have.
I thought this might be useful for folks who maxed out on their BestBuy orders, or since the sale seems to be over (at least that's what I see).

Keep in mind, all the new 8TB WD My Books come with white label drives, not Red like the old My Books (or the relabeled WD Easystore).
I'm not really sure what's happening here, but I feel like we're talking about entirely different things. I don't know how you can say that MAC addresses don't matter, especially considering my entire comment, hell, this entire post (given that it's about LAN and Plex) is about the LAN level; not hops between multiple networks, which happens later. But I guess I'll try to explain what I wrote in a different way and include links on the concepts I'm talking about.

How does user data get transmitted over a physical medium? It has to travel down the [OSI model](http://www.escotal.com/Images/Network%20parts/osi.gif) by a process called [encapsulation](http://www.firewall.cx/images/stories/osi-encap-decap-1.gif), because you can't stick high level user data directly onto a physical medium, right? This means that user data --> segments --> packets and all of that is eventually encapsulated into frames (layer 2). Frames are what ensures the packet reaches its destination WITHIN the local network (if it's intended for another physical network, the old data link layer (aka frame) is discarded once it reaches the router and a new one is applied once it enters another physical network). [See Network layer interaction with the Data Link layer.](http://www.ciscopress.com/articles/article.asp?p=101151&seqNum=2)

This travel through the local network is possible because the [frame has a header](https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Ethernet_Type_II_Frame_format.svg/700px-Ethernet_Type_II_Frame_format.svg.png) which contains the destination and source MAC addresses, and this is assisted by the fact that devices on the network have an [ARP table](http://searchnetworking.techtarget.com/definition/Address-Resolution-Protocol-ARP) and can properly forward the frame to the correct destination (WITHIN the local network). Running an ARP table request (arp on linux, or arp -a in Windows) on the device connected to the VPN, will show you the hosts on both subnets; which means you can see the VPN provider's device that receives the frames from your TAP interface. Don't take my word for it, connect to your VPN and run a traceroute. You'll see the very first device will be the gateway address on your VPN's subnet (well, it'd have to be, or else your VPN wouldn't be working at all).

So can you see how it would be advantageous to emulate a layer 2 device which can [write and read](https://openvpn.net/tuntap) all frames received by the physical layer 2 device? Any packet bound for an external network will be [captured and handled by the TAP driver](https://books.google.com/books?id=hKXEz92wtlMC&pg=PA32&lpg=PA32&dq=tap+vpn+interface+frames&source=bl&ots=av0eYzsH3D&sig=oo0_YbVUuVcJ5q2nmI4WpXEHhE0&hl=en&sa=X&ved=0ahUKEwispIy0m5LUAhVMxYMKHV8FBUE4ChDoAQhNMAo#v=onepage&q=tap%20vpn%20interface%20frames&f=false), written to a frame that is designated to travel within the subnet that connects your TAP virtual interface to the VPN's network. Any packet that isn't bound for an external network can be processed normally and put into a frame that is bound for the local network (or the home subnet); unmodified by the TAP driver.
You could force Plex to work over one interface or another, and it's not a bad idea if you're unsure or have doubts about what interface it's using. 

I guess I haven't seen any set ups like the one you mention in a while, at least not on desktop OS's by commercial VPNs. As I understand it, a lot of the major VPN providers (at least NordVPN, PIA, and PureVPN) are using the TAP interface on PCs, which makes life easier by allowing the virtual interface to create, capture and parse the headers in the frames it receives/sends (because it's a layer 2 device which handles frames, unlike TUN which is layer 3). This means, keeping local and external networks separate should be easier to achieve without manual intervention (like firewall rules). 

Any frames populated with headers that contain MAC addresses of local devices (or of the physical network interface) will be ignored by the TAP interface; meaning those frames will be handled by the physical device and routed normally onto the local network. All externally bound, and received, frames will be handled by the TAP interface, and would therefore be routed towards the TAP's subnet (because the header would point to the MAC of the VPN provider's device which is only available on the TAP's subnet).

Edit: Just talking about destination MAC addresses, not the source. And since OP can see and interact with this local network, it's likely he has the setup described above. 
I'm not sure I understand what you're trying to say in regards to firewalls and the streams going over the internet.

Even if OP had no firewalls at all (ignoring the obvious security implications), the VPN network and his home network are on different subnets (unless OP is using an obscure VPN provider who uses server side bridges for some reason; but then they wouldn't be able to see their home network). Plex, by default, will only route streams to the subnets that it's connected to and it even says this in the Plex Server network settings. In OP's case, the Plex Server is connected to 2 subnets, the VPN's network and OP's home LAN. Given the way that Plex's broadcasting/network discovery works (GDM), it can't route any streams onto a subnet that has no devices on it. This means it can't send streams to the VPN's network, nor can it send streams to the internet as if it's a local network, because the internet doesn't work that way. Only subnets with devices that actively broadcast will be acknowledged by the Plex Server; so OP's home LAN, with their roku device, is the only subnet that can receive streams from the Plex server.


If you're saying that OP can force Plex to only use the subnet of their choice by adjusting the rules in their firewall, you're totally right. But the lack of firewalls or lack of proper rules in a firewall doesn't mean Plex streams will be routed outside the subnet that it's on, much less onto the general internet or to the VPN.
You're absolutely right about Plex not going outside the home network. Plex accesses external networks for only a few reasons, and Remote Access is probably the only one that OP cares about.

Otherwise, Plex will only deliver streams to devices on its own subnet. In OP's case that's the VPN network and OP's home LAN. Since the VPN network has no devices or clients on it, the only real option for Plex to stream to is OP's home network.

No streaming data leaves OP's local network. 
**Tl;dr:** If you're using a commercial VPN provider, like Private Internet Access, then you don't really have anything to worry about, especially if keep "Remote Access" turned off in Plex. If you're using a work or home VPN (and if they record your internet history, and/or have more open ports), then things are a little different, but you should be fine for the most part as long as you turn off "Remote Access", "auto check for updates", and uncheck every metadata agent.

If you want a more thorough explanation, you can read on below.

**Access to LAN and VPN networks at the same time:**

Being able to access your local network and VPN at the same time is normal on many VPN technologies. OpenVPN (which is probably what is used by your commercial VPN provider), works in routing mode and bridged, and on Windows devices (for example), it defaults to routing mode and sets up a virtual network interface. Windows will still see your home network and devices via your normal network interface, while the virtual network interface is seen as having the only working internet connection (meaning all your internet traffic gets routed through it, instead of your home network). Which gives you the best of both worlds; LAN access and an encrypted VPN tunnel to external networks. 

Some business VPN clients work in bridged mode, which would put your Plex server on the VPN server's subnet, instead of keeping them both separate. Given your request, this isn't what you want and should be avoided.

**When Plex connects to external networks:**

Not including Plex extras (like channels/plugins, etc), there's only a few reasons that the Plex app would access an external network (internet). To check for updates, get movie/tv information, and if you enable "Remote Access". If you're connected to a commercial VPN provider, it's likely they will block most non-standard ports, meaning Remote Access will not work (some providers will open ports for you after you contact their support staff). Either way, I don't think any of these things are worth worrying about, unless you're using a work or home VPN. If you're using a work VPN, it might be inappropriate to have a Plex update server, or TheTVDB or things like that on your internet history.

**Concerns about data leakage between networks:**

Your VPN network and your local home network aren't on the same subnet, which means you don't have anything to worry about when it comes to accidental data leakage regarding your Plex library, what you're streaming or anything like that. Plex uses GDM (Plex's custom broadcast protocol) as it's broadcast method, which means it's the client (your roku) who asks your home network if there's a Plex server on it. If there is a Plex server on the same network as the roku, the server will respond. Anything your stream to your roku will stay on the subnet that has both your server and rokue on it (your home network). The server itself doesn't send out any kind of broadcast in this sense, so if your server is connected to VPN, you have nothing to worry about in that regard.

**How to further lock down your server if you still have concerns:**

If you're connected to a workplace VPN, and they use devices with Plex apps at your job (for some reason), then there's a good chance that they'll see your Plex server (since technically your server is connected to 2 LANs at the same time; your home and your work intranet). In this case, [there's a setting within Plex](http://i.imgur.com/h2aLsOn.jpg) itself to let you specify which network Plex treats as the local network, and then it will consider all other networks to be external networks. After you fill that out, disable automatic updates, uncheck every metadata agent, and make sure Remote Access is turned off and you should be golden to use your work network and stream with Plex to your home network. 

And as always, you can use your firewall to limit Plex, and all the ports associated with it. You can make it only use a certain interface, or only allow it to access local networks, or trusted/private networks. There's a wide variety of ways to do this depending on what OS you have and what firewall you're using. 
Sure, here's something I wrote up earlier, I just copied and pasted, it's a bit wordy/long and might cover stuff you already know. The parts you need to copy and paste are in 

    code

So it should be easy to find.

-------------------------------------------------------

Any line with a hashtag in front of it will be ignored by youtube-dl. I wrote up some comments, so it's easier to keep track of what each command does, in case you want [to modify the config file later on](https://github.com/rg3/youtube-dl/blob/master/README.md#readme). You can copy everything in the coded area, comments + commands into the text file.

The easiest way to do all this, would be to download youtube-dl and put it in a folder on your storage HDD drive. Inside that folder, next to the youtube-dl.exe file, put in [ffmpeg.exe](http://ffmpeg.zeranoe.com/builds/) and the config files and your lists for your channels/playlists. The reason you need ffmpeg.exe is because Youtube separates the video and audio files for high res videos (anything higher than 720p), so youtube-dl has to download them separately and put them back together into one file (which requires ffmpeg.exe). 

For some reason I can't get it to work if I put channels and playlists in the same list, so I put users/channels in "channels.txt" and playlists in "playlists.txt". For ease of use, I have 2 config files, the only differences are that one points to channels.txt and the other points to playlists.txt and it saves videos in different folders (Channels and Playlists respectively). I just call them "configuser.txt" and "configplaylist.txt". This way I can just run the config file of my choice without having to modify it each time I need to run it.

Once your config files and lists are set up, you need to open CMD, navigate to the folder where youtube-dl is stored using CMD, and then run the command 

    youtube-dl.exe --config-location configplaylist.txt

Just replace "configplaylist.txt" with "configuser.txt" if you want to download channels/users instead. I've added my settings for both config files below. You can copy it directly to a txt file and it should work as soon as you make a "playlists.txt" and/or a "channels.txt" files. All videos are saved into a new folder called Videos in the same directory as the youtube-dl.exe file. 

Some of those youtube channels and playlists out there are huge, so if at any time you want to stop youtube-dl, the CMD command to stop something is Ctrl+C. So press that once or twice and youtube-dl will stop and it'll pick up where it left off the next time you run it. To run it again in the future, you just need to use CMD, navigate to the folder with youtube-dl and run the command above.

Here's my configplaylist.txt

---------------------------------------

    #Keep track of what has been downloaded. The next time youtube-dl runs, it'll only download new videos that you don't have yet.
    --download-archive downloadedplaylist.txt
    
    #Ignore errors for videos that can't be downloaded.
    -i
    
    #This saves videos to (example): "Videos\Playlists\(name of the playlist)\20170527 - Video Name Goes here - (300s) [1920x1080].mp4. Filename includes date, name of video, duration, and resolution. 
    -o "Videos\Playlists\%(playlist_title)s/%(upload_date)s - %(title)s - (%(duration)ss) [%(resolution)s].%(ext)s"
    
    #Gets the best quality video by downloading video and audio separately and then putting them back together with ffmpeg.exe.
    -f bestvideo[ext=mp4]+bestaudio/best
    
    #Downloads all the playlists listed 1 per line in the given filename
    --batch-file=playlists.txt
    
    #Don't overwrite older videos with the same names
    --no-overwrites
    
    # Write video description to a .description file (can be opened and read in a text editor, like notepad)
    --write-description
    
    #Get a thumbnail image of the video and save it next to the video file
    --write-thumbnail

Once you put the above into a text file and call it something like "configplaylist.txt", then you just need to make your playlists.txt file.

Place your playlist links into the text file, one link per line. It has to be a link to the playlist itself, not a video in the playlist.

So your playlists.txt file should look something like: 

    https://www.youtube.com/playlist?list=PL55713C70BA91BD6E
    https://www.youtube.com/playlist?list=PLMC9KNkIncKtPzgY-5rmhvj7fax8fdxoj
    https://www.youtube.com/playlist?list=PLvFYFNbi-IBFeP5ALr50hoOmKiYRMvzUq
    
---------------------------------------------------

Below is my configuser.txt file:

-------------------------------------

    #Keep track of what has been downloaded. The next time youtube-dl runs, it'll only download new videos that you don't have yet.
    --download-archive downloadedchannels.txt
        
    #Ignore errors for videos that can't be downloaded.
    -i
        
    #This saves videos to (example): "Videos\Channels\(name of user or channel)\20170527 - Video Name Goes here - (300s) [1920x1080].mp4. Filename includes date, name of video, duration, and resolution. 
    -o "Videos\Channels\%(uploader)s/%(upload_date)s - %(title)s - (%(duration)ss) [%(resolution)s].%(ext)s"
        
    #Gets the best quality video by downloading video and audio separately and then putting them back together with ffmpeg.exe.
    -f bestvideo[ext=mp4]+bestaudio/best
        
    #Downloads all the users/channels listed 1 per line in the given filename
    --batch-file=channels.txt
        
    #Don't overwrite older videos with the same names
    --no-overwrites
        
    # Write video description to a .description file
    --write-description
        
    #Get a thumbnail image of the video and save it next to the video file
    --write-thumbnail


The channels.txt file is a little different. You add users and channels to it in different ways. Users use "ytuser:UserNameHere" and channels use the full link. You can get their username from the link to their page: https://www.youtube.com/user/h3h3Productions = ytuser:h3h3Productions. 

Here's an example of what your channels.txt file should look like:

    ytuser:TheGreatWar
    ytuser:h3h3Productions
    https://www.youtube.com/channel/UC0vBXGSyV14uvJ4hECDOl0Q
    https://www.youtube.com/channel/UCXuqSBlHAE6Xw-yeJA0Tunw
    

Sure, yea, that would work just fine. It's mostly just about seeing how long it takes you to fill up that drive. If you're downloading 20, 2 minute long, youtube videos at 4k per day, that means you're going to use about 2gb of space per day. So you probably won't need to ugprade for a while. 

But if you're downloading a new 1080p bluray quality movie every day, then you're going to run out of space more quickly since those can come in at anywhere 4-20gb each. 

Once you know how long it takes to fill up your drive, you can get a better idea of what you should buy next. If you use up space fast enough, it might be useful to consider getting a 2-5 hdd bay NAS or a USB drive bay so you can put multiple hard drives in it.
Start out with an external drive or something like that, maybe 4-6TB, and as you fill up your hard drive, you'll get a better idea of how much space you need and how long it'll take you to fill that up. If you know that, or once you do know that, you can start looking at bigger solutions.



As for downloading youtube videos, I recommend using youtube-dl. It's great for ripping entire playlists or channels, but if you just want one video at a time, it can handle that too. 

It's a command line application, but it's pretty easy to use when you set it up with a config file. I have it set up, so that the only thing I need to type in cmd to get it running is "youtube-dl --config-location config.txt". From there, it handles everything until it finishes downloading, or until I stop it.

Config.txt holds information on where to save the videos, what kind of quality I want (I have it set to select the best possible quality) and it points to another text file, "channel_list.txt", which contains information on what I want it to download. Anytime I find a new channel I like, I just copy and paste the URL into my "channel_list.txt" file.


If command line isn't your thing, I can share the code from my config.txt file to help you get started. If you're fine with the settings I use, then you only need to copy and paste my settings into a txt file, and then save that file in the same directory as wherever you downloaded youtube-dl. 
Interesting. I just received my shipment from Best Buy the other day, and it came with more air pillows/cushions than I know what to do with. 

I keep the all the boxes and air cushions just in case I need to return stuff, but it was packaged pretty well. I couldn't get the HDD boxes and the air cushions back inside, so I ended up throwing a few out.

Edit: It was packaged just as well when I ordered from them back in April.
Friend's or relative's place is the most common answer/option.
Definitely. Doubling up and unwanted extras (with things like Norton Identity Safe), it not doing your system any favors.
This can be true, but it should be noted that [Defender didn't score well in AV-C's performance test](http://chart.av-comparatives.org/chart1.php). The test was done back in October of 2016 so it's likely things have changed since then, they only tested basic day to day stuff (ie PCMark 8 Pro and copying files/launching apps, etc), and didn't test performance impacts on things like gaming.

The difference in performance isn't enough to get me to switch to something other than Defender, but for those who are always tweaking their system to eek out that tiny extra bit of performance, it might be worth consideration and testing out different anti-virus programs on their own.
I think the only way to come close to that is you manually turn on/off your firewall, or you have it set to run on a schedule.

Either way, it's a bad idea.
No, there's a disk in there. It's a normal external hard drive, but instead of keeping it that way, OP opened it up so he could take the hard drive out.
I know this is just an advertisement, but you realize you're trying to sell intel nucs to people who already have intel nucs, right?
Just curious, but have you received any warnings or anything about sharing being disabled? 
You're definitely right. Finding r/datahoarder was a very happy accident on my part and a side affect of my data hoarding habits, as I was trying to find better ways to manage my ever decreasing lack of space on my hard drives/Drobo/etc.

If I wasn't into datahoarding, I can see myself finding this reddit and thinking some of the stuff people do on here is pretty cool, but I can't see myself doing anything more than buying a few external hard drives to start out with. Certainly not anything like building my own NAS.
You covered a pretty big range with your questions. A lot of these questions can be more easily answered if we know what your primary use for your NAS/computer is; especially when it comes to recommending hardware and software setups. Do you just want it to act like a huge hard drive that's on your network? Are you planning to use it to stream media to devices around your house? Is running virtual OSs something that's important to you (if you don't know, then the answer is probably going to be no). Do you prefer to work with Windows/Linux/don't care? 

If you want a bit of a better idea of what a NAS can do/be, then check out what some of the pre-built NAS machines out there. For example, I have the [Synology DS916+](https://www.synology.com/en-us/products/DS916+). It's more expensive (550 dollars when I bought it), but it is a fully built system (only without the hard drives), and their OS is pretty easy to use, it has an appstore, it handles RAID and filesystem formatting in a very easy to use manner (I'd recommend btrfs over ZFS for your filesystem, and I use [Synology Hybrid RAID (SHR) as my raid type](https://www.synology.com/en-us/support/RAID_calculator)), and it has help files on just about every aspect of their OS and the apps they make. But, power users can get a lot done with it as well, like running virtual OSs, or using applications like Docker. 

I use my NAS with [Plex](https://www.plex.tv/) which organizes my media library and makes it easy to stream my movies and tv shows to all sorts of other devices, from ipads, to smart TVs, to laptops and PCs. It's a much much better experience than browsing through folders to find the show you want to watch. I also run a virtual OS on it (Windows 10) because, sometimes there's apps that I need to use and they're only on Windows (like Stablebit CloudDrive). Since my DS916 is on 24/7 anyways, and I only need to run one or two apps, I prefer to run it as a virtual OS on my NAS rather than keep another computer on 24/7 also.

**Cases**

The only real difference I see between the first and second case is that the first is your basic computer tower case but with more drive bays than the normal computer case. If I was leaning towards building a more powerful PC/server (like for virtualization purposes), I'd definitely want to get this case since I can put full sized motherboards and maybe a graphics card in it.

The second is designed entirely around the idea of acting as a NAS (networked attached storage). The idea of a NAS is to be a device that is on 24/7, is attached to your network (via Ethernet or wireless), can be used as a giant hard drive, and can do other things like stream media. NAS's are built to be less powerful in order to consume less electricity, and hard drives are a big focus (it's meant to be storage after all), so if it has easy to access hard drives, that's a definite bonus. The device you linked has 8 easy to swap drive bays on the front; which will be rather convenient when you need to upgrade your hard drives, expand and add new drives, or when you need to replace a bad drive. You can do all of that without having to open up your PC every time, which is what you'd need to do with a normal case. It also has LED indicators for each HDD so you can monitor them and see what is in use. 


**Processor**

The processor you pointed out, is a server grade processor. Server grade processors generally have more cores which makes them better at things like transcoding videos (basically converting a video on the fly), and other things like virtualization. Transcoding is something that might be necessary if you're using an application like Plex, and you're trying to stream a movie/tv show onto a device that can't play it natively. For example, my Smart TV is a champ, and it can play just about everything I can throw at it, but my Xbox One has more issues and it definitely can't play videos with embedded or external subtitles. So when I use Plex with my Smart TV, my system uses very little in the way of resources (minimal CPU usage). When I try to play something on my Xbox One, especially if it has subtitles, then Plex has to transcode that video which demands more from the CPU. The [CPU in my NAS](http://ark.intel.com/products/91830/Intel-Pentium-Processor-N3710-2M-Cache-up-to-2_56-GHz) (which is less [powerful than the average i5](http://www.cpubenchmark.net/cpu.php?cpu=Intel+Pentium+N3710+%40+1.60GHz)) can handle roughly 3-4 1080p streams at the same time, which is more than I'll need, so I'm fine with what I have. If you want to use an i3 or i5, you'll probably do just fine with those. And since those are consumer processors, it'll probably be easier to find sales on them and related parts, like compatible motherboards or RAM. If you aren't at r/buildapcsales already, you should check it out.

**Virtualization**

So, whether you need VT-d or PCI passthrough, really depends on how much of a focus you want to have on virtualization. If you want to run Windows and Linux at the same time from one machine (not dual booting, but running them both at the same time), VT-d allows you to assign cores directly to those virtual machines. If you have an Intel chip with hyperthreading (which almost all Intel chips have nowadays) with 4 cores which = 8 threads in your processor, you could assign 6 to Windows and 2 to Linux and they'll each think they have a processor with 6 or 2 cores. PCI passthrough is similar, but it lets you pass your PCI devices to your virtual machines. Maybe you have a graphics card that isn't useful on Linux, but you have a USB hub you need to use on Linux. PCI passthrough lets you assign the graphics card to Windows, and assign your PCIe USB hub to Linux.

All of this only applies to running virtual machines on "bare metal" hardware. Basically, you're running a super minimal OS (like Unraid or Vmware Vsphere) which is just passing the hardware components to the virtual machines. 

If you don't need that level of virtualization, keep in mind that you can run virtual machines on top of a fully booted OS. That's how I run Windows 10 ontop of DSM (DSM is the name of the Synology OS). I also have a Windows laptop and a Windows desktop, and I use VMware Workstation to run multiple virtual machines (usually Ubuntu, Kali and another copy of Windows 10) within Windows. It's not as resource efficient as the 'bare metal' virtualization done by Unraid or Vsphere, but I don't need anything that extensive yet.

**Quick note on RAM**

The RAM is a different matter. ECC is error correcting memory, and the idea behind it is that it can prevent data corruption in environments where data corruption can't be tolerated or will cause major issues/downtime. Depending on your usage, it's probably not worth spending extra on that, especially if you plan to get a consumer CPU (i3 or i5) and consumer motheboard, because those are only compatible with normal RAM. 

---------------------

ZFS is a type of filesystem, like NTFS on Windows, or ext4 on linux. Btrfs and ZFS have a lot of features that are useful to datahoarders, and preventing silent data corruption is one that btrfs is known for; which is why I recommend that.

FreeNAS and Unraid are full OSs that can also handle setting up RAID on your drives, but DrivePool and SnapRAID are applications that you use in your OS (like in Windows). DrivePool is for Windows and it can pool all your drives together to act as one large drive, and you can set certain drives, folders or individual files to be duplicated across multiple drives. If a drive dies, then you'll at least have that data still available on one of your other drives. SnapRAID gives you a parity drive, like you'd have in RAID. So if you have 4 drives, SnapRAID will claim 1, and you'll have 3 for data storage. If one of those 3 dies, then SnapRAID will replace it with the parity drive to ensure that you can keep on working without missing a beat. SnapRAID isn't exactly the same as RAID, but that's the general overall idea behind it.


I wish I could transfer my files, but unfortunately I was storing linux isos without encryption, so my Plex Iso Cloud could stream them as needed (Plex Cloud doesn't work with encryption). 

Sharing any of those linux isos would have gotten my account locked down to begin with, but your guide should be helpful for all my other accounts.
Last I checked, [MSDN has hashes of the iso files on their site](https://msdn.microsoft.com/subscriptions/securedownloads/). Sometimes getting to the right hash can be a pain, and sometimes they remove files (and hashes) from public view (I logged in with my live account, but I don't actually have access, so I can only see some files and some hashes). For example, the file en_windows_8.1_n_with_update_x64_dvd_6051677.iso has an SHA1 of [457D02BD26A19965DA172DAAE78F985CF53AF692](https://msdn.microsoft.com/subscriptions/securedownloads/?#searchTerm=&ProductFamilyId=545&Languages=en&PageSize=10&PageIndex=0&FileId=0).

Find the hash that MSDN provides, and run it against the hash you get once you've downloaded the file. Another alternative is to get the hash of the file you have, and google it, and see if any reputable sites come back and say that it's "Windows10.iso" or something. 

If you need an application to hash the files, the one I'm using is [Multihasher](http://www.majorgeeks.com/files/details/multihasher.html). I dislike installing applications, so I use portable apps, and this one comes in a portable version. 

Select the hashing algorithms you want to run (MS uses SHA1 primarily, I believe), add/select the file, then once it's finished calculating it, go to Tools > Compare Digests, then copy and paste the hash you get from MSDN into there and it'll say if it matches or not.
Damn, how did I miss this. Then again, I browse datahoarder everyday, but I can't remember the last time I was on opendirectories. 
I wouldn't say it's any more difficult for the police to do the fingerprint method, especially since they don't have to go through the steps that a normal person would. They can just have the person place their fingerprints onto a transparent sheet (using some thicker ink) and then apply the wood glue/pink liquid latex and create a fingerprint mold and use that to unlock the phone. It'd probably take less than 5 minutes (including time for the latex to dry). 

If they had to do this often enough, I'm sure some company could make an easy to use kit for them to do this, rather than buying liquid latex or wood glue in bulk. Luckily for us, they still need warrants to do this kind of thing, at which point they use the person's actual finger to unlock the phone, so as far as I know, no such kit exists. 

With the iris scanner, as you pointed out, they just need to get a photo of the person's eye using a special/dedicated camera, print it out and put a contact lens on it and position it to open the phone.

Or they could make the person apply their fingerprint onto plastic type paper (or use transparent sheets), apply liquid latex, place latex on anyone's finger and open the phone.

For the police, these both seem equally easy. What's easiest for the average person depends on what they have to work with (ie how easy is it to get a photo of the eye of the person who's phone you just stole or a fingerprint).


--------------------

I followed a guide by starbug (the guy who is demonstrating the method to fool the iris scanner) on my cousin's iphone 5s (with their consent). I would have used my own Note 4, but it requires you to swipe your finger. Anyways it wasn't too difficult, probably took me an hour with some trial and error, but it can be done with household ingredients. If you already own a 3d printer, to create the 3d finger molds that you were talking about, it'll save you from having to do the last few steps, but I didn't have one. 

The steps I took were:

1. Get the fingerprint from the phone's screen/back/case/home button with a fine powder or superglue. With superglue, place it in a tiny bowl/cup and hold that up to the fingerprint. The goal is to get the fumes from the superglue to react with the fat residue that makes up fingerprints (so don't let the superglue actually touch the fingerprint). Since her fingerprints were on the screen, I just used baby powder and her flat topped makeup brush. 

2. Take some high res shots of the fingerprints. I used a 20MP Sony Cybershot camera.

2. Clean up the photo and invert the colors if necessary to get the fingerprint to show up as white. It very helpful to use gimp's intelligent scissors (or the equivalent in photoshop) to isolate the fingerprint and use the fill tool to change the background to the color black. So you're left with a white fingerprint on a black background.

3. Use a laser printer with at least 1200dpi (so basically any laser printer) to print out the fingerprint onto some overhead project sheets (transparent) using a thicker/denser toner setting on the printer, and in black and white. I had issues with this part because the latex wouldn't pick up the print, so I ended up printing onto the same sheet twice (took a few tries before it lined up perfectly).

3. Apply woodglue or pink liquid latex onto the printed fingerprint. I just bought some pink liquid latex in the form of women's latex for nails. 

4. Once dried, place the liquid latex on your finger and breathe on it to apply some slight moisture and unlock the phone. 

That's basically all you need to unlock the phone, so you might be able to do all of it without needing the user for anything after you steal the phone. This is, of course, assuming they don't use their penis or elbow to unlock their phones, as some redditors have demonstrated in the past. 


Gsuite for educational institutions is free. By setting up a proper domain and filling out the forms (so minus the cost of the domain and some time) the ebay sellers were making just about 100% profit on every account they sold. Going forward, I would guess that Google will be checking new accounts more closely, but I don't think they're going to start requiring credit cards to run credit checks or something.

As to whether folks were using fake credit cards on Ebay, I can't say. But that's ebay's problem, not Googles or the admins of the fake education Gsuites.

Edit: 
Domains can be pretty cheap. For example, thegsuite dot org can be had for 99 cents per year and can be paid for with bitcoin. I'm not saying they aren't using stolen credit cards for that, but it seems like a massively unnecessary risk.

I don't know if you're saying you think it's a good idea, but trust me, for that price, all you should expect to use it for is as a throw away account. Which is why I only used it with Plex Cloud.
Can't speak for anyone else, but I bought mine solely to be used with Plex Cloud.

For 5-15 dollars for an unlimited storage account, I think that's all one could expect from it. I wouldn't even use it as a backup for another account. 
Yea, it didn't have anything to do with what was stored or how much of it. It was about the fact that the ebay resellers were violating Google's policies when it came to reselling google accounts.

There were some folks who had entirely empty accounts that had lost them, and it's because Google removed entire domains, instead of targeting specific accounts.
It was in the one about Comey and Trump, or Dialysis or Net Neutrality (I don't watch the show, so those are the only episodes I've seen). I know I saw that quote, but I can't remember which one it was in.

Edit: It was the [Comey one](https://www.youtube.com/watch?v=dtAqPRuqNSg)
Yea it had everything to do with reselling google accounts. 

In regards to contents, if you read through Google's TOS, you can store copyrighted information on your drive if you want, but they will take action if you try to share it or its been reported to them that your drive contains copyrighted information (which nobody should be able to do unless you share it somehow).

So as long as you aren't storing something that's super illegal/harmful to others, then you can get away with just about anything as long as you keep your drive to yourself.
I wish I could say the same. I had spent a long while uploading stuff to it so I could use it with Plex Cloud, but I hadn't gotten any of my family or friends to start using it yet. 

It's a bit unfortunate, but I never expected it to last; it was my "throw away" gdrive account.

Edit: I was hoping it would last long enough to get some decent usage out of Plex Cloud though.
Just curious, but what was your process for backing it up? Just using the share function?

That wouldn't have worked for me since I've been storing linux isos in the clear for use with Plex Cloud.
I had walked into my local store and they said they didn't keep those in stock since not enough people bought high capacity HDDs (they had one My Book Duo which had a total of 8TB), but I just checked the website and it says they're available for shipping again. 

So thanks for the heads up, I managed to grab a few more. 
There isn't really a sleep mode on Synology devices, or at least nothing I'm seeing in DSM 6. There's HDD hibernation, which can enable deep sleep for any external devices you have plugged in, but for the NAS itself, the only options are HDD hibernation and auto-power off. 

If you want to use WOL, then that will allow you to turn on your Synology device whenever it's fully shut down (so you can enable auto-power off and use WOL), but that means it will have to do a full boot when you wake it up and want to use it.

I don't know how long it takes you device to boot, but mine takes longer than I'm willing to wait. 
Are you still able to ping your device, and have you tried to log into it from a different computer or phone? Since you said you had HDD hibernation on, does it sound like the drives are completely idle when you turn it off, or does it sound like they're active/spinning up?

Either way, if you're using Plex, then your HDDs shouldn't be entering hibernation. I believe that's one of the apps that keeps your disks running 24/7.

It might be useful to download the Synology Assistant app to see if it can recognize your NAS on the network when you're unable to log in. If it can't, and you can't log in from another computer/phone, then it sounds like an app on the NAS is causing it to disconnect somehow from the network; or perhaps something odd is going on with your router/switch.
I think you're talking about HDD hibernation; unless you went ahead and enabled auto-shutdown. HDD hibernation is as close as it gets to a sleep mode without shutting down entirely.

To utilize WOL your Synology device has to be fully shut down, at which point you can turn it back on by sending a magic packet to its IP address. Also, I don't know how your device is set up, but I've found that my DS916 doesn't boot in 30 seconds; although it might if I replace the system volume with SSDs in Raid 1 or Raid 0.

Anyways, you can use any application that is capable of sending magic packets to wake up a Synology device, but DSM Help also says the Synology Assistant app has this functionality built in.
Make sure to disconnect the drive from your home computer before you try to connect to it from your work computer. 

Having 2 computers simultaneously connected to the same Clouddrive drive is likely to result data corruption. 
Just FYI, the new WD My Books don't have Reds in them. They have 8TB white label drives. 
Yea, your config is a good match if you're trying to get a good price while having enough cores.

I'm sure that both the i9 7920x and the Ryzen 1998x will be outside of my price range (although it'd be pretty great to have 32 threads on one non-server CPU), but if the prices of the lower specced versions aren't compatible with my wallet, then I'm just hoping that prices on older chips will be lowered once these are released. 
While the entire system has a little over 24k in passmark, they did say they're planning to run VMs. 

So depending on how many VMs they have going and the performance they need per VM, they might get half that performance for Plex. 

I've been planning a similar build (waiting for the new Intel i9/Xenon and Ryzen server/enthusiast chips to drop first), and even if I had 16+ cores, I'd only leave 2-4 cores or 4-8 threads for Plex (kinda depends on the performance of those cores as well). 
I've seen those little raid arrays for micro sd cards. It comes in a 2.5 inch form factor and plugs into a sata port. 

Unfortunately the largest i've seen is 10 micro sd cards. Also, buying 10 would be very expensive or have very slow performance. 
Luckily, cable tv will be staying around longer than they otherwise would have, courtesy of their partnerships with ISPs (or being out righted owned by them/same parent companies). 

So in the short term, we should see streaming prices rise while cable options are presented as good alternatives. 

Had title 2 not been revoked, then I would have predicted that traditional cable would have died off much more quickly and the dozens of streaming companies would be enough to keep the marketplace competitive. That doesn't seem in the cards for the near future though. 
You say that now.

I predict that in the near future, things like Hulu will either be priced much higher or, it will be throttled to the point of uselessness; making cable seem cheaper or more appealing by comparison. 
Hmm ok. I checked the site just yesterday or the day before, and it was in stock but it was also at 200 bucks then too.

The first time I bought these, they weren't available at my local best buy so my only option was to order online and have it shipped to my house or to the local best buy.

I'm guessing my local best buy won't have it in stock, but I'll give them a call and find out.
Every time these go on sale, it always says "Shipping not available, instore pickup not available".

I bought 3 the first time around, and I wonder if that's why it's not showing up as available for me anymore. And It says it's not available in any stores within 250 miles of Chicago.
Plus there's also the consideration that these have different drives in them.

All of the new 8TB WD My Books have white label drives, while the Best Buy easystore have 8TB Red drives.
They playback slowly in the editor, but the final result isn't that slow. At least it wasn't in my experience. 
Yea, I've noticed all of my external drives (I got 3 from Best Buy) will idle at 50-55 range. It makes CrystalDiskInfo unhappy when it goes above 53. I don't know if it's because they never spin down (despite my settings in Windows to spin down after 20 minutes), or if it's just cause they normally run at that temperature. 

The only time I've seen it get below 35 is when I plug in the drive after a few hours of it not being powered.

I'm not terribly worried yet though. Heat isn't great for longevity, but Red drives are rated to the 65 degree range when it's in use (75c when it's in storage). Also, under load, I haven't seen it go above 56.
There's a discussion about that going on right now here: 

https://www.reddit.com/r/DataHoarder/comments/6c8yaa/are_wd_purples_only_for_surveillance_or_would/

They're the same physical drive with different firmware, but the reply from the WD Staff member (on that forum that was linked), seems to say that the major issues (ATA streaming commands) aren't really a factor if you put it in a NAS or desktop. Other differences would be that the Purple drives are tuned to favor sequential writing and reading, and the firmware keeps the drives running 24/7 (no spindown). 

I'm not really well read on the details of Purple drives, but if those things are the only major differences, then I'd imagine it'd be just fine to use Purple drives in a NAS. Performance might be different, but the lower cost might make it worth the difference. 
When it's in stock, I think the student store will be your best best. I got in on the Best Buy 8TB sale, and the lowest it was was 180/drive which isn't far off of the student discount on WD. 

If you buy an external My Book Duo at $383 (comes with 2 8TB Red drives), the price per drive is $191, giving you an effective price of $23.875 per TB. A bare Red 8TB drive is $198 per drive, which comes to $24.75 per TB.

Also the Best Buy sale was on WD Easystore external drives. Those come with 8TB Reds. I've personally verified that the new My Book comes with Blue if it's under 8TB and I've read that it comes with white label drives if it's 8TB.

I'm only pointing that out, just in case you see a future sale on 8TB My Books. I don't know what the difference is between white label drives and Reds, but the externals with white labels seem to be cheaper (250 for 8TB Easystore, and 200 for the new 8TB My Book)

Edit: If you're interested, the 8TB Purple drives seem to be in stock now, and more often, and those are 181/drive.
Depending on how it's set up, you can have deduping happening across multiple devices. This could be done via some kind of software keeping track of original files and pointing all others who request that file to the original, or via some sort of virtual filesystem/raid setup to span multiple devices (possibly a combo of both). I don't know how it would happen exactly on the scale that Amazon operates at, but I'm guessing it might happen like that. I use an app called Treesize to manually dedupe files across my devices on my home network, but it's not something I need to deal with all that often, so I run it maybe once a year.

Either way, it's unlikely that Amazon dedupes at separate servers. They have a lot of servers around the world (and in the US), so they can provide files quickly and they'll use this to keep backups of their data as well. If your US East (Virginia) server burns down, you don't want all that data to disappear off the face of the Earth; so it's probably backed up to both US West (Oregon) and US East (Ohio) and maybe other places as well. That also allows them to provide fast access to people on different sides of the country. Instead of someone living in California having to connect to a server in Virginia to get access to a certain file, or website/service, they can instead connect to the US West server and get faster access to it.
Yea it certainly varies. My guess on how much 'average' folks are storing was entirely a ballpark guess. I'm sure there are many professionals out there who use ACD for various things and almost all of it certainly won't dedupe as you pointed out.

Wouldn't that dedupe the best? You're downloading the same media files as however many other people, and it's even better because the heavy hoarders are likely hording many overlapping files. Depending on the client/method used to download, there's various levels of hashing to ensure you're getting the same files as well (bittorrent verifies the integrity of every downloaded piece of a file, and usenet clients run checksums to ensure it downloaded properly).

It's the folks who rip their own media who would have content that doesn't dedupe well; especially if they use custom settings or an application that lets them change output settings. Even if they have an application that doesn't let them change output settings, it's still quite possible they'd end up with differing files from others who use the same application on the same media. 

Also the folks who store personal items like family photos/videos or documents would have files that wouldn't dedupe as well; but it's not like those folks are storing more than a TB or so.
Don't you remember that semi-recent AWS (Amazon Web Services) outage where it was down for a few hours? It took down half the internet with it; some of which were actual websites and many services that are used to run websites. Reddit, Pinterest, various game services (ie Ubisoft), and many others (including Netflix up until 2016) all run off of AWS.

Even sites that don't utilize AWS directly, will often rely on 3rd party services that are run on AWS. Amazon outstrips Google and Microsoft and they started their cloud services 2 years before both Google and Microsoft even announced they were bringing cloud services of any kind to market. 

When it comes to the cloud, the internet, and anything related to that, Amazon is anything but a "shop".

Edit: worded something improperly.
I don't know about your thermostat, but if your wife's MacBook is old enough, then that might be why it's not working. It's hard to find info on when Apple started supporting 802.11w, but some sites seem to say that it happened after 2013 and/or they only support it on Macbooks that have 802.11 AC wifi cards (not available on 802.11n devices).

Windows added support for it back in Windows 8, for the OS itself, so if you set up bootcamp and run a modern version of Windows, it might be an interesting way to see if that fixes the problem.
Certainly, and the way most other "unlimited" plans deal with it is to enforce a limit of some sort.

Usually that means they look at the max use of a 2%er or the the lowest use by someone who still qualifies as a 1%er and use that as the limit. "Unlimited" until you get to that point.

If Amazon gets to the point where they can't afford to keep allowing heavy users on their ACD plans, this is the route they'll probably take, rather than give the ax to a customer outright.

I don't know if excessive usage will be against the TOS (they could write in a specific limit, but they might not treat it as severely as other violations), but TOS violations run the risk of losing your entire account (only an issue if you use your Amazon shopping account for ACD). There's similar stories of that kind of thing happening at Google and Microsoft. 

If I lost my Amazon account, with all the giftcards and other random stuff I have and legally paid for, especially after having been a good customer for so many years and giving them so much money in many different ways (including using Amazon as a payment service at random sites), I probably wouldn't go back.
The difference is that the hype around Star Citizen is based on the fact that they have done a pretty good job at rolling out new features for people to play with right now. They might be slow at releasing upgrades/patches (as in they often miss their expected release dates), but they do deliver. 

If people could play No Man's Sky as it was being created, nobody would have bothered to buy the finished product, and there would have been no hype surrounding that game. 
I highly doubt we're responsible for a negative net profit. The way unlimited plans work is you use the 99% of users, who are casual users, to offset the costs of heavy users. For every couple TB we use, there's probably a couple hundred people who are paying to just store a couple hundred GB of photos or videos. I know quite a few people who use ACD as a glorified sync client, but they use Amazon instead of Dropbox/Google, because Amazon gives them unlimited storage.

Excluding some very extreme examples (ie the 1PB pornstash), I'm sure it's pretty easy for them to offset the costs of just about everyone here. 
That's unfortunate, but I stopped using Stablebit CloudDrive with Amazon a while ago just because Amazon is a pain.

I actually don't use Amazon much unless I want to toss something random onto it, like a backup of a game I got from Gog.com or something.
Piracy of course!

There is no way you can make any impact on rights holders, where they would give 2 shits what you or any other consumer thinks. 

The only thing they give a shit about is piracy.

Plus, Netflix has had a huge impact on piracy (I'd link the studies, but I'm lazy), so if Netflix loses enough content and the piracy starts to rise, maybe they'll reconsider how they do business.
That's makes sense, and it's probably not made with people in mind who have more than a hundred movies or episodes in their library either, which would explain why it's a pain to move your server from one device to another, and how unwieldy the server files get as you add more movies to it. I guess at over 200 movies (which is likely more than anyone could fit on a laptop's hdd, even if they used compression to the point of blatant pixelation) that makes me a bit of a power user and having some uncompressed blurays makes me a videophile. I never considered that I might not be Plex's target demographic, considering that it seems the only purpose of their app is to do these kinds of things, but I've never used anything other than Plex, so maybe they aren't good for serving files/media that's larger than what someone could keep on their laptop.

And that's very true, but it's not really any different than it is now. You can't really game on a machine that is using nearly 100% of its CPU resources for transcoding. Hell, you can barely open a couple of chrome windows on it when it's transcoding. But if you're using the GPU, then at least the would still be functional for day to day tasks. You're not going to be gaming, but the GPU is still far more capable than the CPU when it comes to these kinds of tasks that benefit from multiple cores.

Either way, it seems the only way to get good usage out of Plex is to download highly compressed files that caters to your lowest quality device or build an expensive server grade builds. I guess it's a good thing 4k media isn't really all that prevalent yet. Plex might have to redesign their app to support higher quality files when it does become popular though.

Have you used Emby before and if you have, did you like it? I've never looked at it before, but browsing their features, it seems like it's more accommodating to libraries larger than a few hundred files and they've had GPU transcoding for a while, which sounds like they're targeting casual users who use their desktops as servers; as opposed to folks in here who are buying or building entirely new devices to be their dedicated Plex servers.
I'd like to see what kind of quality videos people have if they're able to transcode on a rasberry pi. I mean, if it's direct play, then it doesn't really matter since it doesn't take much to send a file over the network. I used to use my old laptop for the same thing, and if Plex had GPU support, I might be getting a lot more use out of it today.

I know a 20-30mbps bluray rip is a lot more than the average pirated movie which ranges from 1-4gb H264, AAC files, but I'm not getting movies with phones/tablets in mind. I rip movies with my 4k TV in mind (and no, I'm not using 4k movies since those would be closer to 50-80mbps), and that works just fine with most of my devices. The reason I built my library around my best looking device, is because you can always transcode files to a lower resolution/lower bitrate, you can't transcode low quality files to look better on high resolution/high quality screens. I'm not really concerned with preserving quality when streaming to devices that need transcoding.

If I could afford the storage hardware, I'd make rips in sizes from 720p to 4k, and in every codec necessary. The point of transcoding is that you shouldn't have to spring to have enough storage, not to mention the cost of electricity, in order to support the random couple of devices that can't play X. Transcoding is a much more efficient solution, since those low quality rips aren't something you'll need to keep around for most of the time.

Desktops being rare isn't something I would have guessed is a trend in the Plex community, but I haven't spent enough time here to know either way, I suppose. Reading some of the comments in here about normal users running server grade builds and the random posts I see about utilizing CloudDrive/cloud/managing larger libraries, I often thought I was on the more casual side of the Plex community. 
Yea, I'm right behind you on that. Everyone is so focused on judging OP for having the audacity to do something they wouldn't, that nobody is considering the fact that many people are running Plex from their desktops; and desktops often come with dedicated GPUs.

Rather than encouraging people to build entirely new dual 8 core processor servers, or making the excuse that high core CPUs are cheaper than GPUs, I think it'd be better if we encourage Plex to develop their software to allow people to make use of the hardware they already have. 

Either way, judging OP does absolutely nothing to help anyone or answer their question.
Regardless of how many streams OP has going, allowing for GPU processing is something that I'm sure many people could benefit from. I'd be willing to bet that a fair number of people are running Plex from their desktops, some of whom are running gaming rigs (in other words: good GPU, midrange CPU).

If they're ripping their own media without compressing it (which many do, to maintain quality), that means their CPU is likely to handle 2 1080p transcodes (by Plex's recommendation of 2k passmark score per 10Mbps; and most bluray rips skew closer to 30Mbps), but anything above that is a no go.

I'm sure desktop users aren't the 99%, just from looking around this thread, it seems a lot of people are running dual 8 core Xenon servers, but I'm guessing they're a sizeable number, and anyone with a dedicated GPU could benefit from Plex bringing this functionality. 
I've been looking for something like that for a while now. I wish internet "cafés" were a thing here. Just a simple, pay for a certain speed rate and pay for a certain amount of time. 

Unfortunately my former university is an hour out, and their guest network is limited in speed (but students get much higher speeds, at least they did 6 years ago). And local library has slow speeds. 

Anyways, I have to take a couple of classes at local college. I'm hoping they've got good speeds. 
I don't know what exact is needed for a trucking job, but the community college near me has a few semesters worth of courses (including behind the wheel training) that people have to go through.  These are for semi trucks, not delivery vehicles. 

So I'm guessing it's not as easy as: I already have a class D lisence to drive cars, so let me just hop in and drive this semi truck across the country. 

Anyways, doesn't seem cheap, especially if you don't already have a job. But if trucking companies hire just anyone off the street with no training, then it sounds like a great job for a lot of folks out there. 
Buying a Synology unit for just cold storage and not connecting it to the network seems like a lot of money wasted (as you pointed out).

I know I wrote a lot, but this first time setup should take about 30 minutes, not including the time it takes to download/install the virtual OS and format the drives. Any subsequent use of your drives should be easy and quick. This will give you the same redundant btrfs storage for the price of 2 external hard drives (so it should be significantly cheaper).

**Install VMPlayer and setup Ubuntu:**

If I were in your situation, I'd go out and buy 2 external drives, download and install [VMplayer](http://www.vmware.com/products/player/playerpro-evaluation.html), download a Linux distribution ([ubuntu 16.04 64bit should work just fine](https://www.ubuntu.com/download/desktop)), and set up the Ubuntu virtual machine (lots of [youtube videos](https://www.youtube.com/watch?v=CdiKs6Hu9O4) on how to do this from [start to finish](https://www.youtube.com/watch?v=wHxvu_t-wAc)). Instead of doing it how they do it, after you press "create virtual machine", I recommend selecting the second option and pointing it to the Ubuntu iso file you downloaded. This will make it install much faster.

During the setup part, when you get to customize hardware screen, you can leave it as is or tweak it to whatever you want and your computer can handle, but you should definitely change the USB controller to use USB 3.0, and make sure the top and bottom box are checked. For my VM, I just changed the ram to 2gb, left it at 1 processor, and changed the USB settings.

I've never created a RAID or btrfs system in linux before, so I decided to set up my own virtual machine and try it out myself (before telling you what to do). If anyone knows a better way to do this, or wants to correct something, let me know.

**Format Drives into Raid1 btrfs**

Before going further, you'll need to pass through your external drive to the virtual machine (if you haven't already, make sure the drives are plugged into your PC and show up on your Windows side). In the upper right hand corner, you'll see 2 little arrows, just below VMPlayer's minimize button. Click that and you'll see some devices; find your USB hard drives and right click on them and select "Connect (disconnect from host)". You'll need to figure out what the OS is calling your disks (it's likely they'll be /dev/sdb1 and /dev/sdc1). There's a couple methods to figuring this out but terminal is easier to explain.

Right click on the Ubuntu desktop and open terminal. 

Type in:
    
    sudo fdisk -l


It'll ask for your password and then list a bunch of ram and disks. Your disks will probably be at the bottom. [It'll say "Disk /dev/sdb 2TiB" or something like that. Below that, look for where it says "Device" and keep track of that for both disks, it should be something like "/dev/sdb1".](http://i.imgur.com/LNNlpYb.jpg) It'll also list the current file system type (which will probably be NTFS). In my picture, my drives were 5GB partitions I was using to test setting up a Raid 1 btrfs system.

[Here's a picture of my full console and all the remaining steps.](http://i.imgur.com/zbg4j43.jpg)

In the terminal type:

    sudo apt-get install btrfs-tools

Once that is installed, run the command: 

    mkfs.btrfs -f -m raid1 -d raid1 /dev/sdb1 /dev/sdc1

Replace sdb1 and sdc1 with whatever the names of your disks are. After that finishes, your devices are both in Raid1 and have btrfs as the file system. A couple more commands to go. In my case, I was using 2 SSD partitions at 5gb each, so it finished in no time at all.

On the left side, you should see both of your disks on the taskbar. We need to mount the disks, so click on both of them and only one of them will mount (since it's Raid 1, you only need to write to one of those drives). Once it does mount, a file manager window will pop up to show the empty drive, but you won't be able to write anything to the disk. Close that window and go back to the terminal.

Type in:

    sudo chown -R $USER:$USER /media/username

Replace "username" with the username you chose (all letters in lowercase). In my case it was "/media/penguin/". This will give you ownership of all the mounted drives and let you write data to them as you want. Might take a minute before file manager shows that you can write to it.

**Access Windows and Copy files over**

At this point you should be nearly done. All your files are probably stored on your Windows side, so you can set up a shared folder to give Ubuntu access to your Windows files. Go to Player (on VMPlayer) > Manage > Virtual Machine settings. Click on the Options tab at the top. Select Shared Folders, and change that to Always Enabled. Click Add and browse to wherever the files are that you want to copy onto your external drives.

Once you've done that, click on File Manager (second button from the top on the taskbar), navigate to Computer on the left side, then go to mnt > hgfs and inside there you should see whatever folders you shared to Ubuntu. Copy your files, or do whatever it is you wanted to do. 

Last thing to mention, be sure to unmount your drives or shutdown Ubuntu before you unplug them to avoid any kind of data loss. You can unmount them by right clicking on their icons on the left side taskbar, and going to unmount.

Now you've got 2 external disks in RAID 1 btrfs for cold storage. You can take the VM (stored in your My Documents folder by default) and put it into cold storage as well, since you won't need it until the next time you want to update your drives. At which point its as easy as booting up Ubuntu, plugging in your drives, connecting them to Ubuntu, and clicking on the drive icons on the left side to mount them.
Yup.
I'm sure you're exaggerating, but I've never known Nvidia to make drivers so poorly that a later version of the driver netted a 30+ fps increase on the same card. Nvidia is the one who gives Microsoft the drivers that they push out in Windows Update. They aren't updated as frequently as Nvidia's, and you won't get beta/game-day release drivers, but they should be more than adequate (and something is seriously screwed up if you're seeing a loss of more than a handful of FPS). Besides the age, there's no difference between the drivers, but the one you get from Windows Update won't install any bloat either (no Nvidia Control Panel, GFX, 3D Vision, etc).

Anyways, that's with the drivers you get from Windows Update. If you don't connect your PC to the internet, then you'll be stuck on a more generic driver until you manually install one, which is a different situation entirely.
Reading through the forum post, it looks very promising. I hope they bring this to the regular release and soon. 
Yes, it has to be unencrypted if you want to use Plex Cloud. If you want to use Plex Server, then you can use it encrypted.

The second drive isn't really necessary, but I wanted to have two separate accounts to avoid any issues I might face if Google changes their policy and starts banning accounts of people with copyright infringing material. I can't afford to lose my main account because I do absolutely everything with it. It might never happen, but better safe than sorry.
* If you want something that acts like a normal hard drive, and will automatically encrypt and upload anything you put into that hard drive (but it'll stay transparent on your local computer), then Stablebit CloudDrive is the right choice for you. It'll work well with the Plex Server app (there are some settings you can tweak to optimize CloudDrive towards streaming videos).

* If you just want to copy files directly to google (encrypted), then rclone is for you. The virtual hard drive thing that rclone has doesn't work on Windows, but it does work perfectly on Linux. So, on Linux, Plex Server and rclone will work well together.

* Plex Cloud won't work if you encrypt anything, which means CloudDrive and rclone aren't good options. You can upload files unencrypted via the Google Drive website, the Google Drive desktop app (which I wouldn't recommend, because it's for syncing files, not 1 way uploads) or other 3rd party apps.

* So if your primary goal is to upload stuff (movies/Tv shows) to Google Drive so you can use Plex Cloud, then you should check out Expandrive and Netdrive. They will create a virtual hard drive on your computer (kinda like CloudDrive, but without the encryption) and then anything you place inside of that hard drive will be uploaded (unencrypted) to Google Drive. These will allow Plex Cloud to work with your Google Drive, but last time I tried ExpanDrive, it worked very poorly with Plex Server. So they'll allow you to use Plex Cloud, but they won't stream videos well on Plex Server (unless the apps have improved since I last used them).

----------------------------------

My current setup (if you're interested), is I have 2 (unlimited) Google Drive accounts. On my first Google account, I upload all my movies and everything else, unencrypted; and then I linked my Plex Cloud to that Google Drive. I upload everything via an app called Cloud Sync on my Synology NAS. I've linked Stablebit CloudDrive to my other Google Drive account. It's a great app that provides easy to use encryption, because it works like a normal hard drive, so I can just drag and drop files/folders into it. I put movies into that hard drive and it uploads (and encrypts) everything for me. I point the Plex Server app to search for movies inside that hard drive and it works great. CloudDrive is designed to handle all types of files but it has some settings that you can tweak so it works better for streaming videos. Anyways, that lets me use Plex Server when I'm at home (and have encrypted files), and when I'm out of the house, I can use Plex Cloud.

If I used Linux, I'd be doing the same thing, but I'd use rclone instead of CloudDrive on my second Google account (CloudDrive isn't available on Linux).
That is a massive heatsink. Is it for passive cooling, and if yes, do you see performance comparable to the fanned counterparts?

Also, sucks about the mobo which might be the hardest part to recover from this. If it didn't short, then you might have a chance. I don't know how damaging coffee will be, but if you can make sure it's fully cleaned out..maybe.

[LTT](https://youtu.be/tASvbnODtq4?t=5m40s) mentioned that an option is to soak electronics in alcohol (90% or higher according to [ifixit](https://www.ifixit.com/Wiki/Electronics_Water_Damage#Section_pH_of_common_fluids)) and ifixit says that alcohol is helpful at displacing any other liquid that might still be on the board (and alcochol will dry away faster than other liquids).
I haven't used rclone (so I don't know the commands), but you don't have to encrypt your files first and then sync them. You can have rclone encrypt and upload the files for you. This way, your local files can stay unencrypted (well, they'll still be encrypted at rest with Bitlocker), and you can have your encrypted files in the Cloud.

If you want to use your encrypted files on Google at some point in the future, you'll have to use rclone, or some compatible program, to download and decrypt the files before you can use them. So you should keep rclone around. 

Either way, I prefer to use [Stablebit CloudDrive](https://stablebit.com/) on Windows, simply because I want to see my Google Drive mounted on my computer, so it looks and acts like a local hard drive. This makes my life much easier since I can just drag and drop files into that hard drive the way I would any other hard drive/flash drive, and I know the data is being encrypted before it reaches Google. Plus, there's a very user friendly GUI, so you don't have to work with command line. 

Rclone has a similar feature that allows you to mount your Google Drive on your local computer, but it doesn't work on Windows.
If you're running Windows 10 Home, you should be fine. The exploit used was patched back in March, and Home users don't get the option to refuse an update from MS.

Ransomware could still hit you, especially if you like clicking on sketchy looking files, but it won't be delivered via this exploit.
Sure no problem.
It's possible to move from [SHR to SHR-2](https://www.synology.com/en-us/knowledgebase/DSM/help/DSM/StorageManager/volume_diskgroup_change_raid_type), if that's something you're interested in doing. Just be sure to add enough blank disks to your array when you are ready to change to SHR2.

But it'll probably be easiest to start out with using SHR2. It'll help if you're worried about multiple disk failures, which might be useful considering that rebuilds will take longer as you start adding larger drives to the pool. 
Sounds good. I was just about to edit my comment to say Cat5-e instead of Cat5 (to avoid confusion), but if you don't have any extra cables, then Cat6 or Cat7 are totally fine. And whether you'll see any benefit in aggregating connections depends on your setup.

In my case, almost all of my clients (except for my NAS) are wireless. My router is capable of delivering 1733mbps speeds over wifi, but realistically, none of my devices will be hitting anything close to those speeds. Most of my devices report a link speed around 800mbps or lower, and most of them are just used to stream videos or something like that so I don't need to worry about them maxing out my connection. Most I have going at one time is 3 devices streaming video. I use one device to copy files, which uses the most bandwidth out of all of my devices, but I don't need to do that often and it happens late at night when the other devices aren't in use.

If you have some devices on wired gigabit connections, and if you want to do something bandwidth heavy (like copying files to the NAS) from more than one device at a time, then you'll probably see some real benefits from aggregating your NAS's connections. Or if you have enough devices that do things like stream video, it might be worth it to aggregate your connections.
Looks pretty solid to me. There isn't a whole lot involved in setting up the NAS. It's quite user friendly, and you only need to plug in to the ethernet ports, the power cable, the hard drives and you're set.

If you have any extra Cat5 cables lying around, you could use those instead of getting Cat7 cables. The switch you linked doesn't support more than gigabit speeds anyways.

I run my DS916+ with a few 8TB Red drives, and only have 1 port connected to my router for the time being. I can't make use of any extra speed I get from aggregating 2 connections together, and I'm not too worried about uptime/redundancy since I can walk over and fix the NAS at any time.
I wish I had 114TB to play with, all at once, it'd be pretty awesome. Unfortunately, I don't have the hardware to handle that many drives. Also 114TB is the raw (advertised) disk space on every drive in the house, so some of them are things like externals that are plugged into my Xbox, or maybe they're old drives/drives that aren't in use. I guess it might be a bit misealding for me to list all the drives in the house, but they are drives I could reclaim and use at any time if I need to.

Anyways, I use my NAS to store my library of linux isos. It has 60TB of drives in it, but only about 38.8TB of that space is useable, and my linux library accounts for 15TB so far.

I ran out of space on my NAS 2 months ago, so I upgraded its storage capabilities and that's why I have so much free space right now. Now that I have the free space, I've been able to start going through my collection and upgrading them to better quality linux isos.
Isn't the C2538 the same processor that they used in the 1815 and 1515 series?

I mean, they might have needed to redesign the board anyways, since it seems they've added new functionality to the 1517 series that wasn't there on previous models. 

If I didn't already have a DS916+, I'd be very interested in buying a new NAS from Synology with a Xenon processor.
If you aren't interested in trying this, there is a VirtualBox app for Synology devices. I've never tried it myself, but there's lots of youtube videos of people using it on their NASs.
Indeed?

Are you asking if there's an easy way to upgrade your isos? If you are, I'd look into Sonarr. It can be set to automatically find and download videos that meet your specifications (iso is a certain size, a certain quality, a certain resolution, etc). After the download finishes, it can move the iso into your collection and remove the older version that the download is meant to replace. 

It's quite useful for getting new distributions as well. Just click on "add series" and type in the distro you want to download...like "Futurama" and then click the add button. It'll automatically search and download any isos it finds for that distribution that matches your quality preferences. 
If your router supports it, you should look to enable 802.11w. If it doesn't have a setting for that, you might want to look into flashing something like dd-wrt, OpenWRT onto your router (if it's possible, sometimes it can't be enabled on older routers), or use a Cisco router. On those linux based router OSs, there are settings that let you enable 802.11w (Cisco's Management Frame Protection). This allows your router to send out hashes with its management frames (ie things like deauthentication packets), thus providing you with additional security. This means that deauthentication packets sent by anyone, other than your router, will be useless; since they won't have the proper cryptographic hashes. They could run dauthentication attacks on you all day and nothing would happen.

Also, every modern computer and phone OS has support for 802.11w, so compatibility shouldn't be an issue.

Edit: It might be called Protected Management Frames in your router, or something along those lines as well.
Doing what r/datahoarderguy70 suggests should really be all you need to do.

If you don't use WPS, then turn it off. If you do use it regularly, and you have a newer router, then you should be fine since most routers nowadays have protections against WPS attacks (increasing timeouts).

When it comes to wifi hacking, especially in dense areas, it's very likely they'll move on if they can't get yours in a few minutes.

Of course the situation is different if they live next to you, and their 4g wireless modem (with unlimited data) died, and they were 1 episode away from finishing Lost (which they wanted to finish tomorrow night), so they decided to borrow your internet while they waited for the new modem to be shipped. Then they might let an attack run for longer than a few minutes. As long as your password is sufficiently long and avoids words in a dictionary and obvious variations on dictionary words (like "1ns3cur3" is much safer than "insecure" but it's also the kind of thing that could be found in some dictionary files), then you don't really have anything to worry about.

Also, the ending of Lost isn't worth the cpu cycles it takes to crack someone's wifi. I think that's common knowledge now, so you have that going for you.

Edit: changed modems to routers. Don't know why I put modems.
I'm not sure I follow your logic here.

You say that antivirus applications are useless (since they won't protect you from viruses), then you go on to say that their mere existence will invite more people to develop viruses. Finding new exploits for Android isn't as simple as running a few outdated, prepackaged tools. If they're intelligent and tech savvy enough to find exploits, then surely they don't think that a phone with a useless antivirus app presents a worthy target (I mean, antiviruses on Android do little more than protect you from outdated modes of attack).

If a useless antivirus application can provoke these rogue companies and actors with malintent into developing more viruses, then can you imagine the negative impact things like firewalls, encryption, sandboxed apps, running users with lower privileges by default, would have? Those things are actually useful when it comes to protecting phones, so I can only imagine that having those protections will certainly invite far more challenge. 


The way I see it, the people who want to hack android today (with malintent) are the same people who wanted to hack it yesterday. New, bad actors aren't suddenly going to start wanting to exploit you and/or Android because Mcafee scans for for viruses and exploits that have been patched or aren't relevant today.

On the other hand, those without malintent, I can certainly see them being inspired to try and hack the Mcafee app. They probably already try to hack Android on a regular basis (Google is pretty good at paying for exploits/patches), and Mcafee is yet another company who is willing to pay for bug bounties. But if they are more inspired to attack Android or Mcafee, then we should be thankful, because every exploit they find and report to Google/Mcafee, is one less that a bad actor can use against us.
The good old days. I remember I had installed a Master Chief mod, so instead of Clippy you got the MC. It was amusing and he would randomly say Halo related stuff, and quotes.

That whole thing got me interested in desktop assistants, so I managed to find and download a desktop assistant application (which could also be skinned as the MC). Basically all it did was look stuff up on the internet, or, if you had Dragon (the sound to text thing), it could do other small things like open My computer if you said "open My Computer".

If it could add appointments, set alarms and send texts, it'd be about as useful as today's assistants. 
It saves the description as a separate file next to the video file (with the same name as the video file). You can open them in any text editor. I just used notepad to open them. 
Certainly sucks, but if you aren't a Windows user, you can buy one and not be affected.

At least, there's no flickering on mine when I boot into Ubunutu instead of Windows.
Seems like it. After my last reinstall of Windows, there wasn't any flickering either, until I installed the drivers.

Whatever generic driver MS uses before Windows gets any updates seems to work. I think once Windows pulls updates, it gets the same driver that Intel has on their website.
Yea, for me it's when the monitor enters sleep that it'll cause the screen to flicker when it wakes up. The NUC entering sleep doesn't cause the screen to flicker if it wasn't flickering earlier. But if it was flickering earlier, then the NUC going to sleep doesn't do anything to change it.

I thought the problem had fixed itself, but after rebooting it started doing that again. No idea why I was able to go the last few days without it happening, or why it came back after a reboot. 
Damn, that's too expensive for my tastes.

If anyone does get it, could you run CPU stress tests and see if it performs any better than the fan? Running Aida64 apparently causes the CPU to throttle after hitting 100 degrees, in the normal version.
I know this may not be convenient, but could you try booting to a linux usb boot drive and seeing if you can recreate the problem?

I have the NUC6i7KYK and was having a similar issue, which really seemed like a driver issue as well. In my case, the monitor would flicker when I woke it up from sleep (by moving the mouse) or when I changed resolutions (1080p is my monitor's max resolution by the way). It would continue to flicker until I turned the monitor off and back on (temporary fix). This didn't happen when I was booted into bios and it didn't happen when I was running off a linux boot drive, which suggested the problem was in Windows. And a fresh install of Windows, before all the updates/drivers were put in, it seemed that I didn't have this problem either (but I did eventually install the drivers at which point I definitely noticed it).

I don't know what happened, but for some reason that seems to have stopped now. I haven't changed anything and I still have the same drivers, but it randomly started working for me after I rebooted, futzed around in the bios (didn't change anything) and went back into Windows.

Edit: I spoke too soon. The screen didn't flicker at all...until I rebooted the machine. Not sure why it's back, but I did manage to go a few days without it, since I kept the NUC running or in sleep mode. 
My situation might be different than yours, but I had issues with my screen flickering on occasion when I moved the mouse and the monitor came out of sleep or changed resolution. I chalked it up to a driver issue (since it didn't happen in the bios, or my linux usb boot drive, only in Windows with all the drivers installed) but turning the monitor off and on again seemed to be a temporary fix and stopped the flickering.

I don't know what's changed, but the issue seems to have resolved itself and it isn't happening anymore.

Edit: I went a few days without issue, but after a reboot, the issue was back. So I just need to figure out what I did that one time, and then never reboot again.
I installed the bios update first, before installing windows, but it's probably easier to upgrade the bios from the exe file they provide in the drivers zip file.

After you install Windows, start installing the drivers, then it's probably a good idea to do the bios before you install windows updates.

I'd say that not all the drivers are necessary (depends on what features you want to use), but I'd say the important ones are networking (wireless/ethernet), bluetooth, chipset, graphics, and thunderbolt. There's an html file in the zip file that explains what each installer is for.
I only buy retail keys and it's because my friend watched some youtube video, discovered a site called kinguin (or something like that, it's basically G2A but instead of just selling sketchy/stolen game serial keys, they sell sketchy software codes as well), and he managed to buy a working Windows 10 Pro OEM key for 20 bucks.

When he needed his activation reset, Microsoft basically told him that he had an OEM key and to go get support from the original manufacturer (he didn't have one, since it was a custom built pc). He tried a few more times, but eventually he just bought a retail key off of kinguin, twice (first time he got a used key that someone was trying to sell as a legitimate one).

Tl;dr, don't get an OEM key if you plan to upgrade/repair your pc since it's tied to your motherboard. Retail keys are tied to your MS account and are easy to reset via the automated phone support thing.

Also Tl;dr, don't use kinguin or whatever the name of that site is.
That's certainly true, especially if you shop around or get parts on sale.

I just threw together a bunch of parts on pcpartpicker, using the cheapest equivalents of all the specs listed on their site, my total came out to 1183 or ~1158 after mail in rebates and promo discounts. 

For a pre-built PC, this one is pretty decently priced (at its sale price). The case they use probably costs 3x as much as the one I chose.
Same, I never watched any of his videos until today, but they seem like decent stuff. I watched a couple.
**Tl;dr**: Jerk impersonates a former prize winner by making a fake reddit account, and gets people to hate on Ohnickel by posting a "I never received my prize" post in r/overwatch. Apparently all this was done for no reason other than the fact that the jerk wanted reddit gold and karma.

----------------------

Long version: 

Ohnickel does lots of giveaways (and actually follows through on them). 

Scammer sees that one of the winners has a twitter account but doesn't have a reddit account and makes one (with the same name as the twitter), so he can impersonate that twitter user.

The real winner publicly thanked Ohnickel for winning and thanked him again, on twitter, when he got the prize (a gift card). That was a few months ago.

Scammer makes post on r/overwatch, just the other day, about how he never received the prize, reddit blindly upvotes him (over 20k upvotes), gives him lots of gold, and some people felt so bad for the scammer they even PM'd him and offered to send him money.

Reddit bandwagon is in full effect. Ohnickel wakes up to see his twitter is full of hate messages, from the "you suck" to the "go die in a fire" variety. He also sees a huge number of people unsubscribe from his youtube channel. All of this could have been prevented if a few people looked at the winner's real twitter account (and called out the scammer in that post), instead of blindly believing the faked twitter images the scammer presented.

This all happened overnight while Ohnickel was a asleep, so he had no idea. Lots of reddit users said ohnickel's silence was proof of his guilt, but in truth, he was just asleep.

Some responsible redditors, including a few of the mods at r/Overwatch, did their due diligence and tried to check out the scammer's story (they even contacted the real winner). They realized the scammer had a history of karma whoring and he did it to get karma and reddit gold; but the thread proving ohnickel was innocent didn't get as much visibility cause the mods deleted both threads, since they thought the entire topic was too polarizing. 

It's ok though, this youtube vid made it to the top of r/overwatch and #1 on r/all. Ohnickel still lost a bunch of subscribers and is still getting hate on twitter though, but at least all of reddit now knows that he's innocent. 
I'd still recommend normalizing the volume across your songs. Having to speak to your phone to lower or raise the volume sounds far more annoying than tapping ok once on the volume limiter (although it'd be nice if we could turn that off as well).

I believe Google Play Music will normalize your songs if you upload your songs to GPM. So that's another alternative if you don't want to pay for a streaming service.
I did a quick google search, and the [first (and every)](http://i.imgur.com/RFki47s.jpg) result was about how the 4A engine (that Metro Last Light was built on) was designed to scale up and use as many CPU cores (and multi-GPU setups) as the system is capable of providing. The entire engine has a huge focus on parallelization, apparently, which a quick google search should have shown. 

Dimitry of 4A Games: "No, there is no upper bound. However, there is lower bound. We can run on a dual-thread CPU, but in this case there is already internal oversubscription, which causes lower framerate and stutter. Realistically, a quad-threaded CPU is the minimum for us, with eight-thread CPUs vastly preferred."

I'm not saying that all games are CPU heavy or anything like that. I'm just saying that google is doing you wrong if you can't find a single entry about multi-core CPU usage on a game that was built from the ground up to take advantage of that.
Maybe they've changed how they do things with the S8, but on my S7, the only thing I see in Galaxy Apps that aren't in my application drawer, are extensions and plugins that support others apps/features (those apps/features often have user facing interfaces in the system settings menu or elsewhere). These, on my phone, are pre-configured camera modes which you can see in the Camera app, language packs which work for S-Voice (I've never used S-Voice, but I keep language packs for it and for Google Now installed on my phone), Occulus app (but the full blown Occulus app and service doesn't get installed until you put your phone into a Gear VR, which I did), or things that support system features, like the aforementioned quick connect (located in the notifications drop down), which shows up on my phone since I cast my phone to my TV. 

Any other app from the Galaxy App store (like I have S-Note installed), shows up in my application drawer and can be uninstalled via the application drawer. And I actually prefer it this way. I dislike unnecessary clutter, and having an app icon in my application drawer for every single camera mode I have installed, or even little things like the Nougat Easter Egg app (which is a system app) would be excessive. As it is, I often freeze apps, that I've installed, so they don't show up in my application drawer until I need them.
Shouldn't you be setting up your phone, including volume settings, before you start driving, not in the middle of driving?

While the volume notification is most definitely annoying, using the phone while driving sounds like the unsafe part in all this. 

Unless of course you have some sort of sound system in your car that doesn't have any volume controls, in which case in makes sense that you'd have to change the volume constantly on your phone while driving. I'd recommend getting a sound normalizing app so you don't have to fix your volume while driving, or just run your songs through an application on your computer and resync it to your phone. Or get something like Google Play Music, which does a pretty good job of doing that for you.
If you haven't used an Android device before, or were a casual user, there are many apps and services that are installed on phones that don't require user facing interaction and therefore aren't shown in in your application drawer. Some of these can be language packs, system services/apps, extensions, plugins that add additional functionality to a feature/app that does have a user facing interface, etc.

To find these apps, you can use the default application manager in the Android settings (be sure to click on the 3 dots menu and select "show system apps", or you can install an app from the Play Store that lets you freeze/uninstall apps. All of these apps will show up in both of those places. The only exception is that in the former, you won't have any option to uninstall system apps that are critical to running your phone. If you really want to cripple/ruin your Android OS, you could installing a 3rd party app, use root, and mess with/remove those hidden system services. Although most of those uninstaller applications are designed well enough that they won't let you do this anyways.

Not having apps shown in your drawer isn't something that Samsung has invented, it's an inherent part of Android. Most of the things in Galaxy Apps that aren't shown in your application drawer are things like filters/modes/features for your camera, extra language packs for voice interaction in apps, plugins and extensions that allow your extra features to work (like wifi extender, quick connect), etc.
Until I had a USB-C (with Thunderbolt 3) port, I thought it was unnecessary to have it because there aren't enough accessories. The only thing I have for USB-C is a portable ssd which also came with a USB-C to USB-A connector, which meant I could use it on any computer I owned.

But frankly, USB-C is the future. It can power devices, it can output to a monitor a monitor, and connect to a dozen accessories, and all you need is one cable going into your computer. A single cord connected your computer can turn it into docking station that can be used across all your devices that support the USB-C protocol. 

Most importantly, the Thunderbolt 3 enables it to do even more. Using an external graphics card cannot be achieved with current USB 3.1 plugs because they simply lack the bandwidth. With this, you could effectively turn any Surface tablet into a gaming powerhouse that rivals desktops (so long as your CPU is a core i5/i7 or is fast enough that it doesn't act as a bottleneck). I'm sure there's more applications than just ultra fast storage and graphics cards, but that's all I need at the moment. 
Hmm...

Maybe I should start storing all my encrypted files inside a giant container called "pagefile.sys".

Then when the evil police state comes rolling around, I can just say that I did it to play Modern Warfare, and the file was corrupted which is why it seems like random data.
Sure no problem. If you have any questions about this stuff, feel free to ask (if I can't answer it, someone here will be able to). I'm a big fan of my Synology NAS, especially since it has a hybrid RAID (SHR which protects against 1 disk failure, or SHR2 which protects against 2 disk failures) that lets you use different sized disks while still offering you some level of protection.

https://www.synology.com/en-us/support/RAID_calculator

Basically, when I bought it, I was a complete and total noob to this stuff as well, but Synology's OS is pretty friendly, so I was able to get it up and running. Overtime I decided to delve a bit deeper and see if I could accomplish more than it being a big hard drive that ran Plex, and I started playing with Sonarr and Plex in Docker.
I must have played that game over 100 times, and I never made that connection before, but it seems really obvious now that you mention it. 
I avoid these drives, but only because most of my disks are used in RAID type arrays, and doing a rebuild with archive drives would be painfully slow (weeks, probably more in my case). Not to mention defragging, balancing, anything like that would be crazy slow and would affect system performance.

The drives that I have that aren't in RAID usually have data rewritten to them a lot (as I get better quality media files).
Not exactly. Paran014 explained it best. It's not the rotation speed, but the fact that it has to write/rewrite to these tracks that makes it slow.

They have fast burst write speeds (couple gigabytes maybe), but they will be very slow if you have to write a lot of data to it. It gets worse if you fill up the drive, or delete data and it has to rewrite to previously written on sections of the disk.
I'm sure there are. Between this reddit and the Plex one, I've heard some huge numbers when it comes to how much is stored in the cloud. Although I can't name which users have used that much off the top of my head.

It could be that the app doesn't recognize storage larger than 12TB.
It depends on how careful you are when you remove the drive. There's a few tabs in the single drive WD external enclosures that almost always break when you remove a drive from it.

Reading around online, it seems like the general consensus is that these tabs are basically there so WD can know if you removed the drive or not (which will likely void your warranty).
The cheapest route will be to build your own NAS (basically a desktop with lots of hard drives in it) and then use a NAS OS (unraid, Xpenology, FreeNAS, etc). You'd stand to save a lot money, but you'll miss out on some small hardware conveniences (like easy drive swapping).

With Synology devices, the hardware is good, but their OS is what sets them apart.

On it's face, it's very user friendly and you can just plug in some drives, it'll take you through the initial walkthrough, and then you can just install Plex from their appstore and you're good to go. But if you're a power user, you can accomplish quite a bit with it, especially using Docker.

I have a Synology DS916+ and I really like it. I've got Plex, Sonarr and Download Station (Synology's usenet/torrent/http/ftp download app) running 24/7, so between those 3 apps, it'll handle automatically finding shows, downloading them and moving them to my Plex media folder. It never needs any interaction from me, and new episodes show up in Plex as they come out.


Sounds good. I'll give them a shot, thanks.

What kind of transfer speeds are you seeing on it? Also, do you have any experience with the 2000mbps model? I'm curious if they're just talking about throughput over the powerline (meaning you will get better speeds even if you place the devices far away from eachother), or if it means you can plug the device into the router twice (using both ports) and it aggregates the connections to give 2000mbps speeds.

I'm pretty interested in getting something like this. My desktop and router are on opposite sides of the house and my NAS is located where the router is. The AC wifi does reach my desktop which reports that it has a link speed of about 780mbps, which means that I should realistically expect to see half that speed (even on MIMO wifi).

So if you're getting speeds higher than 350mbps (especially in file transfers), then this sounds like something I could really use. 
Yea, none of the pumps in my area allow anything other than physical cards, but there's 2 gas stations (the internal POS devices), that Samsung Pay always seems to fail on. They don't use chip cards yet either, but their devices always come back with a "card read fail" error. 

I've seen the exact same card reader devices used at Subway and Samsung Pay works fine there. I can never figure out why it works flawlessly at some places, requires a retry or two at some, and doesn't work at all at others.
Really? I've found that grocery stores and such places are where Samsung Pay works best. As fast as using a credit card, and works on the first try.

Gas stations, some restaurants (the ones where you can pay yourself anyways, not through a waiter) and one or two fast food places in my area are where Samsung Pay doesn't work, or takes multiple tries to work. 

Might have something to do with the approval process from the bank/Samsung, but I would have thought they'd be more willing to approve stuff since Samsung is on the hook for handling security.
I never knew that. I'll have to check my old desktop to see if it's got different controllers set up on it.
Ahh, gotcha. 
Not sure what system you're using, but on my NAS, I set it to optimize a couple videos and it used the cpu at 95% until the transcode was done.

Then again, Plex isn't optimized for my NAS (Plex doesn't utilize the hardware transcoding), so on the fly transcodes use up 90-95% of my system resources as well.
I shucked a 6TB version of this yesterday (had a 6TB Blue inside). I wasn't trying to do this, but I almost managed to remove the drive without breaking a single internal tab.

Stick a few old credit cards, or hotel key cards into the seams at the top (I used two cards on each side and pushed them about half a inch into the case), stick some cards into the seams along the bottom (I used one card on each side), then push out the drive by pushing on the bottom (the area with the serial number). Once the drive pops out, there's 4 hex screws holding the drive into the plastic internal case, and 1 normal screw which holds the board on the hard drive.

I was hoping to get the case working again after I removed the HDD, but unfortunately all I got was a bunch of "fatal hardware errors" whenever I tried to initialize the 4TB Blue drive I put in there. I read online that you need to break some pins on the card, and I tried that as well, but it didn't seem to do anything to help me out.

Oh well, I have an extra dock at the moment, so it's not a big deal.
How do you go about selecting which controller manages your storage? Is that something you have access to in the bios?

I've never attempted to change my storage controller before, but the only options I've ever seen in my bios(s) is between using AHCI or RAID for my internal disks.
A high quality linux iso is one that plays at 1920x1080 resolution and has a bitrate of at least 7-10mbps or higher.

Previously, I had quite a few linux isos that only played at 720p and/or had a low bitrate.

Also, "linux isos" can mean anything really. It's just a term that is used when you don't want to admit exactly what you're hoarding (could be videos, ebooks, games, comics, porn, software, actual linux isos....could be any kind of data, really).
Not rcloning specifically, but yes I was uploading isos to my Google Drive (via Cloud Sync app on my NAS). So a decent portion of my upload counter, maybe 800GB or more, is accounted for by my NAS uploading stuff. 

The rest of it is probably overhead from my downloads. Download something at 60-65mbps, and I'll see an overhead of at least 3-4mbps in the upstream (which is unfortunate since I only have 5mbps up). 

So there were plenty of times when I paused/throttled my NAS's uploads, because without doing that, most of my downloads were limited to about 30mbps.
Indeed. Until Assistants are like the Viv demo that I saw in 2016, I will consider them useless (or only to be used when I'm driving). 

Assistants need to be able to do what you want in a faster and in a more efficient way than it would be if you were to do the same by tapping on your phone. 

The command "Order some flowers and send it to my mom on her birthday" that Viv was able to carry out was much faster than what you'd be able to do on the phone. That's what assistants should be. 

I hope they start putting those types of things into Bixby soon. 
Yup. And my usage isn't normally so high but I was replacing a bunch of my Linux isos with higher quality ones. 
I'd guess no. I haven't read through Covecubes TOS, but most companies have clauses that say people aren't allowed to resell their software unless they're an authorized dealer/re-distributor. 

You can probably give it away, but usually selling it is where the problems pop up. 
I wouldn't do this. When you buy more than one license (at least in my experience) they all get tied to the same activation code. That means if I buy two licenses, then I use the same code to activate it on 2 computers. 

Let's say you buy 10, then I buy one from you and you give me the activation code. Once I know that activation code, there's nothing to stop me from trying to use that code on 3 or more computers, even though I only paid you for one. 

I'd get away with using 3 of your licenses and there's not a whole lot you could do about it. If you contact support and explain the situation, they might choose to revoke all of your licenses for violating their TOS (most companies have clauses to prevent people from reselling their software unless you're and authorized dealer). 
I was getting slow speeds the other day, so I was trying to see if there was something on my end causing the issue. When I checked my bandwidth usage in my router, it looks like I've used 8.4TB total (7.1 down, 1.3 up) last month. 

Not bad for a 60/5 connection. 
Is there any point in reporting it? Google might take down the app, but they'll publish the exact same app under a new name. 

There's dozens of other apps that are promising the exact same thing and asking for permissions and data they shouldn't. It doesn't seem like Google cares, and reporting one app at a time (even if Google takes them down) doesn't seem like a good way to fix this.
There's probably lots of fraudulent installs, but there's also reviews like this:

"I hate the fact tht u hve to wait fo 20 people to install,and i need the data nw,and also the ussd code does nt work"

Pyramid scheme at work, but without the small rewards that come with a traditional pyramid scheme.
Hopefully that's the case, cause then it's just a minor inconvenience. I guess time will tell what the problem actually is.
Two 8TB Red drives at a price of 383 dollars comes out to about $23/TB (for students) or $30.5/TB for non-students ($488 for both drives). I'm not sure it's possible to find a better deal on 8TB (non-SMR) drives, regardless of where you live.
You should start backing up your files and use the device as little as possible until you get it repaired/replaced.

When li-ion batteries swell like this, continuing to use them will only cause them to degrade, and after a certain point they may catch fire or explode. 

Same thing happened to my Razer Blade a while ago. The battery swelled up and I was able to use my laptop for a week or two without issue, but continuing to use it only exacerbates the problem. When I first noticed my keyboard was slightly uneven, only 2 cells were bad, but by the time I decided to take out the battery, 5 out of the 6 cells were swollen (and the corner of the track pad was starting to bulge out). 

Anyways, the tiny details making schoolwork difficult is the least of your problems with that device at the moment.
It's been a long while since I've used drivepool (so I'm working off of memory), but you can set certain folders/files/drives [to be duplicated](https://stablebit.com/Content/Images/overview/drivepool/screenshots/protect_1.jpg?776267314). I do recall that it let me set up which drives I wanted my mirrored data to be stored on, so at this point, you'd select the cloud drive as the target for your mirrored data. 

You can go through that process and set up each root level folder to be duplicated to your cloud drive, or you can set it up so the entire drive gets mirrored to Cloud Drive. When I was using Drivepool, I wanted to get my Cloud Drive on Google to mirror my Cloud Drive on Amazon, so I had it set so that all data on my Amazon was duplicated to my Google Drive (I set this at the drive level, instead of doing it for each folder).
Get Stablebit Cloud Drive, create a drive on your Google Drive account, add that drive to your storage pool, and have it set to be a mirror of all the other data in your pool. 
Helium levels arw monitored in the smart data, so if there's a leak, you'll have time to get your data off before it becomes an issue. 

And from what I understand, helium will always leak out, since the molecule is so tiny. That being said, you're probably going to suffer mechanical failure or buy a new/larger drive before you lose enough helium that it'll affect your ability to use the drive. 
They're still allowing you to get apps, they just aren't giving paid apps out for free anymore. 
Then I don't think it would trigger anything. Cloud drive stores all the chuck files into one giant folder, and Plex would probably scan through the files inside the chunks sequentially. I think that might make it less likely to trigger any kind of temporary usage ban. 

Plus the devs of Stablebit Cloud drive tried to put in some limits on the number of API calls the app would make to avoid any kind of usage bans. I think the problem was that Plex Cloud drive or Plex server (with an unencrypted Google Drive) would go over that limit. 

So if you're using the Stablebit Cloud drive app, you probably have nothing to worry about. 
7000 subfolders in Stablebit Cloud drive or uploaded to Google Drive with no obfuscation or encryption? Are you using a normal Plex server, or Plex Cloud? 

Either way, I've heard they were only temporary bans and it was because of excessive scanning by Plex (but I haven't heard of anyone complain about that for a long time now). So 10 days might not be enough time to test this out. 

Anyways, it's probably best to ask this question in r/Plex
It's because the Surface Book is capable of connected standby. Windows automatically enables that on tablet/laptop CPUs that are capable of utilizing that feature, but then the high performance and power saver plans disappear. Disable connected standby by changing its registry value and those plans come back for good. 
Windows just enables connected standby on CPUs that can handle it. Turn off connected standby and you get those power plans back.

If anything, you could say that Microsoft believes they know what features you want in a modern tablet/laptop better than you do. 
If you use the registry to disable the connected standby feature, then it will unlock high performance and power saver modes for you automatically. So you won't have to use that powercfg console command each time you change plans and reboot or something.

http://www.surfaceforums.net/threads/disable-connected-standby.10901/

Tl:dr: 

1. Enter the registry (search Cortana for 'regedit' without the quotes, or use the windows key + r and type regedit into the run box).
2. Go to Edit > Find and type in "csenabled" (without the quotes) into the find box and press enter
3. Double click on CsEnabled (once you find it), and change the default value (1) to 0. Hit ok, and reboot your PC.

Now, Power Saver and High Power should show up in your battery plans area.

If you can't find it via the search thingy in regedit the full path is:

HKey_Local_Machine\System\CurrentControlSet\Control\Power\CsEnabled
Gotcha. Yea, that seems to echo my experience as well (the few times I used it on my phone).
Yea, I thought that would be the case. I haven't really used it all that often, unless I'm connected to an open wifi network.

Now that ISPs can sell your data, it'd be nice if there was a VPN service that had minimal power drain so I could leave it enabled while on 4g as well.
Yea that makes sense. I've never taken the time to figure out the best price per TB based on that before, but it would give you a better price comparison. 
Edit: Sorry, just realized you were calculating price per TB based on how much usable space you would have, not the raw disk space (which is what is normally used for price per TB calculations). Feel free to ignore this post. I'll keep the post up in case anyone wants to reference price per TB in this way. 

If you're buying 4x4TB drives, each at around 150 dollars per drive (I rounded up for the Amazon price), that gives you a total of 600 dollars. 600/16=37.5 per TB. 

For the 4x6TB, with 2 @ $245 and 2 @ 213 gives you a total cost of 916. 916/24 = 38.1 per TB. 

Subtracting the dell credit (420) from each of the subtotals I calculated, that gives you a total of 180 for the 4tb drives and 458 for the 6TB. Giving you a per TB cost of 11.25 per TB and 19 per TB (respectively). 
I've seen them use their own drivers and job listings for Amazon delivery drivers, but only for Prime Now deliveries, which is different than normal Amazon products though.

Other than that, they do seem to use local/regional companies for same day deliveries in some markets, could that be what you're thinking of? 

In the area I used to live in, one of those companies always had people in plainclothes who delivered my same day deliveries. I thought it was odd, but only because most of my deliveries came from uniformed folks, like from Fed Ex, UPS, or USPS.
Their customer support is pretty decent in my experience. I asked them about returning an opened/used device (Synology NAS) because I wanted to know if I'd get a full refund, and how the refund would work (I used a few different payment methods). 

They basically said it's fine, and later on, I saw that I got a full refund for the device. 
If you're in the US, I'm sure you'll be fine, especially if you bought from Amazon directly.
They're ordering from the UK.

I don't think anyone int he US needs to worry about this. I've ordered a dozen or more hard drives from Amazon over the years and never had to worry about this kind of thing happening. 
I asked about this in the last thread and it seems like that is the case. OP is buying from Amazon (directly) in the UK. 

Reviews from the US Amazon page for that hdd seem to show that people are receiving their HDDs with good packaging. 
Are you asking about VPN cause you're curious, or because you saw OP using VPN?

I glanced over the screenshots and didn't see anything that indicated he were using a VPN.

Anyways, I'd like to know the answer to your question as well.
Did you throw it out?

I mean...if it's within a month, you might have been able to return it, and you definitely could have gotten it covered under warranty. 

Then again, it's your money. You can throw it out if you want to.
That's probably part of it, but she's also a very clumsy person. Her non-portable items are in good shape though...like her dresser...her tv, her roomate's cat? Well, last time I saw it anyways. 
That's some good life advice right there. If everyone took better care of their possessions, there wouldn't be any need for cases or insurance.

But until then, those companies will continue to make bank off of everyone buying cases or insurance, and even more money off folks like my sister.
Her case is actually an otterbox case [around this size, but for the normal S7](https://www.amazon.com/OtterBox-DEFENDER-Case-Samsung-Galaxy/dp/B00Z7SF7GM/ref=sr_1_1?s=wireless&ie=UTF8&qid=1493246310&sr=1-1&keywords=s7+otterbox). I just meant that it's thicker than most of those sleeve, or flip cover type cases that most folks have, and short of the brick like case I [put on my old Note 4](https://www.amazon.com/Case-Zerolemon-ZeroShock-Red-Black/dp/B00ZDGZ98O/ref=sr_1_3?s=wireless&ie=UTF8&qid=1493246174&sr=1-3&keywords=note+4+rugged+case). Her case survived though, it's in decent shape and she's still using it. 

As for how she does this to her phones, I have no idea. By the time she's done with a phone (also laptops), it's usually in terrible shape, to the point where most people would have stopped using it long ago. But this was the first time she actually ruined a phone enough that she thought it needed replacing before the 2 year payment/upgrade plan was over. 

I haven't used cases or screen protectors for a couple generations now but modern phones are built to survive me. I've dropped them on occasion, but I've rarely ever suffered a scratch, much less anything worse. 

My sister on the other hand, she really should be a product tester for a company like Otterbox.
Depends on the kind of person who is using that phone. 

My sister always rocks a thickish case (thicker than most cases, but not so thick that it's a giant brick) and a screen protector and she's on her second S7, which already has a cracked screen.

Buying a cheap ass (budget) phone would obviously be cheaper than doing the insurance, in her case, but insurance is cheaper than shelling out for a new, midrange to flagship type phone. 
I think it'd be fine to make a topic here about that if you wanted. Discussing media streaming, hoarding, organizing, etc is something that comes up often enough, especially when it comes to NASs. 

I don't think you'll find many, if any, that will be able to transcode 4k with Plex support. The DS916+ is supposed to be able to handle 1 4k transcode (@30FPS), but that's only via their native Video Station app (and I've never tested that). Building a NAS yourself is probably the ideal route, since you can make it as powerful as you need, while likely saving money over something pre-built of equal performance. You might lose out on some small conveniences that you see in pre-built NAS hardware, but nothing important.

As for myself, I really haven't had all that much in the way of issues. There have been times when I grew frustrated because my NAS couldn't handle transcoding a super high bitrate video on the fly (bitrates high enough that I come close to hitting bandwidth restrictions), but that's been fairly rare. Most of our devices are rokus, android phones/tablets, and a Samsung TV (which can handle just about any media format you can throw at it), so just about everything is direct play. Only our Xboxs need transcoding (for subtitles, especially), but I'm the only one who uses the Xbox for Plex. I've never had to transcode any of the 4k media we have, but I usually keep 1080p versions around in case we use a device that needs transcoding or can't support 4k.
The 1817 and the 1517 have the same CPUs as the 1815 and 1515. I don't know about that particular cpu, but I do know that Plex doesn't do a good job at supporting hardware transcoding on my 916+, even though they support hardware transcoding on other devices with the same CPU. 

The DS916+ could handle 3 simultaneous 1080p x264 transcodes, but without hardware support from Plex, one 1080p transcode maxes out the CPU at 85 to 90% (give or take 10% for the background apps I run, like download station). 

Anyways, just something to consider if Plex is your main use case. Usually I don't need to transcode more than one stream, so it doesn't ruin my plex experience or anything; just annoying that they don't fully support Synology devices.
Probably not. Like many things about Android, it appeals to a particular crowd, and to some degree they do it because they can, not because they need it or because they think the average person would want it. 
This is pretty fun to play with, and surprisingly fast. I thought it would be stupidly tedious to type out every command/app name on a touchscreen keyboard, but with the suggestions and shortcuts, it's pretty damn fast. In terms of speed, it's like having every app placed on your main homescreen, making everything 1-2 taps away. 

Only, I suck at command line and can't figure out how to give this app access to the SD card. Without access, it doesn't seem to be willing to allow the use of the ls command outside of the internal storage (and the command can't be used in root folders since it doesn't have access there either), which majorly hampers my ability to use this app. 

Either way, it's a fun app to play around with. Once I set up the shortcuts, I could see myself using this as my main homescreen interface from time to time. 
If you want to make your own rips, then use something like MakeMKV to create rips of your DVD and Blu-ray discs (it's apparently quite easy, just select the languages and subtitles you want to include and then go for it). If you don't have the storage space to store the full, uncompressed files, then you can use something like Handbrake to re-encode the videos into a smaller, compressed format. 

But it's much easier to pirate it in a quality you deem acceptable (everything from super compressed to completely uncompressed/blu-ray copies are available). 

Once you have the video files, use a program like plex to keep them organized and looking nice and it'll let you stream it just about anywhere you want to. 
Futurama is available on the high seas (and in better quality than you could get on Netflix). I like to use both Netflix and the high seas for shows like Futurama. 
Yea, I had 5x4TB Green drives in my Drobo 5D, and I've replaced all of them except for one with 6TB Blue/Ironwolf drives. The last rebuild took about 36 hours, so I'm guessing it'll be another 36 or so when I get around to replacing that last 4TB drive.
A rebuild with a couple of these drives in a drobo could take forever. If you have lots of data, or large drives in your drobo, a rebuild could easily take days or longer. 

SMR drives can write quickly for short bursts, but any sustained, even sequential writing (like large files, or doing a rebuild) will be slow. Overwriting older blocks will be much slower and that's likely to happen with drobo devices since it performs automatic background maintenance (defragmenting, balancing, etc).

I wouldn't recommend using archive drives in drobos. As mmaster23 said, a good bet is to get the My Book Duo, which comes with two 8TB Red drives. If you have access to an educational email address, you can get drives for much cheaper on WD's official site. 
I actually had the opposite happen to me. Before the CU, the button on my pen almost never worked. I'd have to futz around with disabling and re-enabling bluetooth in order to try and get it to work. Now it works normally for the first time.

I've had other hardware issues (clipboard wouldn't detach, and batteries stopped charging), but I've managed to get them fixed.
Sorta happens in Halo Combat Evolved. The second to last mission, Keyes, there's a part where you fall into a pool of greenish water and he has to walk along the bottom to get out. 

https://youtu.be/YgtjuMPCGwY?t=2m31s
If you want to be as secure as possible while filling in passwords, on apps/pages where Lastpass can't auto fill, then you need to use the lastpass keyboard. 

It can be a bit unwieldy, but when you're logging in, select the password box on the website/app, pull down your notifications to select the keyboard input notification, switch to the Lastpass keyboard, select the appropriate password from the list. 

As the other guy said, if you copy and paste them without using the Lastpass auto fill, or their keyboard, then any app with access to your clipboard can see your passwords. Swiftkey is the only one that tells you it has your passwords in the clipboard. 
I haven't used it before (I'm downloading keypass now), but it seems like the bypassing the clipboard* requires you to use the KeePass keyboard (according to their Google play page). 

It sounds the same as the Lastpass keyboard. The issue is most people won't switch their keyboards to allow their password manager to fill in a password without using the clipboard. 

*Edit: Just to be clear, I'm talking about apps or websites they don't play well with autofill type features. 
Interesting. Does that mean that Snapchat just monitors the default folder where screenshots are saved? 

I don't use Snapchat, so I don't really know how it works when it comes to stopping/reporting screenshots. 
A lot of companies have that kind of feature built in. I'm honestly surprised that Google hasn't implemented it yet. Android isn't like the iphones, we've had big phones for forever now. 

I guess it doesn't matter to much to me, Samsung is always on top of their game when it comes to one handed mode, but I'm just surprised it isn't in Stock yet. 
I was having the same problem and was also receiving the "import failed, path does not exist or not accessible by Sonarr" message in the logs. I was trying to fix any permissions issues (running it as different users), but it turned out that my paths weren't set up quite right. Your situation might be different.

I'm pretty new to docker, so up until now, I had my Sonarr mapped the way it was recommended by the setup guide for the Sonarr docker image (linuxserver): 

    Synology DSM Filesystem  ----> Sonarr
    "Downloads/SonarrDownloads/" --> "/downloads"

The absolute path would be "/volume1/Downloads/SonarrDownloads", which is what any app outside of a Docker container would see.

In my case, I use Download Station (which isn't a Docker app) to download files; so when Download Station completes a download, it tells Sonarr that the download is located at "/volume1/Downloads/SonarrDownloads/TheDownloadedIsHere". The issue here, is that Sonarr has no folder called "/volume1/" inside its docker container.

I fixed this by mapping:

    Synology Filesystem -----> Sonarr
    "Downloads/SonarrDownloads/" ----> "/volume1/Downloads/SonarrDownloads" 

So when Download Station says it completed a download and that it's located at "/volume1/Downloads/SonarrDownloads/Somedownload.mkv", Sonarr looks in the right place.

If you run SABnzbd outside of a container, then you might be having a similar issue.

If you run SABnzbd inside a container as well, then you should be fine as long as the external and internal paths match up in both containers.


If all you're looking for is a way to view/mount your Google drive, then NetDrive or Expandrive or such products might be more up your alley.
[This](http://forums.plex.tv/discussion/126254/rel-webtools/p1#top) acts as a channel inside of plex and allows you to install other tools and features. 

Pretty easy to install. Just extract the "webtools.bundle" folder from the webtools zip file and paste it within your [plex install folder](https://support.plex.tv/hc/en-us/articles/202915258-Where-is-the-Plex-Media-Server-data-directory-located-).

Put the webtools.bundle folder inside the plug-ins folder:
Library\Application Support\Plex Media Server\Plug-ins\

I forget the name of the app, but once you get webtools/unsupported appstore installed, one of tools/apps allows you to export your entire media library into a csv or other database files. You can include many different types of metadata (including resolution, video and audio codecs and other things like that) as well.

It won't organize your library for you automatically, but at least it lets me keep all the media files+metadata information in one spot.
A few days ago, I promised my bank account I wouldn't buy this and I would wait until one of my HDDs died before getting it. 

My bank account is very upset with me at the moment. 
I think that all drives, 8TB or larger (not including archive or SSDs), are helium filled at the moment. 

Anyways, the normal helium value for 8TB Reds is 100, but if it hits the threshold of 25, that's when SMART will throw out warnings about it being pre-failure. So, unless you puncture your drive (which would probably be fatal for non-helium drives as well), I think you'd have some warning.

I'm hardly a physicist, but as I understand it, helium is small enough that it should leak out over time, regardless of any punctures or leaks. I'm guessing that, on average, it will leak out at a slow enough rate that your hard drive will likely die of traditional mechanical failure (or maybe you'll replace it with a newer hard drive), before you lose enough helium that you have to worry about the health of your disks. 
You have very little usage time on this drive (less than 100 days). If it's still covered under warranty, which should be 3 years for a bare drive, this might be a good time to contact support, run their diagnostic tools and then send it back. From what I've read over the years, Seagate is usually pretty good about replacing drives that have (non-temperature related) SMART warnings.

I've also read that some folks with this same error (which is common on Samsung's EcoGreen series) have managed to run their hard drives for a while, up to a year, after receiving this warning. I'd make a backup immediately, but I'd continue to use the drive with the understanding that it could fail at any time. So, like you said, I wouldn't put any data on there that I wasn't willing to lose, or didn't already have backed up.
Not necessarily, unless it's an ISDS that happens to take place in Mexico; but that's more about overturning/overruling US domestic law than it is about enforcing new laws on the US.

I don't think a ruling in a Dutch court will have any influence over another country in the EU, but it might make it a little bit easier for lawmakers to push this issue and make it a law across the EU. 
I don't know what to say then. 

I've mainly bought WD drives, but I've bought 3 Seagate drives from Amazon and all of those came in those little hard drive boxes and had good packaging overall. After browsing the reviews from Amazon's US page for that product, it looks like those who did upload pictures of their packaging had theirs shipped in hard drive boxes as well. 

If I ever need to buy a HDD when I'm in the UK, I'll be sure to think twice about where I order it from, I guess.
Yes, Amazon absolutely dropped the ball in this case, and regardless of the state of the drive when they receive it, they should have done better.

Luckily, in my experience (and I suspect most others), Amazon doesn't drop the ball when you buy products from a trustworthy source (ie a manufacturer).
True, but if the 3rd party seller didn't provide Amazon with the cardboard HDD box they received when they originally purchased the drive, then I wouldn't trust that hard drive; even if Amazon did a great job of packing the drive (which they obviously didn't in OP's case). The problem is that you can't really know what state that hard drive was shipped to Amazon in. 

The 3rd party sellers could have put the bare HDD in a giant shipping box that was packed from top to bottom with bubblewrap, but for all we know, they sent the HDD to Amazon's distribution center in a padded envelope. Regardless of how well (or poorly in OP's case) Amazon packages that HDD they received, I wouldn't trust it, which is why I don't buy from 3rd party sellers.

When I buy direct from Amazon, I'm getting the merchandise that the manufacturer sold to directly to Amazon, which is why all of my hard drives come in those HDD boxes, same as if I bought them from WD, Newegg, or elsewhere. I know from start to finish that there's a certain standard that is being maintained, by the manufacturers and then by Amazon.
Are you guys buying these hard drives from sellers other than Amazon? 

I've seen plenty of folks on this reddit complain about bad HDD packaging from Amazon (and quite a few with pictures like the one above), but every hard drive I've gotten from them, over the years, comes in the same packaging as drives from WD or Newegg. [It's these small, individual hard drive boxes](http://i.imgur.com/i4UdQ6x.jpg), inside of a shipping box with with Amazon, WD, or Newegg logos on them.

I've probably gotten a dozen hard drives from Amazon over the years, never had any of these kinds of issues; but I only buy direct from Amazon, never from 3rd party sellers. 
Maybe in a later update they can prioritize the Bixby cards app, so it's always in memory, and runs updates more often so it's ready to go at a moments notice.

Granted, I don't know if I want that or not yet. I won't be buying an S8, and I am pretty excited to see what Bixby is capable of, now that Samsung has the Viv team working for them (folks who were well ahead of Google Assistant/Now, at the start of 2016), but I don't know if I'd want Bixby running all the time in the background and using resources.

I'd be fine with a short delay, so long as it meant Bixby cards wasn't using CPU cycles in the background. On the other hand, once the Bixby voice part comes out, that better be instant.
1. I think it's worth the 15 dollars. I use it only for Plex Cloud, and for the last couple months it's worked out well. 

2. I just checked my own admin account, and I can't find any way to see people's IP addresses. I can send a password reset request, suspend or delete an account, and I can see when they last logged in (and some general activity information). I could be missing something, but I don't think they can see your IP address. Of course Google will know your IP, so I use a VPN and take other precautions to prevent Google from linking my accounts together.

3. I bought it at night, around 10pm, and I got my log in info around 5am the next day. Just send them what you want your name and username to be, and they'll send you your password information via ebay messaging. 

Just to reiterate what I said earlier, I wouldn't trust this account with any sensitive or important info. These ebay retailers are basically people who set up a fake school, and then sell accounts. If you want an account for backups or storing your data, I'd get a business GSuite account or an ACD account. 

Also, since they are setting up education accounts, it costs them nothing to make a new account. That's why I wouldn't ever worry about them 'holding your data hostage'. A bad review about them holding someone's data hostage will cost them more than they could make by exploiting their current users.
You can change them whenever you want and add 2 factor authentication. I've changed my passwords a few times now, and gone through the reset process without issue. 
They can set your password to reset, but that would send an email to your backup email account (if you set one up), allowing you to set up a new password. 
Not a scam. The guy has been selling them for a year now, I think. I was worried about it being a scam so I checked the person out before I purchased as well. 

Anyways, I wouldn't be surprised if they got shut down, but short of that, it seems like a decent investment, especially for plex. 
I think you can replace the drives 1 at a time with 10TB drives. You just won't get that extra storage space until the last 8TB drive is replaced with a 10TB and you run some kind of expand function. 

Thats what I've come across when reading the synology forums anyways from people who used traditional Raid (non-SHR). 
I don't know if this is true for this particular WD My Book, but for the 6TB one that I bought the other day (comes in those new My Book cases), it has a couple of internal tabs that usually break when you remove the internal drive. From reading online, the only purpose those tabs have is for telling whether the drive had been removed or not. 

I don't know if that means they'll reject the warranty or not, but I thought this was something worth noting. 
Wisconsin.
This model and the newer version both contain archive drives. 

So, if that's what you're looking for, then it works out well. I wouldn't stick them in a NAS or anything like that though. A friend lent me their the newer version of the model you linked, and the write speeds were unbearably slow. I knew it would be slow, but I underestimated how slow it was.
Personally, I use an account I got from Ebay with the Plex Cloud thing. One time payment of 10 dollars and it's easy to use. 

But I don't necessarily trust that account either. I have a GSuite account for 10/month that I use to backup and house all my important data. 

Buying a domain isn't hard. It's basically like any other online shopping. Go to the site, search for a name, place it in your cart and buy. Godaddy.com or namecheap.com are good places to start. You can get some of those sites for a couple dollars a year. 

The configuration for GSuite threw me for a loop at first. I copied a segment of code from Google's GSuite setup page, logged into the site where I purchased my domain and pasted it into one of the configuration boxes and hit update/save. I basically repeated that process until I eventually managed to paste it into the correct box and Google was able to verify my site. 

If you don't want to go the trial and error route like me, I'm sure there's guides or YouTube videos on how to set up a site with GSuite. Search for something like "Godaddy GSuite setup" and you'll find everything you need to know. I think Google has their own instruction page for setting up godaddy as well. 

i7 should be fine for transcoding multiple (non-4k) videos to your users. Plex + OS isn't going to use up 16gb RAM, so you'll have plenty left over for Chrome to eat through. If you're serving up media to your users, then Plex would be a good interface for them and it'll prevent them from making any unwanted changes to your files (read only).

If you don't care about maintaining uptime (RAID), then I'd probably run storage pooling software like DrivePool or Windows Storage Spaces to make it easier to manage content across 6-8 disks. 

Another thing to consider is using something like Unraid as your primary OS and then use Windows as a VM on top of that. This way you can avoid any downtime that would be caused by using a traditional dual boot system (shutting down the server OS to boot into Windows). I don't know if your hardware supports it or not, but with KVM (which is what Unraid utilizes) or ESXi virtualization you could achieve close to bare metal performance on your Windows VM (if you need that kind of performance).

I don't have any experience with Unraid, KVM or ESXi, but I've started to read up on them because I want to create a build around that tech.
I don't know, and they didn't start doing that until after Android 7.0 came out. In theory a lower resolution should make a slight difference (if you consider processing power alone), which might be why they did that to begin with, but the 3rd party testing showed the difference was negligible.


If you have Spectrum, and depending on where you live, they might have a faster, unadvertised plan available in your area. 

In my area, Time Warner became Spectrum a long while ago, but it took them until last November before they finished the rollout of their 60/5 speeds. Once they finished their 60/5 rollout, a new, unadvertised plan @300 down/20 up, became available for 110/month + $200 installation fee. Since it's unadvertised, I only learned of this plan from a random user/comment on reddit.

You can ask their chat support if it's available to you, but you have to call in to get it. 

You may have to try more than once because out of the 3 chat sessions I had, one of them said it wasn't available in my area, and the first person I called didn't know the plan existed and insisted that only the 60/5 or old Time Warner plans were available. The second person I called knew exactly what I was talking about, confirmed it was available to me (which makes sense because there was a thread full of people near me who said they got this plan), and was able to give me prices.

Unfortunately it's too expensive for me, and I have no other options (which makes negotiating a better price difficult), so I'm stuck with the amazingly low 5mbps upload speeds for the time being.
The 1080p vs native resolution made very little, if any, difference in the tests on the S7. I think early reports say it's the same on the S8. 

But the S8 will display at 1080p by default unless you're playing games or watching videos or doing something that would look better in higher resolution. It's not something you need to manually deal with unless you want to.

Either way, I'd never put in the effort to turn off location services or mess with the resolution. After the 7.0 update came out, I changed the resolution back to max, and haven't touched it since. 
They probably can't make any major optimizations without changing the hardware, but they might be able to optimize it to a smaller degree. 

After the Note 7 died, they brought some of its AOD features to the S7. After that update, I remember Samsung emphasized that the AOD display would now operate on less than 1% battery/per hour.

I don't know if they can optimize it further than they already have just on the software side (maybe they'll push out AOD faces that use less pixels?), but it could be possible that they'll do something similar over the lifespan of the device.
Yea, I've been using Radarr to assist me in upgrading my collection. If it kept track of codec information, then I could go ahead and have it rename my library.

A better route (in case I ever stop using Radarr and move to another application), would be to make a database and keep all the relevant information in there, so I can keep my library nice and organized. But I'm too lazy to make something like that.

Edit: Might have spoken too soon. I think I've found a tool that will handle all that for me.
Yea, I did the same thing. Uninstalled the battery drivers, rebooted, downloaded and reinstalled them, rebooted, tried a force shut down, etc. Nothing seemed to fix it until I booted into the bios, which just seemed to magically make it start working again.
You'd have to pay for the VPS service who will act as the intermediary between your Google and Amazon accounts. You wouldn't be paying anything extra to Google or Amazon. 

I don't know how much any VPS costs are since I've never had to use a VPS (I'm also on my phone, otherwise I'd look it up). 

Since the VPS only acts as an intermediary for your data, you could do the same thing for free with your own computer. It really depends on what your Internet speeds are and how long you're willing to wait for the transfer to finish. 
Those accounts are technically education accounts. Someone sets up a fake school then they sell accounts to people. Or sometimes an administrator at a real school will sell extra accounts on ebay. 

Either way, I imagine Google will only contact the administrator if they plan to shut down the account. Whether the Admin tells you or not, I don't know. Also, I imagine they will only shut down accounts of people who set up fake schools, not the extra accounts on real schools. 

I'm just saying that it could happen. I don't know if it's ever happened yet. Some of those ebay sellers have been selling accounts for upwards of a year or more now. 
Are you talking about their cold storage options, or cloud computing/AWS type things? 

Consumer/education/business versions of Google Drive and consumer versions of Amazon Cloud Drive operate on a fixed, per month cost. You don't pay extra for downloading data or anything like that. You can upload, download, or transfer data to other companies as much as you want without paying anything extra. 

That being said, it is cheaper for Amazon (or Google) if you only upload data to their servers or keep the data within their internal system. As I understand it, it's less cost efficient for them to send data out of their system, but they don't charge you for that. 

Now, both companies have other services, like cold storage and such, and those models operate on a per usage cost (pay X for X amount of data storage, and pay X amount for X bandwidth in or out). 
You can buy unlimited Google accounts on eBay for a one time payment of 10 dollars. 

Google could shut down those accounts at any time, but they seem to work thus far. I've had one for a few months and haven't had any issues, but I'm not relying on it as my primary online storage account. 
http://www.windowscentral.com/generate-battery-report-windows-10

That gives you a pretty comprehensive report on all things related to your battery, it's built into Windows so you don't need to install anything. I run it about once every 2 months and have it set to go directly to my onedrive so I can keep track of the reports.

I don't know how it compares to other battery apps, but I loathe installing anything on my computer, especially things that run all the time, because all of those little apps can add up to be a drain on resources. 
Gotcha, thanks for the info. When I expand my storage capabilities, I'll be sure to pick one of these up.
That's good to know. I was looking at those too and debating whether I should use an application like Drivepool, but sounds like I'll be going with the raid option then. 

Thanks. 
Don't know if this will help you at all, but I keep certain folders on my Nas and USB drobo box synced up, over my lan, using a free application called [DirSync Pro](www.dirsyncpro.org). 

It can be set to run as often as you want (on a schedule), but my data doesn't change often enough that I need to have the application on a schedule. I just run it manually every now and again. For my purposes it works great, and as a bonus (to me anyways) it comes in a portable format. 

Last I remember it had Linux, Windows and Mac versions. 
How long have you had the Mediasonic boxes and do you like them? Do you know how a failed disk replacement process is on those (press a hardware button to start a rebuild after replacing a failed disk?). 

I've been looking for a cheap(er) way to have a solid backup of my Synology Nas and having multiple of these boxes plugged into it might be the best way to go about it. 


I haven't used CloudDrive in a while, but when I used it, they let you mount your drive on a second computer if you really wanted to. There was never a good reason do to that though, because you'd be risking corrupting your data (and corrupted data isn't very useful to anyone). 

To get around this and use the data from the drive on multiple computers, you can do what I do, which is to set the drive up as a network share (which is quite easy on Windows); or there are 3rd party tools to sync data over the web if your computer with the mounted drive isn't on the same network as you. 
Unless they come out with a way to have a 'read-only' drive, it's not possible to mount a drive on two computers without risking data corruption. This is because their system isn't file based like other providers (netdrive, expandrive, etc), and instead acts more like an actual hard disk (the chunks act as sectors/clusters and the data is written on top of that). 

It's similar to the way Veracrypt file containers work. If you need to have 2 computers access the same encrypted file container, you must mount them in read only mode, or you risk data corruption for the very same reasons. 

TLDR: 2 computers writing different data to the same chunk, or the second computer overwriting an older chunk with new data = data corruption; making your uploaded data useless.
Yea, that used to be all they checked and there were lots of apps to help mask your browser agent and allow you to tether without using the official hotspot app. 

I don't remember where I read it, but I do remember reading that they (carriers in general, not specifically T-Mobile) did some level of packet sniffing (packets being routed to websites/services only a PC can use; ex: using Steam or Windows checking for updates), and port checks (ports that wouldn't commonly be used by phones), etc.

I don't know how much of that applies to T-Mobile specifically (or if any of it does), but I imagine they check more than just the browser user agent now.

Using a VPN might help you get around some of those issues though. It would prevent them from sniffing your traffic or scanning for which ports you use. I don't know if that would enough, but that would help.
That's still pretty good. In a city of that size, I'd guess the ratio of T-Mobile customers to towers is very much in your favor. It certainly explains why you have good speeds despite being a heavy user.

And I'm glad they got rid of those HD passes. That was an idiotic move on their part. When they came out with those One plans, the HD passes, the throttling, the extra costs, all made the Simple Choice an easily better plan. Only new customers were screwed because they only had the One plans available. At least now it's not so bad for new customers.

Edit: Don't know what happened or why this ended up replying to my own comment and not the other one.
They'd probably tell you to download your excess data before a certain date, prevent you from uploading anything new, and then possibly suspend your account if you don't adjust your usage within a certain amount of time. I don't think they'd delete your data outright though, even if you go too long without deleting your excess data.

But of course, people have been saying that they might enforce their policy for years now. It's true that they could start at any time, but they've already gone this many years without doing it.

For consumer plans, like the 100gb plan, once you go over 100gb, they prevent you from uploading anything new until you delete something first. That's what I've been told anyways. I don't know how that affects gmail though, since it uses the same storage space as your G Drive.
Huh, that's pretty impressive. Do you live in an area without many T-Mobile customers? They were pretty clear in their TOS for their One plans that they would deprioritize anyone who uses more than ~26-30gb. That's on top of their automatic deprioritization of all tethering traffic below that of on-device traffic so it doesn't affect other customers. And they have a clause in their TOS that says that using tethering an extended period of time would lead to them contacting you discuss alternative pricing/options. 

Anyways, the throttling is one of the reasons I didn't get the One plans when they came out (also because I'd have to pay extra for HD video and then activate a pass everyday that I wanted to see HD video). They tried throttling heavy users with unlimited Simple Choice plans, but ended up getting fined by the government for trying to pull that. That's why they were so clear cut in their TOS for their T-Mobile One plans about where they'd start throttling people's data. 

If you live in an area without many T-Mobile users, then it seems like you can use all you want and not have to worry about suffering slow speeds.
This is what it is. According to the Plex support page (I read it a while ago when I was having the exact same problem as you), the Xbox doesn't support a wide range of audio codecs. 

It does support many common codecs though, like AAC and so on.
Oh, sorry. If you don't count throttling, then all of their plans (and the tethering portions of that plan) are unlimited.

For me, once they start throttling it basically means it's time to turn off the computer, because trying to do anything more complex than emailing (and I have to use the simple gmail client at that) is just an exercise in frustration. I'm not a very patient person.
I am on an unlimited plan, but T-Mobile has a limit on how much tethering data you get. I think it's the same for all US carriers who have unlimited plans. 
Yes, for the last several years they haven't checked that. So even if you only have one account, they will let you go over 1tb
I imagine they want to avoid having to pay extra for tethering. I've done it a few times where I'd download large files on my phone and then just transfer it to my laptop, rather than blow my entire tethering budget on one file. 

I downloaded a Windows VM (15gb) onto my phone when I was travelling and that would have used my tethering budget a few times over. 

I can't ditch my laptop, but there's a huge population of people who use their phone as their primary and only device. 
Cool, thanks. I'll check it out.

I hope they eventually get around to fixing the Windows 10 app, but only because it's easy to get family to use that app. If I tell them to go to the windows store (or Google Play store, or iOS app store) and download Plex, they'll do it. If I tell them to go to plex.tv and download/install something, they'll put it off until the next time they see me at which point I'd end up doing it for them; regardless of how easy it is to install/use.

I don't know why it works that way, but it just does. 
I'm certainly interested, regardless of the storage format. How were you planning on sharing them? 
Gotcha. Up until now I never considered ripping my own DVDs/Bluray disks, and it was mostly because I rarely had enough space for anything. I used to go in the opposite direction and download the smallest HD files I could, which seemed ok at the time, but after having played them on a larger 4k TV, I knew it was a bad choice; especially since the Netflix stream of the same video was much better.

I'd have to buy a DVD/Bluray player for PC, but I think ripping the movies would be easier than redownloading all of them one by one. Thanks for the info.
Gotcha, that would definitely work as well, and save on disk space over what I had been doing in the past. 
When it comes to doing your own rips from DVDs and BluRay, does MakeMKV give you options on compression/conversion of the video/audio streams? Or is that something you have to go back and do later with a different program?
Perhaps Radarr will do the trick?

I haven't used it personally, but (after some quick googling) it seems to have a rename option of some kind, which would automatically rename movies for you.

I do use Sonarr (Radarr is based off of Sonarr), and it has a renaming thing, which lets you rename entire folders of tv shows easily.
I do the same, except I keep the original folder name of the release. Just so I know what quality and which group did it (so I can see what movies I need to replace/upgrade at a glance).

So it's 
    
        Media/
        ├───Movies/
        │   └───Rogue One A Star Wars Story (2016) 1080p DTS 5.1 SomeReleaseGroupHere/
        │       └───Rogue One A Star Wars Story (2016).mkv
        │       └───Rogue One A Star Wars Story (2016).srt
Just curious, but for movies that include external subtitles in the download, is Radarr capable of grabbing them and moving them over with the video file? I know Sonarr can't do this yet (it's a work in progress in their beta version), but I don't know how different Radarr/Sonarr are. 

Not sure if you ever have to deal with that sort of thing, but I like to keep subtitles with all the movies/shows I get.
I have the same issue with the default app icons all being the same (if you use the default MS apps anyways). I don't really consider it a big enough bug to be worth the hassle of resetting my device.
HTTPS is nice and all, but it can't stand up against the almighty secret warrant from a secret court. Although I guess that's not really the HTTPS at fault in that situation. 
Oh, it's just a euphemism that is used on this reddit. Linux isos usually means less than legal materials like copyrighted materials (movies, TV shows), or stuff you don't want everyone to know, like if you had 10TB of porn and didn't want to publicly admit that. 

Although downloading certain Linux isos, like cyborg hawk, tails, or kali may get you put on a list. I remember reading the NSA used to put people on lists for Googling encryption and apps related to it. Don't know if they still do that or not, but I'm guessing they'd want to watch those isos too. 
Yes, I just meant something like PIA.

I'm not sure how secure remote access to your NAS via VPN (like openVPN protocols) would be vs their built in QuickConnect feature, but the VPN does the bring the added benefit of being able to access your home network (printers, computes, shared folders, etc).

Otherwise, for normal login within your home network, you can set up 2 factor authentication.
Just curious, but how is your system set up when it comes to scanning for content? Does it just run every few hours to look for new posts or something?

I'm just wondering if your database would have all those deleted comments that I see on posts that hit the front page.
I just use the VPN to keep my internet activity private, which I think is a generally good idea if you're downloading linux isos. 

If you're interested in doing it the other way around, you can set up your Synology NAS to act as a VPN server as well. 
I have the DS916+ (8gb) and I've been quite happy with it. I bought it with Plex (transcoding) in mind, but just about every device I have (phones, tablets, rokus, smart tvs) can handle most of my media library, even x265 videos, on direct play. Only the Plex app on PC and on the Xbox One give me issues and require lots of transcoding, so I don't really use either.

Transcoding can be hit or miss because Plex doesn't fully support hardware transcoding on Synology devices. A 1080p, x264, transcode will use 90-95% CPU on Plex, but will only use 30% on an optimized app (like Video Station). Most of the videos I've needed to transcode worked fine (in Plex), others didn't (choppy playback). My old plex server, which was my old laptop with an i7 (and has a much larger power draw than the DS916+), wouldn't be able to smoothly transcode some of those videos either.

Other than Plex, I have VPN set up, Sonarr, Download Station (which is a great app that I use all the time, and it can handle torrents, usenet, ftp, http downloads, etc), and Cloud Sync, which will backup folders to your cloud storage provider (and has optional encryption settings as well). 

With this set up, I'd never need to manage my NAS at all. Sonarr would automatically find the torrents I want, send it to Download Station, then move the completed downloads into my media library. At which point Plex would automatically index them, and Cloud Sync would back up any new files to my cloud storage providers. It's about as hassle free of a situation as one can get once it's all set up. Only thing I'd have to do is change out hard drives if one ever fails, or if I need more space (which I'm in the process of doing).
Treesize. 

It can find duplicate files by comparing checksums. So if you're talking about photos that are similar to eachother but not exactly the same, then it can't find it; but if you're talking about duplicates (like the file got copied one too many times), then it can find every duplicate.

It find and selects all the files automatically and offers to make all of them hardlinks, but that doesn't get rid of the duplicates, just makes it so they don't take up any extra space on the hard disk. I like to go ahead and uncheck the files I want to keep (like a photo that is organized in the proper folder) and then select all the others and press the delete button.

Just keep in mind that it automatically selects all files after it finishes searching, so don't hit that delete button without finding the files you want to keep and deselecting those first.
At the bottom, there's two buttons. The left is for news and stuff, the right is for updates relevant to you. 
I guess I wouldn't know. None of the apps I use are intensive or large apps, so my S7 usually keeps everything I need in memory (messaging apps, video apps, music, internet, reddit apps, etc).
If your primary applications are mremote and similar applications, then I'd imagine the internal gpu should be capable to handle your needs. So you can leave hardware acceleration enabled, but don't have it set to use the dgpu. The intel gpu does use shared memory, so it would use your RAM (unlike the dgpu which has a dedicated 1gb), but in my experience it doesn't need all that much to render a Windows 10 VM and a few applications.

In case you're interested (I was so I checked it out), a Win 10 VM with 4gb of RAM, running a few background applications and tabs in Edge (to use up some of that 4gb), and then running a 1080p video from youtube in fullscreen caused my computer to from 5.3gb (no VM running) to 10.2gb in RAM use.

So I'm assuming somewhere in there, the intel GPU was using up to 1gb in RAM to run that video.
I use VMware Workstation (12.5) on my SB, and have hardware acceleration enabled ("accelerate 3d graphics"), but it's never attempted to use my dgpu and I've been able to run VMs while the SB was in clipboard mode. I primarily use a Windows 10 guest and once I install Vmware tools, it automatically has the guest's scaling match the host. I've never had to manually specify scaling in the guest Windows or Vmware (not sure if I can modify it beyond turning automatic scaling on or off in Vmware).

The mouse/keyboard becoming unresponsive (in both the guest and host) is an issue I've run into with VMware as well and I'm not entirely sure why/when it happens. I haven't really found a graceful way to deal with that other than to hold down the power button until the SB reboots (that's only if the touchscreen isn't working and I can't shut down that way).

I haven't had any issues with my VM crashing outright, and in most cases (excluding load times for apps) the guest handles as well as my host OS. So jerky mouse isn't an issue for me.

A separate issue that I've come across is that if you go into clipboard mode while a VM is running, it seems to capture your mouse and keyboard when you dock, making it impossible to interact with the host (even all touch input gets directed into the guest) until you shut down your VM.
Yes. I think it was one of the complaints people had about the S7, was that it didn't keep enough apps in memory.

So it seems they've made major improvements in that area.
I didn't know that they were uncommon. I thought bad sectors was a common problem that disks racked up over time, and that near the end of their life, you'd see a drastic spike in bad sectors. I'll keep a lookout for errors though. 
Ok, and makes sense. I'll probably look into utilizing the drive elsewhere then.
Ahh ok. I haven't been able to get student pricing since my old college email accounts were discontinued. 

I had no idea it was that much cheaper on there. 
How are you getting those prices? I've been buying the 16TB My Book Duos, because that's the best price I could find for 8TB (non-SMR) drives (especially the best price I could find on 8TB Reds). Since the My Book Duos normally retail at 500, that comes out to about 31.25/TB.

The only time I had a better price was when I managed to get a 4TB Blue drive, a couple years back, for 30ish/TB.

At 190 for an 8TB Red, you're paying way less than I can find for even 6TB drives or even 8TB SMR drives.
I'm totally unfamiliar with using this kind of thing, but I'm assuming that if I change these settings on my drive while it's plugged into my computer, that it should carry over just fine to my NAS?

I don't think there's anything on my NAS that would mess with this setting in any way; I have HDD hibernation enabled after 20 minutes, but that would be well after the 300 seconds anyways.
I've never had to RMA any of these drives, and out of the 5-6 WD Green drives I own, only one is still covered under warranty. 

Anyways, since you seem to have some experience with Green drives, do you recommend using -d to disable it altogether or just set it to something higher, akin to the WD Reds?
I'm just kinda surprised that I don't see more faulty sectors in the SMART data since I've had this disk running for about 2 years (according to the power on time). I'll be sure to put this back into my NAS (in an expansion unit) as soon as the rebuild finishes. Thanks.
Not really sure. I haven't messed or changed any settings on the drive using any kind of low level tools at all. I don't think there's anything on my NAS that would change settings like these on the drive.

Either way, that's a good explanation as to why my NAS might have considered this a failed drive.
Yea, someone else had told me to do the same with my Green drives, but I didn't get around to it.

If it's a mechanical failure instead of a magnetic one, does that mean SMART is less likely to display the normal warning signs before HDD failure (like a high relocated sector count)? The drive might fail with less warning?
Do you use them in external drives, or have it in a RAID/JBOD config or something like that?

I've only ever considered using those drives as a backup, but using it to hold a media library would be a good use for SMR drives.
Ok, I'll try that out as well. Pausing for a long time is something I do as well, I didn't consider that until now.
Cool, thanks. I'll have to try out similar settings and see if that helps me.
Just curious, but what are your upload and download speeds?

I own a copy of Cloud Drive and think it's a great piece of software, but the last time I used it (a while ago), I was having issues playing a ~4-8gb, 1.5 hour long video. That was playing directly on my PC in VLC. My internet connection is about 65 down and 5 up. What settings are you using that you can get it to run well with Plex and streaming videos?
I've had 2 Note 7's as well and didn't have issues with either; maybe my eyes/face are just iris scanner friendly since I do seem to have a better experience with Windows Hello than some have as well. There's 4 S7s and 1 S7e in our household (all SD), and they all seem to be the same when it comes to reading/processing the fingerprint. I wouldn't say it's an issue since it works at the speed you see in youtube videos (which I assume means it's normal), but then again it might be faster on Exynos phones. Either way, it was nearly instantaneous on the Note 7; a quick tap is all that's needed, unlike the S7 where you need to keep your finger on the home button after the initial press in order to get logged in.
I guess my experience might be flawed then. Maybe I just had an exceptional iris scanner on my Note 7 (coincidentally, I also have a great experience with Windows Hello as well) and maybe my family has lousy fingerprint readers on their S7s (none of our phones come close to being instant, especially not as fast as the the Note 7's fingerprint reader). 

Either way, using the iris scanner never felt like the hassle you describe it as. I never really had to worry about the angle or anything, since I usually use my phone at an angle that's mostly parallel to my face. I rarely use it at any odd angles unless I'm using my phone on a stand, or if I'm checking for scratches. 

If the iris scanner was that much of hassle, and it took that long, maybe you had a bad sensor or it wasn't properly trained in different lighting conditions. 
I never had any problems like that at all. It was incredibly fast for me. The only reason the fingerprint scanner was faster was because it would unlock the device in the time it took me to press the home button to wake up the phone. 

But in my experience, the iris scanner was faster than the S7e's fingerprint reader. 

I used my finger to unlock my phone most of the time, but I used the iris scanner for everything else (it's just convenient, since you're already looking at the phone anyways). 
Really? My family all bought S7s on release, and they received their gear VR with their purchase, right then and there. 

I bought the Note 7 and I had to wait a week for mine to be shipped to me. 
It was, but that's how large companies operate. What do you think Siri was to Apple, or the dozen startups that Google has bought to bring to Android (ie: a watch OS start up, an Android performance startup, etc)? Buying out start-ups is a daily occurrence in silicon valley.
Man, I'm slow today. I was trying to figure out why someone would need to use Lastpass in Android Auto, until I realized you were talking about the app fill feature. 
It all depends on who you're trying to keep out of your phone and how much effort you're willing to put in. If you're trying to stop the NSA, then it would obviously be beneficial to have a pin at boot, a long password, no biometrics, etc.

If you're only trying to keep out your nosy friend who has a habit of going through your pictures when you get up to grab your coffee, then all you need is something that deters them long enough for you to get back. It'd be enough to just have a pattern they won't guess on their first couple tries, or facial recognition which would require them to plan ahead, and have a photo of you ready to unlock your phone.

My sister is the latter, and I'm guessing someone could break into her phone within ~10 tries, if they were determined to get in.
The 4TB My Book Duos are still in stock...

Unfortunately, the only ones I need are the 16TB ones, and every other large internal/external drive seems to be out of stock. I feel like I'm not gonna get a chance to use this deal before it expires. Here I was all excited that I might be able to afford to expand.

Edit: They have some larger, non-Red drives available.
That's a nice trick.

I've been using Internet Download Manager for a while now (fantastic, and very versatile tool for Windows), and in the past, I'd just copy and paste links into a txt document manually. I never knew about anything like Linkclump; this would definitely help.
Isn't it just an application that sends your backup to a cloud provider (like Amazon)?

Doesn't make sense to me either why they'd have a hard limit on the application itself.
I knew there were apps out there that would pay you to view ads on your lockscreen (I used to have one, but you made money so slowly, it was just too much of a pain to bother), but I didn't know apps could do that without it being the express point of the app. S Photo Editor doesn't sound anything like an app who should be able to do this kind of thing.

Google really shouldn't allow this.
From the video I watched (the other day), it sounded like they wanted facial recognition to be faster than iris scanning. On the Note 7 (in my experience), the iris scanning was pretty damn fast once it learned your face/eyes (best to run it in different lighting scenarios), and it would take less than half a second once it saw your eyes.

So if you want facial recognition to log in faster than that, you can't really implement security features people use to mitigate this type of attack (ie, asking the user to blink, or asking them to rotate their face to prove it's not a picture).

It doesn't sound like facial recognition was designed with security in mind, as much as it is about ease of access.
It's not a gimmick, it's just meant to be a quick way to log in. Kind of like when someone uses a really easy and obvious pattern/pin to log in. They aren't that concerned about security as much as they are with the ease of access.
Yea, from the way the feature was explained to me the other day, it seems like facial recognition was designed to be the fastest way to log in (aside from fingerprint); and not necessarily with any kind of focus on security.
That's very true. But security isn't about being unbeatable, it's about making life difficult enough for the adversary that it isn't worth the trouble. 

If it can prevent identical twins from getting access, I think that sets a pretty good bar.
Honestly, it seems silly not to use IR if they have the ability. But the impression I got when reading an article about the facial recognition, is that they wanted it to be the fastest way to log in, so maybe using the IR, (whether it's to get a good read, or to process the data) took too long?

Either way, from the way it was explained, I never planned to use it.
I'll have to check those out. Thanks for the tip.
Yea I know and that's the problem. It shouldn't be up to the developer to add support for this feature (because some developers might benefit from not adding in that feature, like if you make in app purchases and lose progress, you might be willing to buy them all over again), it should be handled by the system so Google can offer the user a seamless upgrade/restore experience (the kind people experience on iOS). Not every app is the kind of app that needs its data to be backed up (ie settings apps or apps that modify the system), but really it should be done regardless. Perhaps the best way to address that is to use a system like the one on the Note 7, where you could select which apps you wanted to have the apk, app data, and/or app settings backed up. Unfortunately the S7 doesn't allow you to specify which apps you wanted backed up.

Anyways, until Google brings that feature to stock Android, I'm glad that Samsung is there to pick up the slack. Android really needs to be more user friendly because the vast majority of people who aren't going to root their phones to use an app like Titanium Backup.
It's decent stuff. :)
Package Disabler Pro - > select "Calendar"

Or com.samsung.android.calendar if you have more than one app called Calendar on your phone. 

You don't need the pro version, but the app goes on sale often enough (I got it free back in November, I think). 

There are others that let you disable system apps on Samsung phones without root as well.

Edit: I think you can disable most things except the core Knox system apps. IIRC, most of these apps use the Knox API to disable system apps without root.
:( Don't tell anyone, this is a secret, but I would have done it for free (but then he'd have to buy his own app). I'm a terrible businessman. 
That's totally fine. You shouldn't buy a gaming computer if all you're gonna do is use it for facebook. Buy the device that works for you and for your budget.

The fear of Samsung becoming more like Apple has never made much sense to me. People have been complaining about that kind of thing since the early days of Android, and saying Samsung blatantly copied Apple when they started using premium materials (because people seem to think that Apple has a monopoly on using premium materials). If that's the case, then every manufacturer has copied Apple in that way. 

Outside of their hardware changes, I've never seen anything that justifies people's fear of them becoming Apple. Their OS operates the same as it always has; easy to modify/change/disable, like any Android phone they've ever made (although, because of security features, rooting isn't always available the same day the device is released). It's within the realm of possibility that Samsung will try and copy Apple in every way they can, and it's also entirely possible that Google will decide to abandon the openness of Android and pressure partners into using a locked down OS. I honestly do not worry about either of those things coming to pass.

If you don't like the ease of use features that Samsung offers (like a more comprehensive backup; which should be something that's built into stock Android) or features to help with productivity, then don't use them or disable them. All Samsung does is offer people more choices than they would have had otherwise, and if anything that's exactly what the open nature of Android is all about: choice. I don't really see how any of that makes Samsung nothing more than an Apple wannabe (especially since most of the things Samsung adds, are things that won't be integrated into stock Android for years to come and even longer before they're put into iOS). 

If Samsung decides to lock down the OS in the way you claim you're worried about happening, then it just means my next phone won't be a Samsung phone. Luckily, I don't need to worry or consider what a company might do 5-10 years down the line when I'm purchasing a phone today.
Really, that kind of thing shouldn't be left in the hands of developers. It should be done by the system regardless of whether a dev decides to put that functionality in their app. Not all apps need to have their data saved (which is why it was nice when Samsung allowed you to select which apps you wanted to back up in the Note 7, but I don't see that feature on the S7), but it's the kind of thing that should be done automatically unless unchecked. 

There are developers who directly benefit when your data isn't saved, and that's especially true for games. When I moved from iphone to Android, I lost all progress on one of the games I played, and I bought in game currency to catch up. But unlike iOS, your progress isn't saved when you move from device to device on Android, so when I upgraded my Android phone, the expansions I bought were still available, but the in game currency and progress were lost. 

I don't know how hard it is for Google to implement that kind of feature, but in the mean time, I'm glad Samsung is picking up the slack. Especially now, since I'm too lazy to root my devices.
I don't think making an (optional) account makes them a closed off system. Samsung's android is about as closed off as Google's phones. Google's phones come with the same level of bloatware as Samsung phones (pre-installed browser, text message client, email client, calander, picture/gallery, etc). The only difference might be the MS Office suite, but I didn't have that on my S7 Edge. 

But seriously, they ask you once to log in or make a Samsung account when you set up the phone. You don't have to. My dad switched from iphones to Android, and he never made an account (he only used his Google account) and has never been nagged or had a single issue from not having a Samsung account. His experience on Android is not diminished in any way from not having a Samsung account. 

The only point of making a Samsung account is that it makes android easier to use when you reset or change phones (in that it offers a more comprehensive restore/backup that supplements Google's restore/backup, it doesn't replace it).

Anyways, it's very clear you've never used a Samsung phone. You make it sound like they are running an entirely different or locked down OS (just fyi, TouchWiz is just a skin that offers some additional features not found in stock Android, not some closed down android system). You don't have to use any of their apps, and they aren't preventing you from using other apps. 

The only thing you got right is getting locked into their ecosystem. When you leave Samsung, you risk getting an inferior experience if your phone doesn't have wireless charging, waterproofing, WiFi extenders, Samsung Pay, SD cards, and other such features. If other phones offered the same hardware and software features as Samsung, then people could easy switch phones and not miss out on anything (and now that Android has multi-window, we're one step closer to that). But if you don't use those things, then there's nothing preventing you from switching to another phone and being perfectly fine. 
Right, the same backup is there on Samsung phones too (I only use the Samsung cloud feature to supplement the Google restore). But when I've used Google to restore my phones, it usually needed me to log into my accounts again, like Twitter, Facebook, I'd lose my progress in games and such (which isn't as big of a deal since I don't play as often anymore). 

With the Samsung one, the only thing I needed to log into after a restore was my Google, Samsung (both of those during the initial phone setup) and Lastpass accounts. I still lose progress in some games, but it seems to do a better job. 

Titanium backup and such solutions are still the best options available, but i think this helps bring us closer to that for non technical users. 
Well it makes restores and moving to a new phone easier since Samsung backs up all the stuff that Google doesn't (app data, accounts, and phone settings for example). It feels much closer to the iPhone experience of switching phones or doing a restore. 

Either way 100 dollars is a lot. Samsung only ever asks you to log in once when you first start setting up the phone. If you'd like, you can pay me that 100 dollars and I'll disable every Samsung and Microsoft app that I can, and I'll press "skip" on the Samsung account log in page, during the initial set up of your phone. 

For 100 bucks, I'll even throw in a license to a paid app, and lessons, on how to disable apps (without root on Samsung phones), so you can do the same in the future. 
Normally I find tech ads to be dull, and repetitive, but this one is fantastic. 
Yea, it kinda goes that way in a lot of companies that actively innovate. Some companies only pick a project or two, and focus on that until they're done (ie Apple, who brings things about slowly, like Apple Pay, Maps, imessage etc), whereas Google and Samsung will try to do a little of everything and sometimes the wrong projects get the ax. Certainly frustrating when good projects get tossed aside though. 
I don't plan to get the phone, but I'd be surprised if they a manged to make their Internet app (which is the name of their browser) worse than Chrome in the S8. 

Edit: It was poorly worded, but I was trying to finish the comment quickly so I could move onto something else. 
I guess it could be viewed as desperate, but innovation has served them well (as they've captured a huge share of the Android market), and I'm glad they are at least attempting to innovate and compete. Frankly, any company who tries to compete in an established market can be viewed as desperate, but competition is what drives the industry forward. 

Not every attempt, by every company, will be a home run, and that's part of the process. Allo, Duo, Google+, and just about 90% of Google projects are good examples of this. They are trying to compete in markets against well established players, and we could call that "desperation" but I'm glad they chose to try and compete. Many of those projects were lacking compared to competitors at first, but they've grown to include lots of great features (even though it was too late to capture a share of the market). 

In a market that has only 3-4 players (most of whom are crippled on Android since they aren't built into the OS), a new player is more than welcome in my opinion. Most people are fine with Google having the market cornered on most things, but I believe that competition will help consumers get better features and faster. Plus, Samsung is providing something android is well known for having, choice. 

As I said before, I see assistants as largely useless in most scenarios, so if Bixby can capture just a bit of the tech that made Viv work, then I think we will be better off. It'll force Google to start making their assistant compatible with more 3rd party services, and be able to handle complicated requests. Requests like: "Have tulips delivered to my mother on her birthday", and having it only need to ask for confirmation of the price before completing the action. And at that point, assistants would be worth using outside of driving your car. 

I've followed Viv for a while and have been excited about the demonstrations they've had, but no AI type assistant can survive without a platform. I'm glad they finally have one to provide their product. 
Samsung didn't make the app. They bought out the company who made Siri. If experience is what you're concerned about then they have more experience than every competing assistant. 

Also, everyone agrees that S-voice is garbage (I don't even know if they bothered to put it on my S7 Edge because I've never seen it), but other Samsung apps more than hold their own against Google Apps, and some are much better and faster than them. Internet being one of them. 
You really don't need it.  

It's kind of the whole Samsung thing. Most people don't need multi window, iris scanning, Knox, wireless charging, waterproofing or any other feature that Samsung adds. But the folks who use it can appreciate it. I really appreciate the rewards program from Samsung Pay which has given me 30 dollars over the last 5 months in the form of prepaid Visa cards. But most people don't need that kind of thing and would be just fine with Nfc only payments and Android Pay. 

S-voice is a really shitty application, but it's pretty obvious (in recent years) that they've put a much larger focus on improving their software, which is why they bought Viv. 

If Bixby is even a fraction of the assistant we saw during the demos of Viv, then it's a welcome addition to compete against Google. Cause no other assistant is providing Google with any competition at all. Frankly, voice assistants are quite useless unless your hands are occupied (like while driving), but some competition might get them closer to the Viv tech demo, where a voice command is genuinely faster and easier than tapping on your phone. 
I had a similar problem with Sonarr (can't say if it's the same or not, because I didn't check the logs), but no matter what I did, I couldn't get it to start again.

I just uninstalled, rebooted the NAS, and reinstalled Sonarr and then it seemed to work just fine. Luckily I had only been using it for a few days, so I didn't lose all that much data...just tedious setting it all up again. Anyways, I've been downloading each backup Sonarr performs, in case I run into something like that again.
I didn't know that expansion would take that much longer.

I have 2x 8TB and 2x 4TB, and was considering buying an expansion drive and put another 2x 8TB drives in there.

Do you think it would take more or less time if I moved from my current 4 disk setup, and expanded to include 5 empty drives? I feel like it would take less time since there is more space available and should make balancing the parity information easier (vs adding 1 drive); but I'm not sure how it would play out (I've never tried to expand a Synology volume before).
Is that different than their current jump program? I'm on their jump insurance/upgrade program (the only one they offer now), but I can only upgrade if I pay off half of my phone first, so about a year (unless I want to switch earlier and pay it off sooner). 

Since I also had the Note 7 and had to switch to the S7e, it should be around a year once the Note 8 comes out. Which works out fine for me, since I was planning to get that anyways. 
Are you on an upgrade plan of some kind? Or do you just buy and sell your devices? 
Good work Greenpeace. Throwing out all of those phones, even after salvaging what they could, would have been a massive waste of resources; compounded by the fact that many of them were unused, new devices.

At least if they are sold as refurbished, some will be used before they are thrown out and recycled.

Of course, Samsung should probably brick any Note 7s left out there in the wild before selling refurbished phones since last I heard, they only planned to brick Korean Note 7s
The nightly build seems to be a step in the right direction. In the downloads I've tested, it seems to only grab 1 srt, the nfo file and ignores any extra srt files and txt files (I have it set to grab srt, idx, txt, sub, and nfo files). Still, better than what I had before. I'll have to play around with it some more and see if it's something wrong on my end, or if it's just being finicky because it's a feature in active development.

I certainly tried to address the issue, but since (as I stated before) I'm not very familiar with the Diskstaion OS, I wasn't able to think of anything to try beyond reinstalling the app (which I did a couple of times, to resolve another problem I was having as well). The application still acts as if 'remove download' is turned on, even when it isn't, on both the master build and dev builds.

Anyways, the most common advice I saw online was to use SickRage to import files, which would solve the deleted folders issue, and it would solve my need to import extra files as well, but I didn't want to set up a new application, so I figured I'd ask here first. I have a couple hundred downloads going, and since it's much easier to copy and paste files into the right directories than it is to download and match subtitles, I figured it'd best to turn off importing until I figure this out.

Right, sounds like a plan. The recycle bin bit was just about the OS's recycle bin. Whatever Sonarr does when it deletes the folder, it skips the recycle bin feature built into the Synology OS as well.

Switching to dev seems easy enough (according to the wiki), but to switch from dev to master; should I just uninstall dev, install the master, and then restore my settings via the zip file? Or is there more to it?

I'm pretty new to Sonarr, only been using it about half a week, do you happen to know if the backup zips keep track of shows and what's monitored/unmonitored, or will I have to re-add all of those?
That's great to hear, and that would be exactly what I need. How is the dev branch? Stable enough for day to day use? I am on the master branch right now, and it's not in there yet. 

I'm not very familiar with fixing stuff on my Synology Nas, so if it's stable enough, I'd be willing to make the jump. 
Just FYI, I think I've tracked down why it won't delete some episodes. When I download something released by RARBG, those downloads come with some junk files, and Sonarr can't figure out how to handle the Rarbg.mp4 file (says it can't parse the file), so it doesn't delete the folder. Every other download get deleted immediately, even if it has subtitle files.

For the time being, I've turned off Completed Download Handling, so it doesn't import anything, but that is less convenient. 
Truth is, TouchWiz could be an eyesore and laggy, but their new Grace UX is a major step up in every possible way: much smoother, better looking, fast and responsive, and it's easy to discover and use new features of the phone. 

Samsung's software has matured quite well since the release of the S7. It still won't be for everyone, but I think, now more than ever, Samsung's software is finally worthy of their amazing hardware. 
There was that one Asus phone, from way back whem, that allowed you to stick the phone into a laptop/tablet hybrid type thing. So basically you got a tablet and a laptop all powered by the phone.
If using your phone to pay is all about convenience, then people should use whatever is available (Android Pay, Samsung Pay, their bank's own app, or the store's app, etc). 

Personally, I'd only want to use Samsung Pay (if it's available) and it's because they have a fantastic rewards program. I've already earned over 30 bucks, in the form of a Visa pre-paid debit card, and my mom has earned 35 and we've only been using it since December of 2016. Unfortunately we didn't use it as much in December, so we missed out on a lot of promotions to earn even more money. 

Actually, I'm only earning between 2-5% cash back from my credit card, so given my transactions in the past few months, I've earned more cash from Samsung than I have from my CC (although it's nice to get rewards from both).

I've read that Android Pay has some kind of rewards feature as well, but I've never experienced it, since it only had NFC payments which meant spending mostly on fast food (so I stopped using it last year).
I have the S7 Edge and I don't use cases, but since the Nougat update, I've had a lot less accidental touches. Still nowhere near as good as the Note 7, but it feels like it's improved over what it used to be.
I don't think that matters. I had the Note 7 SD, and my experience with the scanner was pretty good. 

The iris scanner wasn't as fast as the fingerprint reader on the Note 7 (I got used to waking my phone up with the home button because it would log me in almost instantly, no matter how short the button press), but it was faster than the fingerprint reader on the S7 Edge (my current phone). I used a tap on the home button to turn on my phone, but for everything else, I used the iris scanner because it was so convenient.

I don't know what affects people's experiences with iris scanning tech, but my laptop and Note 7 worked great for me. 
It's all the information I need. I know I worked out, and I'm not looking to my heart rate for some kind of diagnosis, or something to act on (I'm going to continue working out at the rate that I'm able, regardless of how great or terrible my heart rate is). I'm just looking to get into better shape and lower my overall heart rate to a range that is normal for someone my age (both my active and resting heart rates). 

That means, at any given snapshot of when I measure my heart rate, I want it to be within a certain range (and I take notes within the app when I think an outside factor is affecting it: ie caffeine). 

And its been working out well for me so far. My system, if one can call it that, is far from perfect, since it's not an average of my heart rate over the day, but it's good enough for me and over the long term the trend has been positive. 

If I had a medical condition (or this was something my doctor ordered me to fix), or I was training for a specific athletic event, then I certainly wouldn't rely on my phone and I'd use a specialized device. For my use case, this is fine. I just want to be in better shape and lower my overall heart rate, and a few snapshots a day (of my resting and active heart rates) is just fine for me. 
When I was working at my old job, the most exercise I received was walking from the parking lot to my car. At work I was at a desk all day, and at home, I was usually on the couch doing more work from my laptop.

After a few years of that, my body was in terrible shape and while it might not have been outwardly obvious (because I was not obese), it was easily visible from my absurdly high, resting heart rate (and high heart rate during mild activities, like walking up steps). I really only need to watch my heart rate at rest and after working out to see the progress I've made. 

I don't really care about the peaks and lows of my heart rate during a walk/run, I only ever need it to get a general idea. 
I use it all the time. I only ever need to check my heart rate out a couple times a day, once when I'm at rest, before a workout and once right after a workout. 

It's pretty convenient for me, and it means I don't have to waste money on a dedicated gadget (like a fitbit) that does a bunch of stuff I don't care about: like counting steps, which my phone already does anyways, or vibrating when I get a notification, which my phone already does as well.